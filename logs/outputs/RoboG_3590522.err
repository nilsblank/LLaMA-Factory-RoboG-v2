GpuFreq=control_disabled
[W1022 11:49:18.724749712 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W1022 11:49:18.724850277 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W1022 11:49:18.733428247 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W1022 11:49:18.733427464 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[INFO|tokenization_utils_base.py:2093] 2025-10-22 11:49:18,983 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2093] 2025-10-22 11:49:18,983 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2093] 2025-10-22 11:49:18,983 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2093] 2025-10-22 11:49:18,983 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2093] 2025-10-22 11:49:18,983 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2093] 2025-10-22 11:49:18,983 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2093] 2025-10-22 11:49:18,983 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2364] 2025-10-22 11:49:19,280 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:381] 2025-10-22 11:49:19,282 >> loading configuration file /home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/saves/qwen3_5vl-4b/full/sft/roboG_qwen3_vl_temporal_grounding_box_train/preprocessor_config.json
[INFO|image_processing_base.py:381] 2025-10-22 11:49:19,288 >> loading configuration file /home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/saves/qwen3_5vl-4b/full/sft/roboG_qwen3_vl_temporal_grounding_box_train/preprocessor_config.json
[INFO|image_processing_base.py:428] 2025-10-22 11:49:19,302 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "input_data_format": null,
  "max_pixels": null,
  "merge_size": 2,
  "min_pixels": null,
  "pad_size": null,
  "patch_size": 16,
  "processor_class": "Qwen3VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 16777216,
    "shortest_edge": 65536
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2093] 2025-10-22 11:49:19,303 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2093] 2025-10-22 11:49:19,303 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2093] 2025-10-22 11:49:19,303 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2093] 2025-10-22 11:49:19,303 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2093] 2025-10-22 11:49:19,303 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2093] 2025-10-22 11:49:19,303 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2093] 2025-10-22 11:49:19,303 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2364] 2025-10-22 11:49:19,612 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:724] 2025-10-22 11:49:19,616 >> loading configuration file /home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/saves/qwen3_5vl-4b/full/sft/roboG_qwen3_vl_temporal_grounding_box_train/video_preprocessor_config.json
[INFO|video_processing_utils.py:770] 2025-10-22 11:49:19,617 >> Video processor Qwen3VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": true,
  "fps": 2,
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "input_data_format": null,
  "max_frames": 768,
  "merge_size": 2,
  "min_frames": 4,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 16,
  "processor_class": "Qwen3VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 25165824,
    "shortest_edge": 4096
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen3VLVideoProcessor"
}

[INFO|processing_utils.py:1114] 2025-10-22 11:49:19,618 >> loading configuration file None
[INFO|processing_utils.py:1199] 2025-10-22 11:49:20,032 >> Processor Qwen3VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "input_data_format": null,
  "max_pixels": null,
  "merge_size": 2,
  "min_pixels": null,
  "pad_size": null,
  "patch_size": 16,
  "processor_class": "Qwen3VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 16777216,
    "shortest_edge": 65536
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/saves/qwen3_5vl-4b/full/sft/roboG_qwen3_vl_temporal_grounding_box_train', vocab_size=151643, model_max_length=262144, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151665: AddedToken("<tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151666: AddedToken("</tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151667: AddedToken("<think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151668: AddedToken("</think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
}
)
- video_processor: Qwen3VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": true,
  "fps": 2,
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "input_data_format": null,
  "max_frames": 768,
  "merge_size": 2,
  "min_frames": 4,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 16,
  "processor_class": "Qwen3VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 25165824,
    "shortest_edge": 4096
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen3VLVideoProcessor"
}


{
  "processor_class": "Qwen3VLProcessor"
}

/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1022 11:49:20.459137191 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1022 11:49:20.532189107 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1022 11:49:20.539286627 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Converting format of dataset (num_proc=128):   0%|          | 0/56022 [00:00<?, ? examples/s]Converting format of dataset (num_proc=128):   0%|          | 14/56022 [00:00<11:01, 84.72 examples/s]Converting format of dataset (num_proc=128):   1%|          | 610/56022 [00:00<00:20, 2755.93 examples/s]Converting format of dataset (num_proc=128):   2%|▏         | 951/56022 [00:00<00:22, 2497.88 examples/s]Converting format of dataset (num_proc=128):   2%|▏         | 1241/56022 [00:00<00:25, 2165.87 examples/s]Converting format of dataset (num_proc=128):   3%|▎         | 1485/56022 [00:00<00:26, 2030.75 examples/s]Converting format of dataset (num_proc=128):   4%|▎         | 2057/56022 [00:00<00:18, 2991.24 examples/s]Converting format of dataset (num_proc=128):   5%|▍         | 2590/56022 [00:00<00:14, 3625.26 examples/s]Converting format of dataset (num_proc=128):   5%|▌         | 3052/56022 [00:01<00:13, 3887.15 examples/s]Converting format of dataset (num_proc=128):   6%|▌         | 3471/56022 [00:01<00:15, 3372.02 examples/s]Converting format of dataset (num_proc=128):   7%|▋         | 3840/56022 [00:01<00:16, 3166.21 examples/s]Converting format of dataset (num_proc=128):   7%|▋         | 4192/56022 [00:01<00:16, 3188.87 examples/s]Converting format of dataset (num_proc=128):   8%|▊         | 4557/56022 [00:01<00:15, 3306.12 examples/s]Converting format of dataset (num_proc=128):   9%|▉         | 4913/56022 [00:01<00:15, 3370.53 examples/s]Converting format of dataset (num_proc=128):   9%|▉         | 5261/56022 [00:01<00:16, 3165.45 examples/s]Converting format of dataset (num_proc=128):  10%|▉         | 5588/56022 [00:01<00:16, 3041.54 examples/s]Converting format of dataset (num_proc=128):  11%|█         | 5899/56022 [00:01<00:16, 3050.97 examples/s]Converting format of dataset (num_proc=128):  11%|█         | 6209/56022 [00:02<00:17, 2919.78 examples/s]Converting format of dataset (num_proc=128):  12%|█▏        | 6511/56022 [00:02<00:16, 2944.11 examples/s]Converting format of dataset (num_proc=128):  12%|█▏        | 6812/56022 [00:02<00:17, 2758.48 examples/s]Converting format of dataset (num_proc=128):  13%|█▎        | 7159/56022 [00:02<00:16, 2948.66 examples/s]Converting format of dataset (num_proc=128):  13%|█▎        | 7459/56022 [00:02<00:18, 2694.05 examples/s]Converting format of dataset (num_proc=128):  14%|█▍        | 7806/56022 [00:02<00:16, 2894.08 examples/s]Converting format of dataset (num_proc=128):  14%|█▍        | 8105/56022 [00:02<00:17, 2780.70 examples/s]Converting format of dataset (num_proc=128):  15%|█▌        | 8430/56022 [00:02<00:16, 2908.19 examples/s]Converting format of dataset (num_proc=128):  16%|█▌        | 8727/56022 [00:02<00:16, 2828.84 examples/s]Converting format of dataset (num_proc=128):  16%|█▌        | 9015/56022 [00:03<00:16, 2778.17 examples/s]Converting format of dataset (num_proc=128):  17%|█▋        | 9296/56022 [00:03<00:16, 2770.05 examples/s]Converting format of dataset (num_proc=128):  17%|█▋        | 9577/56022 [00:03<00:17, 2598.81 examples/s]Converting format of dataset (num_proc=128):  18%|█▊        | 10047/56022 [00:03<00:14, 3170.86 examples/s]Converting format of dataset (num_proc=128):  19%|█▊        | 10388/56022 [00:03<00:14, 3233.19 examples/s]Converting format of dataset (num_proc=128):  19%|█▉        | 10717/56022 [00:03<00:14, 3083.62 examples/s]Converting format of dataset (num_proc=128):  20%|█▉        | 11068/56022 [00:03<00:14, 3202.29 examples/s]Converting format of dataset (num_proc=128):  20%|██        | 11394/56022 [00:03<00:14, 3078.59 examples/s]Converting format of dataset (num_proc=128):  21%|██        | 11813/56022 [00:03<00:13, 3386.59 examples/s]Converting format of dataset (num_proc=128):  22%|██▏       | 12193/56022 [00:04<00:12, 3502.98 examples/s]Converting format of dataset (num_proc=128):  22%|██▏       | 12560/56022 [00:04<00:12, 3546.85 examples/s]Converting format of dataset (num_proc=128):  23%|██▎       | 12918/56022 [00:04<00:12, 3514.23 examples/s]Converting format of dataset (num_proc=128):  24%|██▎       | 13272/56022 [00:04<00:13, 3122.91 examples/s]Converting format of dataset (num_proc=128):  24%|██▍       | 13594/56022 [00:04<00:13, 3081.19 examples/s]Converting format of dataset (num_proc=128):  25%|██▍       | 13911/56022 [00:04<00:13, 3020.68 examples/s]Converting format of dataset (num_proc=128):  25%|██▌       | 14267/56022 [00:04<00:13, 3167.36 examples/s]Converting format of dataset (num_proc=128):  26%|██▌       | 14590/56022 [00:04<00:13, 3135.48 examples/s]Converting format of dataset (num_proc=128):  27%|██▋       | 14908/56022 [00:04<00:13, 3086.78 examples/s]Converting format of dataset (num_proc=128):  27%|██▋       | 15219/56022 [00:05<00:13, 2965.40 examples/s]Converting format of dataset (num_proc=128):  28%|██▊       | 15518/56022 [00:05<00:14, 2889.34 examples/s]Converting format of dataset (num_proc=128):  28%|██▊       | 15812/56022 [00:05<00:13, 2879.57 examples/s]Converting format of dataset (num_proc=128):  29%|██▊       | 16104/56022 [00:05<00:13, 2865.25 examples/s]Converting format of dataset (num_proc=128):  29%|██▉       | 16462/56022 [00:05<00:12, 3064.48 examples/s]Converting format of dataset (num_proc=128):  30%|███       | 16811/56022 [00:05<00:12, 3185.21 examples/s]Converting format of dataset (num_proc=128):  31%|███       | 17131/56022 [00:05<00:13, 2989.86 examples/s]Converting format of dataset (num_proc=128):  31%|███       | 17444/56022 [00:05<00:12, 3008.65 examples/s]Converting format of dataset (num_proc=128):  32%|███▏      | 17762/56022 [00:05<00:12, 3054.80 examples/s]Converting format of dataset (num_proc=128):  32%|███▏      | 18070/56022 [00:06<00:12, 3013.38 examples/s]Converting format of dataset (num_proc=128):  33%|███▎      | 18373/56022 [00:06<00:12, 2973.35 examples/s]Converting format of dataset (num_proc=128):  33%|███▎      | 18672/56022 [00:06<00:12, 2886.89 examples/s]Converting format of dataset (num_proc=128):  34%|███▍      | 19002/56022 [00:06<00:12, 3003.52 examples/s]Converting format of dataset (num_proc=128):  34%|███▍      | 19309/56022 [00:06<00:12, 3022.79 examples/s]Converting format of dataset (num_proc=128):  35%|███▌      | 19613/56022 [00:06<00:12, 2993.70 examples/s]Converting format of dataset (num_proc=128):  36%|███▌      | 19914/56022 [00:06<00:12, 2952.90 examples/s]Converting format of dataset (num_proc=128):  36%|███▋      | 20375/56022 [00:06<00:10, 3435.82 examples/s]Converting format of dataset (num_proc=128):  37%|███▋      | 20723/56022 [00:06<00:10, 3375.97 examples/s]Converting format of dataset (num_proc=128):  38%|███▊      | 21063/56022 [00:06<00:11, 3139.11 examples/s]Converting format of dataset (num_proc=128):  38%|███▊      | 21381/56022 [00:07<00:11, 3001.00 examples/s]Converting format of dataset (num_proc=128):  39%|███▊      | 21686/56022 [00:07<00:11, 2972.44 examples/s]Converting format of dataset (num_proc=128):  39%|███▉      | 22099/56022 [00:07<00:10, 3292.53 examples/s]Converting format of dataset (num_proc=128):  40%|████      | 22517/56022 [00:07<00:09, 3542.15 examples/s]Converting format of dataset (num_proc=128):  41%|████      | 22876/56022 [00:07<00:10, 3246.46 examples/s]Converting format of dataset (num_proc=128):  41%|████▏     | 23210/56022 [00:07<00:10, 3107.46 examples/s]Converting format of dataset (num_proc=128):  42%|████▏     | 23545/56022 [00:07<00:10, 3167.79 examples/s]Converting format of dataset (num_proc=128):  43%|████▎     | 23867/56022 [00:07<00:10, 3095.60 examples/s]Converting format of dataset (num_proc=128):  43%|████▎     | 24200/56022 [00:07<00:10, 3154.22 examples/s]Converting format of dataset (num_proc=128):  44%|████▍     | 24525/56022 [00:08<00:09, 3180.03 examples/s]Converting format of dataset (num_proc=128):  44%|████▍     | 24845/56022 [00:08<00:09, 3126.20 examples/s]Converting format of dataset (num_proc=128):  45%|████▍     | 25161/56022 [00:08<00:10, 2968.01 examples/s]Converting format of dataset (num_proc=128):  45%|████▌     | 25476/56022 [00:08<00:10, 3016.49 examples/s]Converting format of dataset (num_proc=128):  46%|████▌     | 25781/56022 [00:08<00:10, 3003.66 examples/s]Converting format of dataset (num_proc=128):  47%|████▋     | 26132/56022 [00:08<00:09, 3145.60 examples/s]Converting format of dataset (num_proc=128):  47%|████▋     | 26580/56022 [00:08<00:08, 3529.85 examples/s]Converting format of dataset (num_proc=128):  48%|████▊     | 26935/56022 [00:08<00:08, 3306.48 examples/s]Converting format of dataset (num_proc=128):  49%|████▊     | 27271/56022 [00:08<00:09, 3162.01 examples/s]Converting format of dataset (num_proc=128):  49%|████▉     | 27597/56022 [00:09<00:09, 3063.08 examples/s]Converting format of dataset (num_proc=128):  50%|████▉     | 27925/56022 [00:09<00:08, 3121.89 examples/s]Converting format of dataset (num_proc=128):  50%|█████     | 28244/56022 [00:09<00:09, 3018.99 examples/s]Converting format of dataset (num_proc=128):  51%|█████     | 28554/56022 [00:09<00:09, 2932.80 examples/s]Converting format of dataset (num_proc=128):  52%|█████▏    | 28899/56022 [00:09<00:08, 3074.39 examples/s]Converting format of dataset (num_proc=128):  52%|█████▏    | 29211/56022 [00:09<00:08, 3074.54 examples/s]Converting format of dataset (num_proc=128):  53%|█████▎    | 29552/56022 [00:09<00:08, 3170.58 examples/s]Converting format of dataset (num_proc=128):  53%|█████▎    | 29883/56022 [00:09<00:08, 3207.47 examples/s]Converting format of dataset (num_proc=128):  54%|█████▍    | 30206/56022 [00:09<00:08, 3166.30 examples/s]Converting format of dataset (num_proc=128):  54%|█████▍    | 30524/56022 [00:09<00:08, 2999.79 examples/s]Converting format of dataset (num_proc=128):  55%|█████▌    | 30870/56022 [00:10<00:08, 3124.29 examples/s]Converting format of dataset (num_proc=128):  56%|█████▌    | 31185/56022 [00:10<00:08, 3067.35 examples/s]Converting format of dataset (num_proc=128):  56%|█████▋    | 31529/56022 [00:10<00:07, 3162.82 examples/s]Converting format of dataset (num_proc=128):  57%|█████▋    | 31936/56022 [00:10<00:07, 3423.42 examples/s]Converting format of dataset (num_proc=128):  58%|█████▊    | 32281/56022 [00:10<00:06, 3411.00 examples/s]Converting format of dataset (num_proc=128):  58%|█████▊    | 32627/56022 [00:10<00:07, 3307.88 examples/s]Converting format of dataset (num_proc=128):  59%|█████▉    | 32960/56022 [00:10<00:06, 3299.64 examples/s]Converting format of dataset (num_proc=128):  59%|█████▉    | 33291/56022 [00:10<00:07, 3238.43 examples/s]Converting format of dataset (num_proc=128):  60%|██████    | 33638/56022 [00:10<00:06, 3273.72 examples/s]Converting format of dataset (num_proc=128):  61%|██████    | 33968/56022 [00:11<00:06, 3230.92 examples/s]Converting format of dataset (num_proc=128):  61%|██████    | 34298/56022 [00:11<00:06, 3152.11 examples/s]Converting format of dataset (num_proc=128):  62%|██████▏   | 34663/56022 [00:11<00:06, 3293.64 examples/s]Converting format of dataset (num_proc=128):  62%|██████▏   | 34994/56022 [00:11<00:06, 3220.13 examples/s]Converting format of dataset (num_proc=128):  63%|██████▎   | 35318/56022 [00:11<00:06, 3222.38 examples/s]Converting format of dataset (num_proc=128):  64%|██████▎   | 35669/56022 [00:11<00:06, 3301.52 examples/s]Converting format of dataset (num_proc=128):  64%|██████▍   | 36002/56022 [00:11<00:06, 3254.65 examples/s]Converting format of dataset (num_proc=128):  65%|██████▍   | 36329/56022 [00:11<00:06, 3231.41 examples/s]Converting format of dataset (num_proc=128):  65%|██████▌   | 36655/56022 [00:11<00:06, 3103.72 examples/s]Converting format of dataset (num_proc=128):  66%|██████▌   | 36978/56022 [00:11<00:06, 3137.19 examples/s]Converting format of dataset (num_proc=128):  67%|██████▋   | 37293/56022 [00:12<00:06, 3086.19 examples/s]Converting format of dataset (num_proc=128):  67%|██████▋   | 37604/56022 [00:12<00:05, 3083.45 examples/s]Converting format of dataset (num_proc=128):  68%|██████▊   | 37922/56022 [00:12<00:05, 3099.07 examples/s]Converting format of dataset (num_proc=128):  68%|██████▊   | 38234/56022 [00:12<00:05, 3032.16 examples/s]Converting format of dataset (num_proc=128):  69%|██████▉   | 38546/56022 [00:12<00:05, 3057.33 examples/s]Converting format of dataset (num_proc=128):  69%|██████▉   | 38853/56022 [00:12<00:05, 3005.22 examples/s]Converting format of dataset (num_proc=128):  70%|██████▉   | 39166/56022 [00:12<00:05, 3041.31 examples/s]Converting format of dataset (num_proc=128):  70%|███████   | 39490/56022 [00:12<00:05, 3092.28 examples/s]Converting format of dataset (num_proc=128):  71%|███████   | 39801/56022 [00:12<00:05, 3076.19 examples/s]Converting format of dataset (num_proc=128):  72%|███████▏  | 40113/56022 [00:13<00:05, 3045.74 examples/s]Converting format of dataset (num_proc=128):  72%|███████▏  | 40433/56022 [00:13<00:05, 3089.30 examples/s]Converting format of dataset (num_proc=128):  73%|███████▎  | 40743/56022 [00:13<00:04, 3068.97 examples/s]Converting format of dataset (num_proc=128):  73%|███████▎  | 41138/56022 [00:13<00:04, 3311.78 examples/s]Converting format of dataset (num_proc=128):  74%|███████▍  | 41498/56022 [00:13<00:04, 3396.71 examples/s]Converting format of dataset (num_proc=128):  75%|███████▍  | 41838/56022 [00:13<00:04, 3336.34 examples/s]Converting format of dataset (num_proc=128):  75%|███████▌  | 42174/56022 [00:13<00:04, 3174.62 examples/s]Converting format of dataset (num_proc=128):  76%|███████▌  | 42495/56022 [00:13<00:04, 3014.31 examples/s]Converting format of dataset (num_proc=128):  76%|███████▋  | 42800/56022 [00:13<00:04, 3013.55 examples/s]Converting format of dataset (num_proc=128):  77%|███████▋  | 43107/56022 [00:13<00:04, 3026.42 examples/s]Converting format of dataset (num_proc=128):  78%|███████▊  | 43434/56022 [00:14<00:04, 3093.33 examples/s]Converting format of dataset (num_proc=128):  78%|███████▊  | 43745/56022 [00:14<00:04, 2980.39 examples/s]Converting format of dataset (num_proc=128):  79%|███████▊  | 44046/56022 [00:14<00:04, 2881.52 examples/s]Converting format of dataset (num_proc=128):  79%|███████▉  | 44344/56022 [00:14<00:04, 2894.77 examples/s]Converting format of dataset (num_proc=128):  80%|███████▉  | 44725/56022 [00:14<00:03, 3147.88 examples/s]Converting format of dataset (num_proc=128):  80%|████████  | 45042/56022 [00:14<00:03, 3009.67 examples/s]Converting format of dataset (num_proc=128):  81%|████████  | 45346/56022 [00:14<00:03, 2954.53 examples/s]Converting format of dataset (num_proc=128):  81%|████████▏ | 45644/56022 [00:14<00:03, 2843.88 examples/s]Converting format of dataset (num_proc=128):  82%|████████▏ | 45931/56022 [00:14<00:03, 2847.81 examples/s]Converting format of dataset (num_proc=128):  82%|████████▏ | 46217/56022 [00:15<00:03, 2790.31 examples/s]Converting format of dataset (num_proc=128):  83%|████████▎ | 46498/56022 [00:15<00:03, 2792.69 examples/s]Converting format of dataset (num_proc=128):  83%|████████▎ | 46778/56022 [00:15<00:03, 2760.74 examples/s]Converting format of dataset (num_proc=128):  84%|████████▍ | 47076/56022 [00:15<00:03, 2815.02 examples/s]Converting format of dataset (num_proc=128):  85%|████████▍ | 47387/56022 [00:15<00:03, 2857.99 examples/s]Converting format of dataset (num_proc=128):  85%|████████▌ | 47747/56022 [00:15<00:02, 3033.03 examples/s]Converting format of dataset (num_proc=128):  86%|████████▌ | 48052/56022 [00:15<00:02, 2933.23 examples/s]Converting format of dataset (num_proc=128):  86%|████████▋ | 48346/56022 [00:15<00:02, 2777.02 examples/s]Converting format of dataset (num_proc=128):  87%|████████▋ | 48627/56022 [00:15<00:02, 2704.26 examples/s]Converting format of dataset (num_proc=128):  87%|████████▋ | 48901/56022 [00:16<00:02, 2661.53 examples/s]Converting format of dataset (num_proc=128):  88%|████████▊ | 49169/56022 [00:16<00:02, 2554.05 examples/s]Converting format of dataset (num_proc=128):  88%|████████▊ | 49426/56022 [00:16<00:02, 2556.40 examples/s]Converting format of dataset (num_proc=128):  89%|████████▊ | 49695/56022 [00:16<00:02, 2579.93 examples/s]Converting format of dataset (num_proc=128):  89%|████████▉ | 49956/56022 [00:16<00:02, 2581.22 examples/s]Converting format of dataset (num_proc=128):  90%|████████▉ | 50216/56022 [00:16<00:02, 2502.03 examples/s]Converting format of dataset (num_proc=128):  90%|█████████ | 50504/56022 [00:16<00:02, 2599.40 examples/s]Converting format of dataset (num_proc=128):  91%|█████████ | 50767/56022 [00:16<00:02, 2540.11 examples/s]Converting format of dataset (num_proc=128):  91%|█████████ | 51053/56022 [00:16<00:01, 2586.27 examples/s]Converting format of dataset (num_proc=128):  92%|█████████▏| 51374/56022 [00:16<00:01, 2762.49 examples/s]Converting format of dataset (num_proc=128):  92%|█████████▏| 51784/56022 [00:17<00:01, 3114.57 examples/s]Converting format of dataset (num_proc=128):  93%|█████████▎| 52111/56022 [00:17<00:01, 3143.33 examples/s]Converting format of dataset (num_proc=128):  94%|█████████▎| 52497/56022 [00:17<00:01, 3267.77 examples/s]Converting format of dataset (num_proc=128):  94%|█████████▍| 52845/56022 [00:17<00:00, 3310.06 examples/s]Converting format of dataset (num_proc=128):  95%|█████████▍| 53179/56022 [00:17<00:00, 3181.45 examples/s]Converting format of dataset (num_proc=128):  96%|█████████▌| 53503/56022 [00:17<00:00, 3038.83 examples/s]Converting format of dataset (num_proc=128):  96%|█████████▌| 53812/56022 [00:17<00:00, 2971.74 examples/s]Converting format of dataset (num_proc=128):  97%|█████████▋| 54114/56022 [00:17<00:00, 2842.15 examples/s]Converting format of dataset (num_proc=128):  97%|█████████▋| 54400/56022 [00:17<00:00, 2639.23 examples/s]Converting format of dataset (num_proc=128):  98%|█████████▊| 54671/56022 [00:18<00:00, 2548.71 examples/s]Converting format of dataset (num_proc=128):  98%|█████████▊| 54930/56022 [00:18<00:00, 2500.41 examples/s]Converting format of dataset (num_proc=128):  99%|█████████▊| 55187/56022 [00:18<00:00, 2485.13 examples/s]Converting format of dataset (num_proc=128):  99%|█████████▉| 55443/56022 [00:18<00:00, 2400.37 examples/s]Converting format of dataset (num_proc=128):  99%|█████████▉| 55686/56022 [00:18<00:00, 2277.57 examples/s]Converting format of dataset (num_proc=128): 100%|█████████▉| 55915/56022 [00:18<00:00, 2066.26 examples/s]Converting format of dataset (num_proc=128): 100%|██████████| 56022/56022 [00:18<00:00, 2956.16 examples/s]
num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
Converting format of dataset (num_proc=83):   0%|          | 0/83 [00:00<?, ? examples/s]Converting format of dataset (num_proc=83):   1%|          | 1/83 [00:00<00:09,  8.50 examples/s]Converting format of dataset (num_proc=83):  40%|███▉      | 33/83 [00:00<00:00, 178.61 examples/s]Converting format of dataset (num_proc=83):  64%|██████▍   | 53/83 [00:00<00:00, 145.19 examples/s]Converting format of dataset (num_proc=83):  83%|████████▎ | 69/83 [00:00<00:00, 140.86 examples/s]Converting format of dataset (num_proc=83): 100%|██████████| 83/83 [00:00<00:00, 133.54 examples/s]
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1022 11:49:43.704036194 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
Running tokenizer on dataset (num_proc=128):   0%|          | 0/56022 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=128):   1%|          | 438/56022 [02:36<5:30:55,  2.80 examples/s]Running tokenizer on dataset (num_proc=128):   2%|▏         | 876/56022 [02:59<2:43:42,  5.61 examples/s]Running tokenizer on dataset (num_proc=128):   2%|▏         | 1314/56022 [03:00<1:28:45, 10.27 examples/s]Running tokenizer on dataset (num_proc=128):   3%|▎         | 1752/56022 [03:03<55:52, 16.19 examples/s]  Running tokenizer on dataset (num_proc=128):   4%|▍         | 2190/56022 [03:03<35:50, 25.03 examples/s]Running tokenizer on dataset (num_proc=128):   5%|▌         | 3066/56022 [03:04<17:39, 49.96 examples/s]Running tokenizer on dataset (num_proc=128):   6%|▋         | 3504/56022 [03:06<13:47, 63.50 examples/s]Running tokenizer on dataset (num_proc=128):   7%|▋         | 3942/56022 [03:09<11:59, 72.38 examples/s]Running tokenizer on dataset (num_proc=128):   8%|▊         | 4380/56022 [03:13<10:20, 83.18 examples/s]Running tokenizer on dataset (num_proc=128):   9%|▊         | 4818/56022 [03:14<07:45, 110.00 examples/s]Running tokenizer on dataset (num_proc=128):   9%|▉         | 5256/56022 [03:14<05:36, 150.94 examples/s]Running tokenizer on dataset (num_proc=128):  10%|█         | 5694/56022 [03:20<07:21, 113.92 examples/s]Running tokenizer on dataset (num_proc=128):  11%|█         | 6132/56022 [03:21<05:50, 142.50 examples/s]Running tokenizer on dataset (num_proc=128):  12%|█▏        | 6570/56022 [03:23<05:14, 157.14 examples/s]Running tokenizer on dataset (num_proc=128):  13%|█▎        | 7446/56022 [03:24<03:12, 251.98 examples/s]Running tokenizer on dataset (num_proc=128):  14%|█▍        | 7884/56022 [03:25<02:48, 285.43 examples/s]Running tokenizer on dataset (num_proc=128):  15%|█▍        | 8322/56022 [03:26<02:23, 333.46 examples/s]Running tokenizer on dataset (num_proc=128):  16%|█▌        | 8760/56022 [03:26<01:50, 427.71 examples/s]Running tokenizer on dataset (num_proc=128):  16%|█▋        | 9198/56022 [03:27<01:44, 449.26 examples/s]Running tokenizer on dataset (num_proc=128):  17%|█▋        | 9636/56022 [03:34<04:43, 163.53 examples/s]Running tokenizer on dataset (num_proc=128):  18%|█▊        | 10074/56022 [03:35<03:39, 209.33 examples/s]Running tokenizer on dataset (num_proc=128):  19%|█▉        | 10512/56022 [03:36<03:20, 227.02 examples/s]Running tokenizer on dataset (num_proc=128):  20%|█▉        | 10950/56022 [03:41<04:41, 160.40 examples/s]Running tokenizer on dataset (num_proc=128):  20%|██        | 11388/56022 [03:43<04:26, 167.33 examples/s]Running tokenizer on dataset (num_proc=128):  21%|██        | 11826/56022 [03:46<04:20, 169.81 examples/s]Running tokenizer on dataset (num_proc=128):  22%|██▏       | 12264/56022 [03:46<03:11, 228.08 examples/s]Running tokenizer on dataset (num_proc=128):  23%|██▎       | 12702/56022 [03:52<04:58, 145.34 examples/s]Running tokenizer on dataset (num_proc=128):  23%|██▎       | 13140/56022 [03:52<03:38, 195.82 examples/s]Running tokenizer on dataset (num_proc=128):  24%|██▍       | 13578/56022 [03:52<02:34, 274.12 examples/s]Running tokenizer on dataset (num_proc=128):  25%|██▌       | 14015/56022 [03:52<01:57, 358.15 examples/s]Running tokenizer on dataset (num_proc=128):  26%|██▌       | 14452/56022 [03:53<01:44, 398.93 examples/s]Running tokenizer on dataset (num_proc=128):  27%|██▋       | 14890/56022 [03:54<01:21, 505.53 examples/s]Running tokenizer on dataset (num_proc=128):  28%|██▊       | 15766/56022 [03:54<00:56, 716.56 examples/s]Running tokenizer on dataset (num_proc=128):  29%|██▉       | 16204/56022 [03:56<01:31, 436.92 examples/s]Running tokenizer on dataset (num_proc=128):  30%|██▉       | 16642/56022 [03:57<01:28, 445.67 examples/s]Running tokenizer on dataset (num_proc=128):  30%|███       | 17080/56022 [03:58<01:28, 440.97 examples/s]Running tokenizer on dataset (num_proc=128):  31%|███▏      | 17518/56022 [04:00<01:55, 333.06 examples/s]Running tokenizer on dataset (num_proc=128):  32%|███▏      | 17956/56022 [04:03<02:22, 266.93 examples/s]Running tokenizer on dataset (num_proc=128):  34%|███▎      | 18831/56022 [04:04<01:38, 377.63 examples/s]Running tokenizer on dataset (num_proc=128):  34%|███▍      | 19269/56022 [04:09<02:46, 221.07 examples/s]Running tokenizer on dataset (num_proc=128):  35%|███▌      | 19707/56022 [04:09<02:16, 265.11 examples/s]Running tokenizer on dataset (num_proc=128):  36%|███▌      | 20145/56022 [04:10<01:59, 299.38 examples/s]Running tokenizer on dataset (num_proc=128):  37%|███▋      | 20583/56022 [04:10<01:30, 393.56 examples/s]Running tokenizer on dataset (num_proc=128):  38%|███▊      | 21459/56022 [04:11<00:52, 659.52 examples/s]Running tokenizer on dataset (num_proc=128):  39%|███▉      | 21896/56022 [04:13<01:17, 440.22 examples/s]Running tokenizer on dataset (num_proc=128):  40%|███▉      | 22334/56022 [04:13<00:59, 564.42 examples/s]Running tokenizer on dataset (num_proc=128):  41%|████      | 22772/56022 [04:15<01:20, 414.50 examples/s]Running tokenizer on dataset (num_proc=128):  41%|████▏     | 23210/56022 [04:15<01:06, 490.55 examples/s]Running tokenizer on dataset (num_proc=128):  42%|████▏     | 23647/56022 [04:16<00:57, 566.01 examples/s]Running tokenizer on dataset (num_proc=128):  43%|████▎     | 24085/56022 [04:17<01:08, 467.22 examples/s]Running tokenizer on dataset (num_proc=128):  44%|████▍     | 24523/56022 [04:18<01:01, 512.33 examples/s]Running tokenizer on dataset (num_proc=128):  45%|████▍     | 24961/56022 [04:18<00:46, 671.52 examples/s]Running tokenizer on dataset (num_proc=128):  45%|████▌     | 25399/56022 [04:18<00:36, 843.66 examples/s]Running tokenizer on dataset (num_proc=128):  47%|████▋     | 26274/56022 [04:18<00:24, 1237.01 examples/s]Running tokenizer on dataset (num_proc=128):  48%|████▊     | 27148/56022 [04:18<00:17, 1686.84 examples/s]Running tokenizer on dataset (num_proc=128):  49%|████▉     | 27586/56022 [04:19<00:14, 1948.21 examples/s]Running tokenizer on dataset (num_proc=128):  50%|█████     | 28023/56022 [04:19<00:23, 1203.35 examples/s]Running tokenizer on dataset (num_proc=128):  52%|█████▏    | 28899/56022 [04:20<00:15, 1745.81 examples/s]Running tokenizer on dataset (num_proc=128):  52%|█████▏    | 29336/56022 [04:20<00:15, 1668.62 examples/s]Running tokenizer on dataset (num_proc=128):  53%|█████▎    | 29774/56022 [04:21<00:28, 909.55 examples/s] Running tokenizer on dataset (num_proc=128):  54%|█████▍    | 30212/56022 [04:24<01:09, 370.80 examples/s]Running tokenizer on dataset (num_proc=128):  55%|█████▍    | 30650/56022 [04:25<00:55, 455.73 examples/s]Running tokenizer on dataset (num_proc=128):  56%|█████▋    | 31525/56022 [04:25<00:36, 665.00 examples/s]Running tokenizer on dataset (num_proc=128):  58%|█████▊    | 32399/56022 [04:26<00:34, 677.31 examples/s]Running tokenizer on dataset (num_proc=128):  59%|█████▊    | 32836/56022 [04:27<00:37, 623.45 examples/s]Running tokenizer on dataset (num_proc=128):  59%|█████▉    | 33273/56022 [04:27<00:30, 740.51 examples/s]Running tokenizer on dataset (num_proc=128):  60%|██████    | 33711/56022 [04:30<00:53, 418.62 examples/s]Running tokenizer on dataset (num_proc=128):  61%|██████    | 34148/56022 [04:30<00:45, 484.75 examples/s]Running tokenizer on dataset (num_proc=128):  63%|██████▎   | 35024/56022 [04:31<00:28, 748.55 examples/s]Running tokenizer on dataset (num_proc=128):  63%|██████▎   | 35461/56022 [04:31<00:25, 808.03 examples/s]Running tokenizer on dataset (num_proc=128):  64%|██████▍   | 35898/56022 [04:32<00:26, 772.00 examples/s]Running tokenizer on dataset (num_proc=128):  65%|██████▍   | 36336/56022 [04:32<00:21, 910.31 examples/s]Running tokenizer on dataset (num_proc=128):  66%|██████▌   | 36774/56022 [04:32<00:19, 1012.54 examples/s]Running tokenizer on dataset (num_proc=128):  68%|██████▊   | 38087/56022 [04:34<00:17, 1043.90 examples/s]Running tokenizer on dataset (num_proc=128):  69%|██████▉   | 38524/56022 [04:35<00:26, 651.50 examples/s] Running tokenizer on dataset (num_proc=128):  70%|██████▉   | 38962/56022 [04:36<00:28, 599.02 examples/s]Running tokenizer on dataset (num_proc=128):  71%|███████   | 39837/56022 [04:38<00:29, 545.27 examples/s]Running tokenizer on dataset (num_proc=128):  73%|███████▎  | 40713/56022 [04:39<00:22, 674.83 examples/s]Running tokenizer on dataset (num_proc=128):  73%|███████▎  | 41151/56022 [04:40<00:23, 642.38 examples/s]Running tokenizer on dataset (num_proc=128):  74%|███████▍  | 41589/56022 [04:40<00:20, 705.09 examples/s]Running tokenizer on dataset (num_proc=128):  75%|███████▌  | 42026/56022 [04:40<00:18, 754.82 examples/s]Running tokenizer on dataset (num_proc=128):  76%|███████▌  | 42464/56022 [04:41<00:20, 674.87 examples/s]Running tokenizer on dataset (num_proc=128):  77%|███████▋  | 42902/56022 [04:42<00:17, 763.04 examples/s]Running tokenizer on dataset (num_proc=128):  78%|███████▊  | 43776/56022 [04:42<00:10, 1209.96 examples/s]Running tokenizer on dataset (num_proc=128):  80%|████████  | 45087/56022 [04:43<00:09, 1123.91 examples/s]Running tokenizer on dataset (num_proc=128):  81%|████████▏ | 45525/56022 [04:44<00:09, 1067.44 examples/s]Running tokenizer on dataset (num_proc=128):  82%|████████▏ | 45963/56022 [04:44<00:09, 1071.60 examples/s]Running tokenizer on dataset (num_proc=128):  83%|████████▎ | 46400/56022 [04:44<00:07, 1261.08 examples/s]Running tokenizer on dataset (num_proc=128):  84%|████████▎ | 46838/56022 [04:46<00:13, 695.17 examples/s] Running tokenizer on dataset (num_proc=128):  84%|████████▍ | 47276/56022 [04:48<00:20, 429.94 examples/s]Running tokenizer on dataset (num_proc=128):  85%|████████▌ | 47713/56022 [04:50<00:26, 309.00 examples/s]Running tokenizer on dataset (num_proc=128):  86%|████████▌ | 48151/56022 [04:51<00:22, 348.89 examples/s]Running tokenizer on dataset (num_proc=128):  87%|████████▋ | 48588/56022 [04:51<00:15, 470.56 examples/s]Running tokenizer on dataset (num_proc=128):  88%|████████▊ | 49026/56022 [04:52<00:16, 429.19 examples/s]Running tokenizer on dataset (num_proc=128):  88%|████████▊ | 49463/56022 [04:53<00:12, 537.24 examples/s]Running tokenizer on dataset (num_proc=128):  89%|████████▉ | 49900/56022 [04:53<00:10, 558.41 examples/s]Running tokenizer on dataset (num_proc=128):  90%|████████▉ | 50337/56022 [04:58<00:26, 216.18 examples/s]Running tokenizer on dataset (num_proc=128):  91%|█████████ | 50774/56022 [05:00<00:21, 240.27 examples/s]Running tokenizer on dataset (num_proc=128):  91%|█████████▏| 51212/56022 [05:00<00:14, 322.01 examples/s]Running tokenizer on dataset (num_proc=128):  92%|█████████▏| 51649/56022 [05:05<00:23, 184.83 examples/s]Running tokenizer on dataset (num_proc=128):  93%|█████████▎| 52086/56022 [05:05<00:15, 252.49 examples/s]Running tokenizer on dataset (num_proc=128):  94%|█████████▍| 52524/56022 [05:06<00:13, 263.15 examples/s]Running tokenizer on dataset (num_proc=128):  95%|█████████▍| 52962/56022 [05:07<00:08, 365.25 examples/s]Running tokenizer on dataset (num_proc=128):  95%|█████████▌| 53399/56022 [05:08<00:07, 349.75 examples/s]Running tokenizer on dataset (num_proc=128):  96%|█████████▌| 53836/56022 [05:09<00:05, 413.12 examples/s]Running tokenizer on dataset (num_proc=128):  98%|█████████▊| 54710/56022 [05:10<00:02, 474.13 examples/s]Running tokenizer on dataset (num_proc=128):  98%|█████████▊| 55147/56022 [05:11<00:02, 428.48 examples/s]Running tokenizer on dataset (num_proc=128):  99%|█████████▉| 55585/56022 [05:12<00:01, 423.07 examples/s]Running tokenizer on dataset (num_proc=128): 100%|██████████| 56022/56022 [05:16<00:00, 265.20 examples/s]Running tokenizer on dataset (num_proc=128): 100%|██████████| 56022/56022 [05:16<00:00, 177.11 examples/s]
num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
Running tokenizer on dataset (num_proc=83):   0%|          | 0/83 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=83):   1%|          | 1/83 [00:00<01:03,  1.29 examples/s]Running tokenizer on dataset (num_proc=83):   5%|▍         | 4/83 [00:00<00:15,  5.03 examples/s]Running tokenizer on dataset (num_proc=83):   7%|▋         | 6/83 [00:01<00:11,  6.50 examples/s]Running tokenizer on dataset (num_proc=83):  10%|▉         | 8/83 [00:01<00:09,  7.62 examples/s]Running tokenizer on dataset (num_proc=83):  12%|█▏        | 10/83 [00:01<00:07,  9.64 examples/s]Running tokenizer on dataset (num_proc=83):  14%|█▍        | 12/83 [00:01<00:07,  9.06 examples/s]Running tokenizer on dataset (num_proc=83):  17%|█▋        | 14/83 [00:01<00:07,  9.19 examples/s]Running tokenizer on dataset (num_proc=83):  19%|█▉        | 16/83 [00:02<00:07,  8.70 examples/s]Running tokenizer on dataset (num_proc=83):  23%|██▎       | 19/83 [00:02<00:06,  9.37 examples/s]Running tokenizer on dataset (num_proc=83):  25%|██▌       | 21/83 [00:02<00:06,  9.42 examples/s]Running tokenizer on dataset (num_proc=83):  28%|██▊       | 23/83 [00:02<00:05, 10.08 examples/s]Running tokenizer on dataset (num_proc=83):  30%|███       | 25/83 [00:03<00:05, 10.18 examples/s]Running tokenizer on dataset (num_proc=83):  33%|███▎      | 27/83 [00:03<00:05, 10.19 examples/s]Running tokenizer on dataset (num_proc=83):  35%|███▍      | 29/83 [00:03<00:04, 11.81 examples/s]Running tokenizer on dataset (num_proc=83):  37%|███▋      | 31/83 [00:03<00:05,  9.77 examples/s]Running tokenizer on dataset (num_proc=83):  40%|███▉      | 33/83 [00:03<00:05,  9.97 examples/s]Running tokenizer on dataset (num_proc=83):  42%|████▏     | 35/83 [00:03<00:04, 11.63 examples/s]Running tokenizer on dataset (num_proc=83):  45%|████▍     | 37/83 [00:04<00:04,  9.73 examples/s]Running tokenizer on dataset (num_proc=83):  47%|████▋     | 39/83 [00:04<00:04,  9.99 examples/s]Running tokenizer on dataset (num_proc=83):  49%|████▉     | 41/83 [00:04<00:04, 10.08 examples/s]Running tokenizer on dataset (num_proc=83):  52%|█████▏    | 43/83 [00:04<00:03, 11.42 examples/s]Running tokenizer on dataset (num_proc=83):  54%|█████▍    | 45/83 [00:04<00:03, 10.93 examples/s]Running tokenizer on dataset (num_proc=83):  57%|█████▋    | 47/83 [00:05<00:03, 11.21 examples/s]Running tokenizer on dataset (num_proc=83):  59%|█████▉    | 49/83 [00:05<00:03, 10.60 examples/s]Running tokenizer on dataset (num_proc=83):  61%|██████▏   | 51/83 [00:05<00:03,  9.55 examples/s]Running tokenizer on dataset (num_proc=83):  64%|██████▍   | 53/83 [00:05<00:03,  9.88 examples/s]Running tokenizer on dataset (num_proc=83):  66%|██████▋   | 55/83 [00:05<00:02,  9.97 examples/s]Running tokenizer on dataset (num_proc=83):  69%|██████▊   | 57/83 [00:06<00:02, 10.01 examples/s]Running tokenizer on dataset (num_proc=83):  71%|███████   | 59/83 [00:06<00:02, 11.52 examples/s]Running tokenizer on dataset (num_proc=83):  73%|███████▎  | 61/83 [00:06<00:01, 11.00 examples/s]Running tokenizer on dataset (num_proc=83):  76%|███████▌  | 63/83 [00:06<00:01, 11.09 examples/s]Running tokenizer on dataset (num_proc=83):  78%|███████▊  | 65/83 [00:06<00:01,  9.37 examples/s]Running tokenizer on dataset (num_proc=83):  81%|████████  | 67/83 [00:07<00:01, 10.87 examples/s]Running tokenizer on dataset (num_proc=83):  83%|████████▎ | 69/83 [00:07<00:01, 10.70 examples/s]Running tokenizer on dataset (num_proc=83):  86%|████████▌ | 71/83 [00:07<00:01, 10.80 examples/s]Running tokenizer on dataset (num_proc=83):  88%|████████▊ | 73/83 [00:07<00:00, 10.59 examples/s]Running tokenizer on dataset (num_proc=83):  90%|█████████ | 75/83 [00:07<00:00,  9.05 examples/s]Running tokenizer on dataset (num_proc=83):  94%|█████████▍| 78/83 [00:08<00:00, 10.36 examples/s]Running tokenizer on dataset (num_proc=83):  96%|█████████▋| 80/83 [00:08<00:00,  9.60 examples/s]Running tokenizer on dataset (num_proc=83):  99%|█████████▉| 82/83 [00:08<00:00, 10.05 examples/s]Running tokenizer on dataset (num_proc=83): 100%|██████████| 83/83 [00:08<00:00,  9.56 examples/s]
[INFO|configuration_utils.py:763] 2025-10-22 11:55:12,912 >> loading configuration file /home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/saves/qwen3_5vl-4b/full/sft/roboG_qwen3_vl_temporal_grounding_box_train/config.json
[INFO|configuration_utils.py:839] 2025-10-22 11:55:12,923 >> Model config Qwen3VLConfig {
  "architectures": [
    "Qwen3VLForConditionalGeneration"
  ],
  "dtype": "bfloat16",
  "eos_token_id": 151645,
  "hidden_size": 2560,
  "image_token_id": 151655,
  "model_type": "qwen3_vl",
  "pad_token_id": 151643,
  "text_config": {
    "attention_bias": false,
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "dtype": "bfloat16",
    "eos_token_id": 151645,
    "head_dim": 128,
    "hidden_act": "silu",
    "hidden_size": 2560,
    "initializer_range": 0.02,
    "intermediate_size": 9728,
    "max_position_embeddings": 262144,
    "model_type": "qwen3_vl_text",
    "num_attention_heads": 32,
    "num_hidden_layers": 36,
    "num_key_value_heads": 8,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_interleaved": true,
      "mrope_section": [
        24,
        20,
        20
      ],
      "rope_type": "default"
    },
    "rope_theta": 5000000,
    "tie_word_embeddings": true,
    "use_cache": false,
    "vocab_size": 151936
  },
  "tie_word_embeddings": true,
  "transformers_version": "4.57.1",
  "use_cache": false,
  "video_token_id": 151656,
  "vision_config": {
    "deepstack_visual_indexes": [
      5,
      11,
      17
    ],
    "depth": 24,
    "dtype": "bfloat16",
    "hidden_act": "gelu_pytorch_tanh",
    "hidden_size": 1024,
    "in_channels": 3,
    "initializer_range": 0.02,
    "intermediate_size": 4096,
    "model_type": "qwen3_vl",
    "num_heads": 16,
    "num_position_embeddings": 2304,
    "out_hidden_size": 2560,
    "patch_size": 16,
    "spatial_merge_size": 2,
    "temporal_patch_size": 2
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652
}

num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[WARNING|logging.py:328] 2025-10-22 11:55:14,344 >> `torch_dtype` is deprecated! Use `dtype` instead!
[INFO|modeling_utils.py:1169] 2025-10-22 11:55:14,345 >> loading weights file /home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/saves/qwen3_5vl-4b/full/sft/roboG_qwen3_vl_temporal_grounding_box_train/model.safetensors.index.json
[INFO|modeling_utils.py:2341] 2025-10-22 11:55:14,347 >> Instantiating Qwen3VLForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:986] 2025-10-22 11:55:14,362 >> Generate config GenerationConfig {
  "eos_token_id": 151645,
  "pad_token_id": 151643
}

[INFO|modeling_utils.py:2341] 2025-10-22 11:55:14,367 >> Instantiating Qwen3VLVisionModel model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:2341] 2025-10-22 11:55:14,384 >> Instantiating Qwen3VLTextModel model under default dtype torch.bfloat16.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.78s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.78s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.78s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.91s/it]

Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.91s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.91s/it]
[INFO|configuration_utils.py:939] 2025-10-22 11:55:28,301 >> loading configuration file /home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/saves/qwen3_5vl-4b/full/sft/roboG_qwen3_vl_temporal_grounding_box_train/generation_config.json
[INFO|configuration_utils.py:986] 2025-10-22 11:55:28,301 >> Generate config GenerationConfig {
  "do_sample": true,
  "eos_token_id": [
    151645,
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.7,
  "top_k": 20,
  "top_p": 0.8
}

[INFO|dynamic_module_utils.py:423] 2025-10-22 11:55:28,302 >> Could not locate the custom_generate/generate.py inside /home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/saves/qwen3_5vl-4b/full/sft/roboG_qwen3_vl_temporal_grounding_box_train.
[WARNING|trainer.py:906] 2025-10-22 11:55:28,345 >> The model is already on multiple devices. Skipping the move to device specified in `args`.
The model is already on multiple devices. Skipping the move to device specified in `args`.
The model is already on multiple devices. Skipping the move to device specified in `args`.
The model is already on multiple devices. Skipping the move to device specified in `args`.
[INFO|trainer.py:749] 2025-10-22 11:55:28,355 >> Using auto half precision backend
[INFO|trainer.py:4643] 2025-10-22 11:55:28,763 >> 
***** Running Prediction *****
[INFO|trainer.py:4645] 2025-10-22 11:55:28,763 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-22 11:55:28,763 >>   Batch size = 8
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/launcher.py", line 180, in <module>
[rank3]:     run_exp()
[rank3]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/tuner.py", line 142, in run_exp
[rank3]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank3]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/tuner.py", line 82, in _training_function
[rank3]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args,custom_args, callbacks)
[rank3]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/sft/workflow.py", line 165, in run_sft
[rank3]:     predict_results = trainer.predict(dataset_module["eval_dataset"], metric_key_prefix="predict", **gen_kwargs)
[rank3]:                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer_seq2seq.py", line 255, in predict
[rank3]:     return super().predict(test_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer.py", line 4567, in predict
[rank3]:     output = eval_loop(
[rank3]:              ^^^^^^^^^^
[rank3]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer.py", line 4685, in evaluation_loop
[rank3]:     losses, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)
[rank3]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/sft/trainer.py", line 272, in prediction_step
[rank3]:     loss, generated_tokens, _ = super().prediction_step(
[rank3]:                                 ^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer_seq2seq.py", line 327, in prediction_step
[rank3]:     generated_tokens = self.model.generate(**generation_inputs, **gen_kwargs)
[rank3]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank3]:     return func(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/generation/utils.py", line 2388, in generate
[rank3]:     self._validate_model_kwargs(model_kwargs.copy())
[rank3]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/generation/utils.py", line 1599, in _validate_model_kwargs
[rank3]:     raise ValueError(
[rank3]: ValueError: The following `model_kwargs` are not used by the model: ['video_metadata'] (note: typos in the generate arguments will also show up in this list)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/launcher.py", line 180, in <module>
[rank0]:     run_exp()
[rank0]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/tuner.py", line 142, in run_exp
[rank0]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank0]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/tuner.py", line 82, in _training_function
[rank0]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args,custom_args, callbacks)
[rank0]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/sft/workflow.py", line 165, in run_sft
[rank0]:     predict_results = trainer.predict(dataset_module["eval_dataset"], metric_key_prefix="predict", **gen_kwargs)
[rank0]:                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer_seq2seq.py", line 255, in predict
[rank0]:     return super().predict(test_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer.py", line 4567, in predict
[rank0]:     output = eval_loop(
[rank0]:              ^^^^^^^^^^
[rank0]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer.py", line 4685, in evaluation_loop
[rank0]:     losses, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)
[rank0]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/sft/trainer.py", line 272, in prediction_step
[rank0]:     loss, generated_tokens, _ = super().prediction_step(
[rank0]:                                 ^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer_seq2seq.py", line 327, in prediction_step
[rank0]:     generated_tokens = self.model.generate(**generation_inputs, **gen_kwargs)
[rank0]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/generation/utils.py", line 2388, in generate
[rank0]:     self._validate_model_kwargs(model_kwargs.copy())
[rank0]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/generation/utils.py", line 1599, in _validate_model_kwargs
[rank0]:     raise ValueError(
[rank0]: ValueError: The following `model_kwargs` are not used by the model: ['video_metadata'] (note: typos in the generate arguments will also show up in this list)
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/launcher.py", line 180, in <module>
[rank2]:     run_exp()
[rank2]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/tuner.py", line 142, in run_exp
[rank2]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank2]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/tuner.py", line 82, in _training_function
[rank2]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args,custom_args, callbacks)
[rank2]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/sft/workflow.py", line 165, in run_sft
[rank2]:     predict_results = trainer.predict(dataset_module["eval_dataset"], metric_key_prefix="predict", **gen_kwargs)
[rank2]:                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer_seq2seq.py", line 255, in predict
[rank2]:     return super().predict(test_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer.py", line 4567, in predict
[rank2]:     output = eval_loop(
[rank2]:              ^^^^^^^^^^
[rank2]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer.py", line 4685, in evaluation_loop
[rank2]:     losses, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)
[rank2]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/sft/trainer.py", line 272, in prediction_step
[rank2]:     loss, generated_tokens, _ = super().prediction_step(
[rank2]:                                 ^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer_seq2seq.py", line 327, in prediction_step
[rank2]:     generated_tokens = self.model.generate(**generation_inputs, **gen_kwargs)
[rank2]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank2]:     return func(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/generation/utils.py", line 2388, in generate
[rank2]:     self._validate_model_kwargs(model_kwargs.copy())
[rank2]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/generation/utils.py", line 1599, in _validate_model_kwargs
[rank2]:     raise ValueError(
[rank2]: ValueError: The following `model_kwargs` are not used by the model: ['video_metadata'] (note: typos in the generate arguments will also show up in this list)
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/launcher.py", line 180, in <module>
[rank1]:     run_exp()
[rank1]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/tuner.py", line 142, in run_exp
[rank1]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank1]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/tuner.py", line 82, in _training_function
[rank1]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args,custom_args, callbacks)
[rank1]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/sft/workflow.py", line 165, in run_sft
[rank1]:     predict_results = trainer.predict(dataset_module["eval_dataset"], metric_key_prefix="predict", **gen_kwargs)
[rank1]:                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer_seq2seq.py", line 255, in predict
[rank1]:     return super().predict(test_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer.py", line 4567, in predict
[rank1]:     output = eval_loop(
[rank1]:              ^^^^^^^^^^
[rank1]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer.py", line 4685, in evaluation_loop
[rank1]:     losses, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)
[rank1]:                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/sft/trainer.py", line 272, in prediction_step
[rank1]:     loss, generated_tokens, _ = super().prediction_step(
[rank1]:                                 ^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer_seq2seq.py", line 327, in prediction_step
[rank1]:     generated_tokens = self.model.generate(**generation_inputs, **gen_kwargs)
[rank1]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/generation/utils.py", line 2388, in generate
[rank1]:     self._validate_model_kwargs(model_kwargs.copy())
[rank1]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/generation/utils.py", line 1599, in _validate_model_kwargs
[rank1]:     raise ValueError(
[rank1]: ValueError: The following `model_kwargs` are not used by the model: ['video_metadata'] (note: typos in the generate arguments will also show up in this list)
[rank0]:[W1022 11:55:32.255679826 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
W1022 11:55:34.257000 70170 /hkfs/home/project/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 70175 closing signal SIGTERM
W1022 11:55:34.272000 70170 /hkfs/home/project/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 70176 closing signal SIGTERM
W1022 11:55:34.272000 70170 /hkfs/home/project/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 70177 closing signal SIGTERM
E1022 11:55:34.865000 70170 /hkfs/home/project/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 70174) of binary: /home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/bin/python3.12
Traceback (most recent call last):
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/bin/torchrun", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/launcher.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-22_11:55:34
  host      : hkn0814.localdomain
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 70174)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/cli.py", line 31, in <module>
    main()
  File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/cli.py", line 24, in main
    launcher.launch()
  File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/launcher.py", line 110, in launch
    process = subprocess.run(
              ^^^^^^^^^^^^^^^
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['torchrun', '--nnodes', '1', '--node_rank', '0', '--nproc_per_node', '4', '--master_addr', '127.0.0.1', '--master_port', '34217', '/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/launcher.py', 'examples/train_full/qwen3vl/qwen3vl_roboG_poc_box_qwen.yaml']' returned non-zero exit status 1.
srun: error: hkn0814: task 0: Exited with exit code 1
