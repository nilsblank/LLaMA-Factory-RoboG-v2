GpuFreq=control_disabled
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
[W1025 00:03:23.900343596 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W1025 00:03:23.900340566 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W1025 00:03:23.900344216 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W1025 00:03:23.900341695 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[INFO|tokenization_utils_base.py:2095] 2025-10-25 00:03:24,556 >> loading file vocab.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/vocab.json
[INFO|tokenization_utils_base.py:2095] 2025-10-25 00:03:24,556 >> loading file merges.txt from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/merges.txt
[INFO|tokenization_utils_base.py:2095] 2025-10-25 00:03:24,556 >> loading file tokenizer.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2025-10-25 00:03:24,556 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-10-25 00:03:24,556 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-10-25 00:03:24,556 >> loading file tokenizer_config.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2025-10-25 00:03:24,556 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2025-10-25 00:03:24,722 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:383] 2025-10-25 00:03:25,299 >> loading configuration file preprocessor_config.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/preprocessor_config.json
[INFO|image_processing_base.py:383] 2025-10-25 00:03:25,546 >> loading configuration file preprocessor_config.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/preprocessor_config.json
[INFO|image_processing_base.py:428] 2025-10-25 00:03:25,552 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "input_data_format": null,
  "max_pixels": null,
  "merge_size": 2,
  "min_pixels": null,
  "pad_size": null,
  "patch_size": 16,
  "processor_class": "Qwen3VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 16777216,
    "shortest_edge": 65536
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2095] 2025-10-25 00:03:25,807 >> loading file vocab.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/vocab.json
[INFO|tokenization_utils_base.py:2095] 2025-10-25 00:03:25,807 >> loading file merges.txt from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/merges.txt
[INFO|tokenization_utils_base.py:2095] 2025-10-25 00:03:25,807 >> loading file tokenizer.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2025-10-25 00:03:25,807 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-10-25 00:03:25,807 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-10-25 00:03:25,807 >> loading file tokenizer_config.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2025-10-25 00:03:25,807 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2025-10-25 00:03:25,962 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:726] 2025-10-25 00:03:26,326 >> loading configuration file video_preprocessor_config.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/video_preprocessor_config.json
[INFO|video_processing_utils.py:770] 2025-10-25 00:03:26,327 >> Video processor Qwen3VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": true,
  "fps": 2,
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "input_data_format": null,
  "max_frames": 768,
  "merge_size": 2,
  "min_frames": 4,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 16,
  "processor_class": "Qwen3VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 25165824,
    "shortest_edge": 4096
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen3VLVideoProcessor"
}

[INFO|processing_utils.py:1116] 2025-10-25 00:03:26,923 >> loading configuration file processor_config.json from cache at None
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1025 00:03:27.774072834 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[INFO|processing_utils.py:1199] 2025-10-25 00:03:27,197 >> Processor Qwen3VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "input_data_format": null,
  "max_pixels": null,
  "merge_size": 2,
  "min_pixels": null,
  "pad_size": null,
  "patch_size": 16,
  "processor_class": "Qwen3VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 16777216,
    "shortest_edge": 65536
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen3-VL-4B-Instruct', vocab_size=151643, model_max_length=262144, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151665: AddedToken("<tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151666: AddedToken("</tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151667: AddedToken("<think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151668: AddedToken("</think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
}
)
- video_processor: Qwen3VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": true,
  "fps": 2,
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "input_data_format": null,
  "max_frames": 768,
  "merge_size": 2,
  "min_frames": 4,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 16,
  "processor_class": "Qwen3VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 25165824,
    "shortest_edge": 4096
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen3VLVideoProcessor"
}


{
  "processor_class": "Qwen3VLProcessor"
}

/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1025 00:03:27.951849886 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1025 00:03:27.153917394 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Converting format of dataset (num_proc=128):   0%|          | 0/22808 [00:00<?, ? examples/s]Converting format of dataset (num_proc=128):   0%|          | 1/22808 [00:00<4:32:20,  1.40 examples/s]Converting format of dataset (num_proc=128):   1%|          | 169/22808 [00:00<01:20, 279.90 examples/s]Converting format of dataset (num_proc=128):   1%|▏         | 340/22808 [00:00<00:40, 553.02 examples/s]Converting format of dataset (num_proc=128):   2%|▏         | 496/22808 [00:01<00:29, 768.13 examples/s]Converting format of dataset (num_proc=128):   3%|▎         | 643/22808 [00:01<00:23, 929.55 examples/s]Converting format of dataset (num_proc=128):   3%|▎         | 795/22808 [00:01<00:20, 1072.78 examples/s]Converting format of dataset (num_proc=128):   4%|▍         | 943/22808 [00:01<00:18, 1176.86 examples/s]Converting format of dataset (num_proc=128):   5%|▍         | 1089/22808 [00:01<00:17, 1249.66 examples/s]Converting format of dataset (num_proc=128):   5%|▌         | 1240/22808 [00:01<00:16, 1320.16 examples/s]Converting format of dataset (num_proc=128):   6%|▌         | 1391/22808 [00:01<00:15, 1362.68 examples/s]Converting format of dataset (num_proc=128):   7%|▋         | 1538/22808 [00:01<00:15, 1392.74 examples/s]Converting format of dataset (num_proc=128):   7%|▋         | 1691/22808 [00:01<00:14, 1428.04 examples/s]Converting format of dataset (num_proc=128):   8%|▊         | 1845/22808 [00:01<00:14, 1457.16 examples/s]Converting format of dataset (num_proc=128):   9%|▊         | 1995/22808 [00:02<00:14, 1456.28 examples/s]Converting format of dataset (num_proc=128):   9%|▉         | 2144/22808 [00:02<00:14, 1453.59 examples/s]Converting format of dataset (num_proc=128):  10%|█         | 2300/22808 [00:02<00:13, 1481.45 examples/s]Converting format of dataset (num_proc=128):  11%|█         | 2455/22808 [00:02<00:13, 1501.41 examples/s]Converting format of dataset (num_proc=128):  11%|█▏        | 2610/22808 [00:02<00:13, 1509.31 examples/s]Converting format of dataset (num_proc=128):  12%|█▏        | 2762/22808 [00:02<00:13, 1500.05 examples/s]Converting format of dataset (num_proc=128):  13%|█▎        | 2914/22808 [00:02<00:13, 1505.33 examples/s]Converting format of dataset (num_proc=128):  13%|█▎        | 3065/22808 [00:02<00:13, 1476.86 examples/s]Converting format of dataset (num_proc=128):  14%|█▍        | 3223/22808 [00:02<00:12, 1506.73 examples/s]Converting format of dataset (num_proc=128):  15%|█▍        | 3378/22808 [00:02<00:12, 1515.90 examples/s]Converting format of dataset (num_proc=128):  15%|█▌        | 3530/22808 [00:03<00:13, 1482.69 examples/s]Converting format of dataset (num_proc=128):  16%|█▌        | 3687/22808 [00:03<00:12, 1506.47 examples/s]Converting format of dataset (num_proc=128):  17%|█▋        | 3838/22808 [00:03<00:12, 1503.07 examples/s]Converting format of dataset (num_proc=128):  17%|█▋        | 3990/22808 [00:03<00:12, 1507.26 examples/s]Converting format of dataset (num_proc=128):  18%|█▊        | 4141/22808 [00:03<00:12, 1506.50 examples/s]Converting format of dataset (num_proc=128):  19%|█▉        | 4293/22808 [00:03<00:12, 1508.88 examples/s]Converting format of dataset (num_proc=128):  20%|█▉        | 4450/22808 [00:03<00:12, 1522.76 examples/s]Converting format of dataset (num_proc=128):  20%|██        | 4603/22808 [00:03<00:12, 1513.79 examples/s]Converting format of dataset (num_proc=128):  21%|██        | 4755/22808 [00:03<00:11, 1505.21 examples/s]Converting format of dataset (num_proc=128):  22%|██▏       | 4906/22808 [00:03<00:11, 1494.73 examples/s]Converting format of dataset (num_proc=128):  22%|██▏       | 5056/22808 [00:04<00:11, 1493.57 examples/s]Converting format of dataset (num_proc=128):  23%|██▎       | 5210/22808 [00:04<00:11, 1505.23 examples/s]Converting format of dataset (num_proc=128):  24%|██▎       | 5364/22808 [00:04<00:11, 1514.40 examples/s]Converting format of dataset (num_proc=128):  24%|██▍       | 5516/22808 [00:04<00:11, 1502.93 examples/s]Converting format of dataset (num_proc=128):  25%|██▍       | 5669/22808 [00:04<00:11, 1506.18 examples/s]Converting format of dataset (num_proc=128):  26%|██▌       | 5820/22808 [00:04<00:11, 1503.00 examples/s]Converting format of dataset (num_proc=128):  26%|██▌       | 5971/22808 [00:04<00:11, 1501.09 examples/s]Converting format of dataset (num_proc=128):  27%|██▋       | 6130/22808 [00:04<00:10, 1519.21 examples/s]Converting format of dataset (num_proc=128):  28%|██▊       | 6282/22808 [00:04<00:11, 1499.27 examples/s]Converting format of dataset (num_proc=128):  28%|██▊       | 6435/22808 [00:04<00:10, 1507.73 examples/s]Converting format of dataset (num_proc=128):  29%|██▉       | 6586/22808 [00:05<00:10, 1503.92 examples/s]Converting format of dataset (num_proc=128):  30%|██▉       | 6737/22808 [00:05<00:10, 1495.35 examples/s]Converting format of dataset (num_proc=128):  30%|███       | 6895/22808 [00:05<00:10, 1516.55 examples/s]Converting format of dataset (num_proc=128):  31%|███       | 7047/22808 [00:05<00:10, 1500.85 examples/s]Converting format of dataset (num_proc=128):  32%|███▏      | 7198/22808 [00:05<00:10, 1500.78 examples/s]Converting format of dataset (num_proc=128):  32%|███▏      | 7354/22808 [00:05<00:10, 1516.97 examples/s]Converting format of dataset (num_proc=128):  33%|███▎      | 7506/22808 [00:05<00:10, 1504.12 examples/s]Converting format of dataset (num_proc=128):  34%|███▎      | 7657/22808 [00:05<00:10, 1490.36 examples/s]Converting format of dataset (num_proc=128):  34%|███▍      | 7811/22808 [00:05<00:09, 1503.70 examples/s]Converting format of dataset (num_proc=128):  35%|███▍      | 7968/22808 [00:05<00:09, 1522.54 examples/s]Converting format of dataset (num_proc=128):  36%|███▌      | 8121/22808 [00:06<00:09, 1512.47 examples/s]Converting format of dataset (num_proc=128):  36%|███▋      | 8274/22808 [00:06<00:09, 1512.55 examples/s]Converting format of dataset (num_proc=128):  37%|███▋      | 8426/22808 [00:06<00:09, 1500.08 examples/s]Converting format of dataset (num_proc=128):  38%|███▊      | 8577/22808 [00:06<00:09, 1486.65 examples/s]Converting format of dataset (num_proc=128):  38%|███▊      | 8731/22808 [00:06<00:09, 1499.24 examples/s]Converting format of dataset (num_proc=128):  39%|███▉      | 8882/22808 [00:06<00:09, 1501.63 examples/s]Converting format of dataset (num_proc=128):  40%|███▉      | 9034/22808 [00:06<00:09, 1505.90 examples/s]Converting format of dataset (num_proc=128):  40%|████      | 9190/22808 [00:06<00:08, 1520.79 examples/s]Converting format of dataset (num_proc=128):  41%|████      | 9343/22808 [00:06<00:08, 1519.95 examples/s]Converting format of dataset (num_proc=128):  42%|████▏     | 9496/22808 [00:07<00:08, 1519.04 examples/s]Converting format of dataset (num_proc=128):  42%|████▏     | 9648/22808 [00:07<00:08, 1498.30 examples/s]Converting format of dataset (num_proc=128):  43%|████▎     | 9806/22808 [00:07<00:08, 1520.67 examples/s]Converting format of dataset (num_proc=128):  44%|████▎     | 9959/22808 [00:07<00:08, 1516.01 examples/s]Converting format of dataset (num_proc=128):  44%|████▍     | 10114/22808 [00:07<00:08, 1521.05 examples/s]Converting format of dataset (num_proc=128):  45%|████▌     | 10267/22808 [00:07<00:08, 1512.35 examples/s]Converting format of dataset (num_proc=128):  46%|████▌     | 10419/22808 [00:07<00:08, 1498.56 examples/s]Converting format of dataset (num_proc=128):  46%|████▋     | 10569/22808 [00:07<00:08, 1487.41 examples/s]Converting format of dataset (num_proc=128):  47%|████▋     | 10730/22808 [00:07<00:07, 1519.80 examples/s]Converting format of dataset (num_proc=128):  48%|████▊     | 10883/22808 [00:07<00:07, 1522.20 examples/s]Converting format of dataset (num_proc=128):  48%|████▊     | 11036/22808 [00:08<00:07, 1520.98 examples/s]Converting format of dataset (num_proc=128):  49%|████▉     | 11190/22808 [00:08<00:07, 1522.90 examples/s]Converting format of dataset (num_proc=128):  50%|████▉     | 11348/22808 [00:08<00:07, 1532.22 examples/s]Converting format of dataset (num_proc=128):  50%|█████     | 11502/22808 [00:08<00:07, 1519.56 examples/s]Converting format of dataset (num_proc=128):  51%|█████     | 11656/22808 [00:08<00:07, 1521.50 examples/s]Converting format of dataset (num_proc=128):  52%|█████▏    | 11809/22808 [00:08<00:07, 1516.50 examples/s]Converting format of dataset (num_proc=128):  52%|█████▏    | 11961/22808 [00:08<00:07, 1495.25 examples/s]Converting format of dataset (num_proc=128):  53%|█████▎    | 12118/22808 [00:08<00:07, 1511.10 examples/s]Converting format of dataset (num_proc=128):  54%|█████▍    | 12272/22808 [00:08<00:06, 1519.15 examples/s]Converting format of dataset (num_proc=128):  54%|█████▍    | 12424/22808 [00:08<00:06, 1513.95 examples/s]Converting format of dataset (num_proc=128):  55%|█████▌    | 12578/22808 [00:09<00:06, 1521.15 examples/s]Converting format of dataset (num_proc=128):  56%|█████▌    | 12732/22808 [00:09<00:06, 1525.95 examples/s]Converting format of dataset (num_proc=128):  56%|█████▋    | 12885/22808 [00:09<00:06, 1523.20 examples/s]Converting format of dataset (num_proc=128):  57%|█████▋    | 13039/22808 [00:09<00:06, 1527.89 examples/s]Converting format of dataset (num_proc=128):  58%|█████▊    | 13195/22808 [00:09<00:06, 1530.86 examples/s]Converting format of dataset (num_proc=128):  59%|█████▊    | 13349/22808 [00:09<00:06, 1513.96 examples/s]Converting format of dataset (num_proc=128):  59%|█████▉    | 13501/22808 [00:09<00:06, 1490.27 examples/s]Converting format of dataset (num_proc=128):  60%|█████▉    | 13657/22808 [00:09<00:06, 1509.92 examples/s]Converting format of dataset (num_proc=128):  61%|██████    | 13813/22808 [00:09<00:05, 1520.26 examples/s]Converting format of dataset (num_proc=128):  61%|██████▏   | 13973/22808 [00:09<00:05, 1537.63 examples/s]Converting format of dataset (num_proc=128):  62%|██████▏   | 14127/22808 [00:10<00:05, 1519.62 examples/s]Converting format of dataset (num_proc=128):  63%|██████▎   | 14280/22808 [00:10<00:05, 1517.45 examples/s]Converting format of dataset (num_proc=128):  63%|██████▎   | 14436/22808 [00:10<00:05, 1529.70 examples/s]Converting format of dataset (num_proc=128):  64%|██████▍   | 14590/22808 [00:10<00:05, 1517.28 examples/s]Converting format of dataset (num_proc=128):  65%|██████▍   | 14742/22808 [00:10<00:05, 1497.11 examples/s]Converting format of dataset (num_proc=128):  65%|██████▌   | 14897/22808 [00:10<00:05, 1509.78 examples/s]Converting format of dataset (num_proc=128):  66%|██████▌   | 15051/22808 [00:10<00:05, 1515.33 examples/s]Converting format of dataset (num_proc=128):  67%|██████▋   | 15204/22808 [00:10<00:05, 1518.31 examples/s]Converting format of dataset (num_proc=128):  67%|██████▋   | 15356/22808 [00:10<00:04, 1493.61 examples/s]Converting format of dataset (num_proc=128):  68%|██████▊   | 15507/22808 [00:10<00:04, 1497.06 examples/s]Converting format of dataset (num_proc=128):  69%|██████▊   | 15673/22808 [00:11<00:04, 1544.61 examples/s]Converting format of dataset (num_proc=128):  69%|██████▉   | 15828/22808 [00:11<00:04, 1506.60 examples/s]Converting format of dataset (num_proc=128):  70%|███████   | 15986/22808 [00:11<00:04, 1527.93 examples/s]Converting format of dataset (num_proc=128):  71%|███████   | 16143/22808 [00:11<00:04, 1537.21 examples/s]Converting format of dataset (num_proc=128):  71%|███████▏  | 16297/22808 [00:11<00:04, 1537.68 examples/s]Converting format of dataset (num_proc=128):  72%|███████▏  | 16453/22808 [00:11<00:04, 1541.38 examples/s]Converting format of dataset (num_proc=128):  73%|███████▎  | 16608/22808 [00:11<00:04, 1530.29 examples/s]Converting format of dataset (num_proc=128):  74%|███████▎  | 16766/22808 [00:11<00:03, 1541.96 examples/s]Converting format of dataset (num_proc=128):  74%|███████▍  | 16921/22808 [00:11<00:03, 1507.33 examples/s]Converting format of dataset (num_proc=128):  75%|███████▍  | 17079/22808 [00:12<00:03, 1526.26 examples/s]Converting format of dataset (num_proc=128):  76%|███████▌  | 17233/22808 [00:12<00:03, 1525.98 examples/s]Converting format of dataset (num_proc=128):  76%|███████▌  | 17391/22808 [00:12<00:03, 1537.00 examples/s]Converting format of dataset (num_proc=128):  77%|███████▋  | 17545/22808 [00:12<00:03, 1536.14 examples/s]Converting format of dataset (num_proc=128):  78%|███████▊  | 17699/22808 [00:12<00:03, 1499.31 examples/s]Converting format of dataset (num_proc=128):  78%|███████▊  | 17854/22808 [00:12<00:03, 1509.92 examples/s]Converting format of dataset (num_proc=128):  79%|███████▉  | 18007/22808 [00:12<00:03, 1514.87 examples/s]Converting format of dataset (num_proc=128):  80%|███████▉  | 18163/22808 [00:12<00:03, 1526.16 examples/s]Converting format of dataset (num_proc=128):  80%|████████  | 18316/22808 [00:12<00:02, 1524.44 examples/s]Converting format of dataset (num_proc=128):  81%|████████  | 18469/22808 [00:12<00:02, 1518.23 examples/s]Converting format of dataset (num_proc=128):  82%|████████▏ | 18621/22808 [00:13<00:02, 1514.51 examples/s]Converting format of dataset (num_proc=128):  82%|████████▏ | 18773/22808 [00:13<00:02, 1514.10 examples/s]Converting format of dataset (num_proc=128):  83%|████████▎ | 18931/22808 [00:13<00:02, 1528.50 examples/s]Converting format of dataset (num_proc=128):  84%|████████▎ | 19084/22808 [00:13<00:02, 1522.40 examples/s]Converting format of dataset (num_proc=128):  84%|████████▍ | 19244/22808 [00:13<00:02, 1545.16 examples/s]Converting format of dataset (num_proc=128):  85%|████████▌ | 19399/22808 [00:13<00:02, 1516.25 examples/s]Converting format of dataset (num_proc=128):  86%|████████▌ | 19551/22808 [00:13<00:02, 1506.09 examples/s]Converting format of dataset (num_proc=128):  86%|████████▋ | 19714/22808 [00:13<00:02, 1523.10 examples/s]Converting format of dataset (num_proc=128):  87%|████████▋ | 19868/22808 [00:13<00:01, 1526.73 examples/s]Converting format of dataset (num_proc=128):  88%|████████▊ | 20021/22808 [00:13<00:01, 1503.34 examples/s]Converting format of dataset (num_proc=128):  88%|████████▊ | 20174/22808 [00:14<00:01, 1502.57 examples/s]Converting format of dataset (num_proc=128):  89%|████████▉ | 20342/22808 [00:14<00:01, 1553.64 examples/s]Converting format of dataset (num_proc=128):  90%|████████▉ | 20499/22808 [00:14<00:01, 1524.07 examples/s]Converting format of dataset (num_proc=128):  91%|█████████ | 20656/22808 [00:14<00:01, 1533.15 examples/s]Converting format of dataset (num_proc=128):  91%|█████████ | 20810/22808 [00:14<00:01, 1515.54 examples/s]Converting format of dataset (num_proc=128):  92%|█████████▏| 20967/22808 [00:14<00:01, 1523.61 examples/s]Converting format of dataset (num_proc=128):  93%|█████████▎| 21120/22808 [00:14<00:01, 1510.70 examples/s]Converting format of dataset (num_proc=128):  93%|█████████▎| 21274/22808 [00:14<00:01, 1516.61 examples/s]Converting format of dataset (num_proc=128):  94%|█████████▍| 21434/22808 [00:14<00:00, 1539.37 examples/s]Converting format of dataset (num_proc=128):  95%|█████████▍| 21589/22808 [00:14<00:00, 1539.90 examples/s]Converting format of dataset (num_proc=128):  95%|█████████▌| 21744/22808 [00:15<00:00, 1530.85 examples/s]Converting format of dataset (num_proc=128):  96%|█████████▌| 21898/22808 [00:15<00:00, 1520.34 examples/s]Converting format of dataset (num_proc=128):  97%|█████████▋| 22057/22808 [00:15<00:00, 1533.54 examples/s]Converting format of dataset (num_proc=128):  97%|█████████▋| 22211/22808 [00:15<00:00, 1512.73 examples/s]Converting format of dataset (num_proc=128):  98%|█████████▊| 22363/22808 [00:15<00:00, 1511.94 examples/s]Converting format of dataset (num_proc=128):  99%|█████████▊| 22520/22808 [00:15<00:00, 1519.47 examples/s]Converting format of dataset (num_proc=128):  99%|█████████▉| 22675/22808 [00:15<00:00, 1525.98 examples/s]Converting format of dataset (num_proc=128): 100%|██████████| 22808/22808 [00:23<00:00, 962.53 examples/s] 
num_proc must be <= 47. Reducing num_proc to 47 for dataset of size 47.
Converting format of dataset (num_proc=47):   0%|          | 0/47 [00:00<?, ? examples/s]Converting format of dataset (num_proc=47):  26%|██▌       | 12/47 [00:00<00:00, 57.21 examples/s]Converting format of dataset (num_proc=47):  38%|███▊      | 18/47 [00:00<00:01, 15.68 examples/s]Converting format of dataset (num_proc=47): 100%|██████████| 47/47 [00:01<00:00, 36.73 examples/s]
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1025 00:03:56.169759032 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
num_proc must be <= 47. Reducing num_proc to 47 for dataset of size 47.
num_proc must be <= 47. Reducing num_proc to 47 for dataset of size 47.
num_proc must be <= 47. Reducing num_proc to 47 for dataset of size 47.
Running tokenizer on dataset (num_proc=128):   0%|          | 0/22808 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=128):   1%|          | 179/22808 [00:44<1:33:57,  4.01 examples/s]Running tokenizer on dataset (num_proc=128):   2%|▏         | 358/22808 [00:44<38:41,  9.67 examples/s]  Running tokenizer on dataset (num_proc=128):   2%|▏         | 537/22808 [00:45<21:17, 17.43 examples/s]Running tokenizer on dataset (num_proc=128):   3%|▎         | 716/22808 [00:45<12:58, 28.40 examples/s]Running tokenizer on dataset (num_proc=128):   4%|▍         | 895/22808 [00:45<08:22, 43.64 examples/s]Running tokenizer on dataset (num_proc=128):   5%|▌         | 1251/22808 [00:47<04:49, 74.56 examples/s]Running tokenizer on dataset (num_proc=128):   6%|▋         | 1429/22808 [00:47<03:52, 91.77 examples/s]Running tokenizer on dataset (num_proc=128):   7%|▋         | 1608/22808 [00:48<02:59, 117.90 examples/s]Running tokenizer on dataset (num_proc=128):   8%|▊         | 1786/22808 [00:48<02:15, 155.18 examples/s]Running tokenizer on dataset (num_proc=128):   9%|▉         | 2144/22808 [00:48<01:21, 253.78 examples/s]Running tokenizer on dataset (num_proc=128):  11%|█         | 2501/22808 [00:49<00:56, 358.55 examples/s]Running tokenizer on dataset (num_proc=128):  12%|█▏        | 2679/22808 [00:49<00:48, 416.20 examples/s]Running tokenizer on dataset (num_proc=128):  13%|█▎        | 3036/22808 [00:49<00:34, 574.10 examples/s]Running tokenizer on dataset (num_proc=128):  14%|█▍        | 3215/22808 [00:50<00:36, 534.27 examples/s]Running tokenizer on dataset (num_proc=128):  16%|█▌        | 3571/22808 [00:50<00:27, 705.90 examples/s]Running tokenizer on dataset (num_proc=128):  16%|█▋        | 3750/22808 [00:50<00:25, 757.22 examples/s]Running tokenizer on dataset (num_proc=128):  19%|█▉        | 4286/22808 [00:50<00:15, 1179.08 examples/s]Running tokenizer on dataset (num_proc=128):  20%|██        | 4642/22808 [00:51<00:20, 886.62 examples/s] Running tokenizer on dataset (num_proc=128):  25%|██▌       | 5710/22808 [00:51<00:09, 1848.19 examples/s]Running tokenizer on dataset (num_proc=128):  27%|██▋       | 6245/22808 [00:52<00:14, 1141.32 examples/s]Running tokenizer on dataset (num_proc=128):  31%|███       | 6961/22808 [00:52<00:13, 1136.07 examples/s]Running tokenizer on dataset (num_proc=128):  39%|███▉      | 8920/22808 [00:53<00:05, 2458.96 examples/s]Running tokenizer on dataset (num_proc=128):  42%|████▏     | 9635/22808 [00:54<00:09, 1341.32 examples/s]Running tokenizer on dataset (num_proc=128):  48%|████▊     | 11060/22808 [00:54<00:05, 2028.61 examples/s]Running tokenizer on dataset (num_proc=128):  52%|█████▏    | 11772/22808 [00:55<00:06, 1681.60 examples/s]Running tokenizer on dataset (num_proc=128):  54%|█████▍    | 12306/22808 [00:55<00:07, 1413.42 examples/s]Running tokenizer on dataset (num_proc=128):  56%|█████▋    | 12840/22808 [00:56<00:07, 1336.99 examples/s]Running tokenizer on dataset (num_proc=128):  62%|██████▏   | 14086/22808 [00:57<00:06, 1248.51 examples/s]Running tokenizer on dataset (num_proc=128):  71%|███████   | 16222/22808 [00:57<00:03, 2093.21 examples/s]Running tokenizer on dataset (num_proc=128):  73%|███████▎  | 16578/22808 [00:59<00:05, 1087.07 examples/s]Running tokenizer on dataset (num_proc=128):  95%|█████████▍| 21562/22808 [00:59<00:00, 3226.32 examples/s]Running tokenizer on dataset (num_proc=128): 100%|██████████| 22808/22808 [01:03<00:00, 361.81 examples/s] 
num_proc must be <= 47. Reducing num_proc to 47 for dataset of size 47.
Running tokenizer on dataset (num_proc=47):   0%|          | 0/47 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=47):   2%|▏         | 1/47 [00:00<00:28,  1.62 examples/s]Running tokenizer on dataset (num_proc=47):   4%|▍         | 2/47 [00:00<00:15,  2.92 examples/s]Running tokenizer on dataset (num_proc=47):  13%|█▎        | 6/47 [00:01<00:08,  5.11 examples/s]Running tokenizer on dataset (num_proc=47):  36%|███▌      | 17/47 [00:01<00:01, 17.35 examples/s]Running tokenizer on dataset (num_proc=47):  45%|████▍     | 21/47 [00:01<00:01, 19.02 examples/s]Running tokenizer on dataset (num_proc=47):  53%|█████▎    | 25/47 [00:01<00:01, 18.85 examples/s]Running tokenizer on dataset (num_proc=47):  60%|█████▉    | 28/47 [00:02<00:01, 15.22 examples/s]Running tokenizer on dataset (num_proc=47):  68%|██████▊   | 32/47 [00:02<00:01, 13.37 examples/s]Running tokenizer on dataset (num_proc=47):  79%|███████▊  | 37/47 [00:03<00:00, 11.72 examples/s]Running tokenizer on dataset (num_proc=47): 100%|██████████| 47/47 [00:03<00:00, 14.43 examples/s]
[INFO|configuration_utils.py:765] 2025-10-25 00:05:10,698 >> loading configuration file config.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/config.json
[INFO|configuration_utils.py:839] 2025-10-25 00:05:10,708 >> Model config Qwen3VLConfig {
  "architectures": [
    "Qwen3VLForConditionalGeneration"
  ],
  "image_token_id": 151655,
  "model_type": "qwen3_vl",
  "text_config": {
    "attention_bias": false,
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "dtype": "bfloat16",
    "eos_token_id": 151645,
    "head_dim": 128,
    "hidden_act": "silu",
    "hidden_size": 2560,
    "initializer_range": 0.02,
    "intermediate_size": 9728,
    "max_position_embeddings": 262144,
    "model_type": "qwen3_vl_text",
    "num_attention_heads": 32,
    "num_hidden_layers": 36,
    "num_key_value_heads": 8,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_interleaved": true,
      "mrope_section": [
        24,
        20,
        20
      ],
      "rope_type": "default"
    },
    "rope_theta": 5000000,
    "tie_word_embeddings": true,
    "use_cache": true,
    "vocab_size": 151936
  },
  "tie_word_embeddings": true,
  "transformers_version": "4.57.1",
  "video_token_id": 151656,
  "vision_config": {
    "deepstack_visual_indexes": [
      5,
      11,
      17
    ],
    "depth": 24,
    "hidden_act": "gelu_pytorch_tanh",
    "hidden_size": 1024,
    "in_channels": 3,
    "initializer_range": 0.02,
    "intermediate_size": 4096,
    "model_type": "qwen3_vl",
    "num_heads": 16,
    "num_position_embeddings": 2304,
    "out_hidden_size": 2560,
    "patch_size": 16,
    "spatial_merge_size": 2,
    "temporal_patch_size": 2
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652
}

num_proc must be <= 47. Reducing num_proc to 47 for dataset of size 47.
num_proc must be <= 47. Reducing num_proc to 47 for dataset of size 47.
num_proc must be <= 47. Reducing num_proc to 47 for dataset of size 47.
[WARNING|logging.py:328] 2025-10-25 00:05:11,090 >> `torch_dtype` is deprecated! Use `dtype` instead!
[INFO|modeling_utils.py:1172] 2025-10-25 00:05:11,091 >> loading weights file model.safetensors from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/model.safetensors.index.json
[INFO|modeling_utils.py:2341] 2025-10-25 00:05:11,094 >> Instantiating Qwen3VLForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:986] 2025-10-25 00:05:11,102 >> Generate config GenerationConfig {
  "use_cache": false
}

[INFO|modeling_utils.py:2341] 2025-10-25 00:05:11,106 >> Instantiating Qwen3VLVisionModel model under default dtype torch.bfloat16.
`torch_dtype` is deprecated! Use `dtype` instead!
[INFO|modeling_utils.py:2341] 2025-10-25 00:05:11,185 >> Instantiating Qwen3VLTextModel model under default dtype torch.bfloat16.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:16<00:16, 16.22s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:15<00:15, 15.96s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:15<00:15, 15.96s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:15<00:15, 15.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.44s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:29<00:00, 14.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.37s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:29<00:00, 14.59s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.45s/it]
[INFO|configuration_utils.py:941] 2025-10-25 00:05:40,611 >> loading configuration file generation_config.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/generation_config.json
[INFO|configuration_utils.py:986] 2025-10-25 00:05:40,611 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.7,
  "top_k": 20,
  "top_p": 0.8
}

[INFO|dynamic_module_utils.py:423] 2025-10-25 00:05:40,732 >> Could not locate the custom_generate/generate.py inside Qwen/Qwen3-VL-4B-Instruct.
The model is already on multiple devices. Skipping the move to device specified in `args`.
The model is already on multiple devices. Skipping the move to device specified in `args`.
[WARNING|trainer.py:906] 2025-10-25 00:05:40,751 >> The model is already on multiple devices. Skipping the move to device specified in `args`.
The model is already on multiple devices. Skipping the move to device specified in `args`.
[INFO|trainer.py:749] 2025-10-25 00:05:40,775 >> Using auto half precision backend
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 151645, 'bos_token_id': None, 'pad_token_id': 151643}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 151645, 'bos_token_id': None, 'pad_token_id': 151643}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 151645, 'bos_token_id': None, 'pad_token_id': 151643}.
[WARNING|trainer.py:982] 2025-10-25 00:05:41,095 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 151645, 'bos_token_id': None, 'pad_token_id': 151643}.
[INFO|trainer.py:2519] 2025-10-25 00:05:41,664 >> ***** Running training *****
[INFO|trainer.py:2520] 2025-10-25 00:05:41,664 >>   Num examples = 22,808
[INFO|trainer.py:2521] 2025-10-25 00:05:41,664 >>   Num Epochs = 3
[INFO|trainer.py:2522] 2025-10-25 00:05:41,664 >>   Instantaneous batch size per device = 16
[INFO|trainer.py:2525] 2025-10-25 00:05:41,664 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:2526] 2025-10-25 00:05:41,664 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:2527] 2025-10-25 00:05:41,664 >>   Total optimization steps = 1,071
[INFO|trainer.py:2528] 2025-10-25 00:05:41,666 >>   Number of trainable parameters = 4,106,660,864
[INFO|integration_utils.py:867] 2025-10-25 00:05:41,667 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: niblank to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.22.0
wandb: Run data is saved locally in /hkfs/home/project/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/wandb/run-20251025_000542-hk5s6wug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Qwen/Qwen3-VL-4B-Instruct_roboG_stagepoc_ablation_multi_frame_8_train_sft
wandb: ⭐️ View project at https://wandb.ai/niblank/llamafactory
wandb: 🚀 View run at https://wandb.ai/niblank/llamafactory/runs/hk5s6wug
  0%|          | 0/1071 [00:00<?, ?it/s]  0%|          | 1/1071 [00:06<2:01:12,  6.80s/it]  0%|          | 2/1071 [00:08<1:12:09,  4.05s/it]  0%|          | 3/1071 [00:10<55:08,  3.10s/it]    0%|          | 4/1071 [00:12<47:14,  2.66s/it]  0%|          | 5/1071 [00:14<42:46,  2.41s/it]  1%|          | 6/1071 [00:16<40:05,  2.26s/it]  1%|          | 7/1071 [00:18<38:22,  2.16s/it]  1%|          | 8/1071 [00:20<37:15,  2.10s/it]  1%|          | 9/1071 [00:22<36:28,  2.06s/it]  1%|          | 10/1071 [00:24<35:52,  2.03s/it]                                                   1%|          | 10/1071 [00:24<35:52,  2.03s/it]  1%|          | 11/1071 [00:26<35:34,  2.01s/it]  1%|          | 12/1071 [00:28<35:19,  2.00s/it]  1%|          | 13/1071 [00:30<35:06,  1.99s/it]  1%|▏         | 14/1071 [00:32<34:54,  1.98s/it]  1%|▏         | 15/1071 [00:34<34:49,  1.98s/it]  1%|▏         | 16/1071 [00:36<34:42,  1.97s/it]  2%|▏         | 17/1071 [00:38<34:38,  1.97s/it]  2%|▏         | 18/1071 [00:40<34:32,  1.97s/it]  2%|▏         | 19/1071 [00:42<34:29,  1.97s/it]  2%|▏         | 20/1071 [00:44<34:28,  1.97s/it]                                                   2%|▏         | 20/1071 [00:44<34:28,  1.97s/it]  2%|▏         | 21/1071 [00:46<34:26,  1.97s/it]  2%|▏         | 22/1071 [00:48<34:23,  1.97s/it]  2%|▏         | 23/1071 [00:50<34:22,  1.97s/it]  2%|▏         | 24/1071 [00:52<34:20,  1.97s/it]  2%|▏         | 25/1071 [00:54<34:22,  1.97s/it]  2%|▏         | 26/1071 [00:56<34:20,  1.97s/it]  3%|▎         | 27/1071 [00:58<34:15,  1.97s/it]  3%|▎         | 28/1071 [01:00<34:16,  1.97s/it]  3%|▎         | 29/1071 [01:02<34:15,  1.97s/it]  3%|▎         | 30/1071 [01:04<34:10,  1.97s/it]                                                   3%|▎         | 30/1071 [01:04<34:10,  1.97s/it]  3%|▎         | 31/1071 [01:06<34:09,  1.97s/it]  3%|▎         | 32/1071 [01:07<34:07,  1.97s/it]  3%|▎         | 33/1071 [01:09<34:06,  1.97s/it]  3%|▎         | 34/1071 [01:11<34:03,  1.97s/it]  3%|▎         | 35/1071 [01:13<34:05,  1.97s/it]  3%|▎         | 36/1071 [01:15<34:02,  1.97s/it]  3%|▎         | 37/1071 [01:17<33:59,  1.97s/it]  4%|▎         | 38/1071 [01:19<33:59,  1.97s/it]  4%|▎         | 39/1071 [01:21<33:59,  1.98s/it]  4%|▎         | 40/1071 [01:23<33:58,  1.98s/it]                                                   4%|▎         | 40/1071 [01:23<33:58,  1.98s/it]  4%|▍         | 41/1071 [01:25<33:54,  1.97s/it]  4%|▍         | 42/1071 [01:27<33:51,  1.97s/it]  4%|▍         | 43/1071 [01:29<33:47,  1.97s/it]  4%|▍         | 44/1071 [01:31<33:48,  1.98s/it]  4%|▍         | 45/1071 [01:33<33:46,  1.98s/it]  4%|▍         | 46/1071 [01:35<33:44,  1.98s/it]  4%|▍         | 47/1071 [01:37<33:41,  1.97s/it]  4%|▍         | 48/1071 [01:39<33:39,  1.97s/it]  5%|▍         | 49/1071 [01:41<33:35,  1.97s/it]  5%|▍         | 50/1071 [01:43<33:31,  1.97s/it]                                                   5%|▍         | 50/1071 [01:43<33:31,  1.97s/it]  5%|▍         | 51/1071 [01:45<33:29,  1.97s/it]  5%|▍         | 52/1071 [01:47<33:27,  1.97s/it]  5%|▍         | 53/1071 [01:49<33:28,  1.97s/it]  5%|▌         | 54/1071 [01:51<33:27,  1.97s/it]  5%|▌         | 55/1071 [01:53<33:22,  1.97s/it]  5%|▌         | 56/1071 [01:55<33:21,  1.97s/it]  5%|▌         | 57/1071 [01:57<33:22,  1.97s/it]  5%|▌         | 58/1071 [01:59<33:20,  1.97s/it]  6%|▌         | 59/1071 [02:01<33:20,  1.98s/it]  6%|▌         | 60/1071 [02:03<33:13,  1.97s/it]                                                   6%|▌         | 60/1071 [02:03<33:13,  1.97s/it]  6%|▌         | 61/1071 [02:05<33:14,  1.97s/it]  6%|▌         | 62/1071 [02:07<33:09,  1.97s/it]  6%|▌         | 63/1071 [02:09<33:11,  1.98s/it]  6%|▌         | 64/1071 [02:11<33:08,  1.98s/it]  6%|▌         | 65/1071 [02:13<33:06,  1.97s/it]  6%|▌         | 66/1071 [02:15<33:04,  1.97s/it]  6%|▋         | 67/1071 [02:17<33:01,  1.97s/it]  6%|▋         | 68/1071 [02:19<33:02,  1.98s/it]  6%|▋         | 69/1071 [02:21<32:57,  1.97s/it]  7%|▋         | 70/1071 [02:23<32:58,  1.98s/it]                                                   7%|▋         | 70/1071 [02:23<32:58,  1.98s/it]  7%|▋         | 71/1071 [02:24<32:55,  1.98s/it]  7%|▋         | 72/1071 [02:26<32:54,  1.98s/it]  7%|▋         | 73/1071 [02:28<32:50,  1.97s/it]  7%|▋         | 74/1071 [02:30<32:48,  1.97s/it]  7%|▋         | 75/1071 [02:32<32:47,  1.98s/it]  7%|▋         | 76/1071 [02:34<32:45,  1.97s/it]  7%|▋         | 77/1071 [02:36<32:41,  1.97s/it]  7%|▋         | 78/1071 [02:38<32:38,  1.97s/it]  7%|▋         | 79/1071 [02:40<32:36,  1.97s/it]  7%|▋         | 80/1071 [02:42<32:34,  1.97s/it]                                                   7%|▋         | 80/1071 [02:42<32:34,  1.97s/it]  8%|▊         | 81/1071 [02:44<32:33,  1.97s/it]  8%|▊         | 82/1071 [02:46<32:31,  1.97s/it]  8%|▊         | 83/1071 [02:48<32:28,  1.97s/it]  8%|▊         | 84/1071 [02:50<32:29,  1.97s/it]  8%|▊         | 85/1071 [02:52<32:26,  1.97s/it]  8%|▊         | 86/1071 [02:54<32:29,  1.98s/it]  8%|▊         | 87/1071 [02:56<32:26,  1.98s/it]  8%|▊         | 88/1071 [02:58<32:26,  1.98s/it]  8%|▊         | 89/1071 [03:00<32:24,  1.98s/it]  8%|▊         | 90/1071 [03:02<32:20,  1.98s/it]                                                   8%|▊         | 90/1071 [03:02<32:20,  1.98s/it]  8%|▊         | 91/1071 [03:04<32:20,  1.98s/it]  9%|▊         | 92/1071 [03:06<32:20,  1.98s/it]  9%|▊         | 93/1071 [03:08<32:18,  1.98s/it]  9%|▉         | 94/1071 [03:10<32:14,  1.98s/it]  9%|▉         | 95/1071 [03:12<32:14,  1.98s/it]  9%|▉         | 96/1071 [03:14<32:13,  1.98s/it]  9%|▉         | 97/1071 [03:16<32:13,  1.98s/it]  9%|▉         | 98/1071 [03:18<32:09,  1.98s/it]  9%|▉         | 99/1071 [03:20<32:07,  1.98s/it]  9%|▉         | 100/1071 [03:22<32:06,  1.98s/it]                                                    9%|▉         | 100/1071 [03:22<32:06,  1.98s/it][INFO|trainer.py:4643] 2025-10-25 00:09:07,864 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-25 00:09:07,865 >>   Num examples = 47
[INFO|trainer.py:4648] 2025-10-25 00:09:07,865 >>   Batch size = 8

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|██████████| 2/2 [00:00<00:00,  5.43it/s][A                                                  
                                             [A  9%|▉         | 100/1071 [03:24<32:06,  1.98s/it]
100%|██████████| 2/2 [00:00<00:00,  5.43it/s][A
                                             [A  9%|▉         | 101/1071 [03:26<42:34,  2.63s/it] 10%|▉         | 102/1071 [03:28<39:20,  2.44s/it] 10%|▉         | 103/1071 [03:30<37:03,  2.30s/it] 10%|▉         | 104/1071 [03:32<35:36,  2.21s/it] 10%|▉         | 105/1071 [03:34<34:27,  2.14s/it] 10%|▉         | 106/1071 [03:36<33:38,  2.09s/it] 10%|▉         | 107/1071 [03:38<33:03,  2.06s/it] 10%|█         | 108/1071 [03:40<32:37,  2.03s/it] 10%|█         | 109/1071 [03:42<32:19,  2.02s/it] 10%|█         | 110/1071 [03:44<32:07,  2.01s/it]                                                   10%|█         | 110/1071 [03:44<32:07,  2.01s/it] 10%|█         | 111/1071 [03:46<31:58,  2.00s/it] 10%|█         | 112/1071 [03:48<31:51,  1.99s/it] 11%|█         | 113/1071 [03:50<31:44,  1.99s/it] 11%|█         | 114/1071 [03:52<31:38,  1.98s/it] 11%|█         | 115/1071 [03:54<31:34,  1.98s/it] 11%|█         | 116/1071 [03:56<31:30,  1.98s/it] 11%|█         | 117/1071 [03:58<31:25,  1.98s/it] 11%|█         | 118/1071 [04:00<31:21,  1.97s/it] 11%|█         | 119/1071 [04:02<31:21,  1.98s/it] 11%|█         | 120/1071 [04:04<31:19,  1.98s/it]                                                   11%|█         | 120/1071 [04:04<31:19,  1.98s/it] 11%|█▏        | 121/1071 [04:06<31:16,  1.98s/it] 11%|█▏        | 122/1071 [04:08<31:15,  1.98s/it] 11%|█▏        | 123/1071 [04:10<31:11,  1.97s/it] 12%|█▏        | 124/1071 [04:11<31:09,  1.97s/it] 12%|█▏        | 125/1071 [04:13<31:07,  1.97s/it] 12%|█▏        | 126/1071 [04:15<31:04,  1.97s/it] 12%|█▏        | 127/1071 [04:17<31:01,  1.97s/it] 12%|█▏        | 128/1071 [04:19<31:01,  1.97s/it] 12%|█▏        | 129/1071 [04:21<31:01,  1.98s/it] 12%|█▏        | 130/1071 [04:23<30:56,  1.97s/it]                                                   12%|█▏        | 130/1071 [04:23<30:56,  1.97s/it] 12%|█▏        | 131/1071 [04:25<30:55,  1.97s/it] 12%|█▏        | 132/1071 [04:27<30:52,  1.97s/it] 12%|█▏        | 133/1071 [04:29<30:53,  1.98s/it] 13%|█▎        | 134/1071 [04:31<30:54,  1.98s/it] 13%|█▎        | 135/1071 [04:33<30:48,  1.98s/it] 13%|█▎        | 136/1071 [04:35<30:46,  1.97s/it] 13%|█▎        | 137/1071 [04:37<30:44,  1.98s/it] 13%|█▎        | 138/1071 [04:39<30:42,  1.97s/it] 13%|█▎        | 139/1071 [04:41<30:41,  1.98s/it] 13%|█▎        | 140/1071 [04:43<30:38,  1.97s/it]                                                   13%|█▎        | 140/1071 [04:43<30:38,  1.97s/it] 13%|█▎        | 141/1071 [04:45<30:35,  1.97s/it] 13%|█▎        | 142/1071 [04:47<30:35,  1.98s/it] 13%|█▎        | 143/1071 [04:49<30:31,  1.97s/it] 13%|█▎        | 144/1071 [04:51<30:29,  1.97s/it] 14%|█▎        | 145/1071 [04:53<30:27,  1.97s/it] 14%|█▎        | 146/1071 [04:55<30:26,  1.97s/it] 14%|█▎        | 147/1071 [04:57<30:24,  1.97s/it] 14%|█▍        | 148/1071 [04:59<30:21,  1.97s/it] 14%|█▍        | 149/1071 [05:01<30:25,  1.98s/it] 14%|█▍        | 150/1071 [05:03<30:21,  1.98s/it]                                                   14%|█▍        | 150/1071 [05:03<30:21,  1.98s/it] 14%|█▍        | 151/1071 [05:05<30:20,  1.98s/it] 14%|█▍        | 152/1071 [05:07<30:17,  1.98s/it] 14%|█▍        | 153/1071 [05:09<30:14,  1.98s/it] 14%|█▍        | 154/1071 [05:11<30:12,  1.98s/it] 14%|█▍        | 155/1071 [05:13<30:09,  1.98s/it] 15%|█▍        | 156/1071 [05:15<30:07,  1.98s/it] 15%|█▍        | 157/1071 [05:17<30:05,  1.98s/it] 15%|█▍        | 158/1071 [05:19<30:07,  1.98s/it] 15%|█▍        | 159/1071 [05:21<30:05,  1.98s/it] 15%|█▍        | 160/1071 [05:23<30:02,  1.98s/it]                                                   15%|█▍        | 160/1071 [05:23<30:02,  1.98s/it] 15%|█▌        | 161/1071 [05:25<30:05,  1.98s/it] 15%|█▌        | 162/1071 [05:27<30:01,  1.98s/it] 15%|█▌        | 163/1071 [05:29<30:00,  1.98s/it] 15%|█▌        | 164/1071 [05:31<29:55,  1.98s/it] 15%|█▌        | 165/1071 [05:33<29:51,  1.98s/it] 15%|█▌        | 166/1071 [05:34<29:46,  1.97s/it] 16%|█▌        | 167/1071 [05:36<29:45,  1.98s/it] 16%|█▌        | 168/1071 [05:38<29:44,  1.98s/it] 16%|█▌        | 169/1071 [05:40<29:42,  1.98s/it] 16%|█▌        | 170/1071 [05:42<29:40,  1.98s/it]                                                   16%|█▌        | 170/1071 [05:42<29:40,  1.98s/it] 16%|█▌        | 171/1071 [05:44<29:37,  1.98s/it] 16%|█▌        | 172/1071 [05:46<29:34,  1.97s/it] 16%|█▌        | 173/1071 [05:48<29:33,  1.97s/it] 16%|█▌        | 174/1071 [05:50<29:32,  1.98s/it] 16%|█▋        | 175/1071 [05:52<29:31,  1.98s/it] 16%|█▋        | 176/1071 [05:54<29:28,  1.98s/it] 17%|█▋        | 177/1071 [05:56<29:25,  1.98s/it] 17%|█▋        | 178/1071 [05:58<29:24,  1.98s/it] 17%|█▋        | 179/1071 [06:00<29:21,  1.97s/it] 17%|█▋        | 180/1071 [06:02<29:18,  1.97s/it]                                                   17%|█▋        | 180/1071 [06:02<29:18,  1.97s/it] 17%|█▋        | 181/1071 [06:04<29:18,  1.98s/it] 17%|█▋        | 182/1071 [06:06<29:15,  1.97s/it] 17%|█▋        | 183/1071 [06:08<29:12,  1.97s/it] 17%|█▋        | 184/1071 [06:10<29:12,  1.98s/it] 17%|█▋        | 185/1071 [06:12<29:08,  1.97s/it] 17%|█▋        | 186/1071 [06:14<29:04,  1.97s/it] 17%|█▋        | 187/1071 [06:16<29:03,  1.97s/it] 18%|█▊        | 188/1071 [06:18<29:01,  1.97s/it] 18%|█▊        | 189/1071 [06:20<29:00,  1.97s/it] 18%|█▊        | 190/1071 [06:22<28:59,  1.97s/it]                                                   18%|█▊        | 190/1071 [06:22<28:59,  1.97s/it] 18%|█▊        | 191/1071 [06:24<28:59,  1.98s/it] 18%|█▊        | 192/1071 [06:26<28:58,  1.98s/it] 18%|█▊        | 193/1071 [06:28<28:56,  1.98s/it] 18%|█▊        | 194/1071 [06:30<28:51,  1.97s/it] 18%|█▊        | 195/1071 [06:32<28:49,  1.97s/it] 18%|█▊        | 196/1071 [06:34<28:47,  1.97s/it] 18%|█▊        | 197/1071 [06:36<28:45,  1.97s/it] 18%|█▊        | 198/1071 [06:38<28:43,  1.97s/it] 19%|█▊        | 199/1071 [06:40<28:43,  1.98s/it] 19%|█▊        | 200/1071 [06:42<28:41,  1.98s/it]                                                   19%|█▊        | 200/1071 [06:42<28:41,  1.98s/it][INFO|trainer.py:4643] 2025-10-25 00:12:27,639 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-25 00:12:27,639 >>   Num examples = 47
[INFO|trainer.py:4648] 2025-10-25 00:12:27,639 >>   Batch size = 8

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|██████████| 2/2 [00:00<00:00,  5.54it/s][A                                                  
                                             [A 19%|█▊        | 200/1071 [06:43<28:41,  1.98s/it]
100%|██████████| 2/2 [00:00<00:00,  5.54it/s][A
                                             [A 19%|█▉        | 201/1071 [06:45<36:13,  2.50s/it] 19%|█▉        | 202/1071 [06:47<33:52,  2.34s/it] 19%|█▉        | 203/1071 [06:49<32:15,  2.23s/it] 19%|█▉        | 204/1071 [06:51<31:05,  2.15s/it] 19%|█▉        | 205/1071 [06:53<30:20,  2.10s/it] 19%|█▉        | 206/1071 [06:55<29:46,  2.07s/it] 19%|█▉        | 207/1071 [06:57<29:23,  2.04s/it] 19%|█▉        | 208/1071 [06:59<29:06,  2.02s/it] 20%|█▉        | 209/1071 [07:01<28:53,  2.01s/it] 20%|█▉        | 210/1071 [07:03<28:43,  2.00s/it]                                                   20%|█▉        | 210/1071 [07:03<28:43,  2.00s/it] 20%|█▉        | 211/1071 [07:05<28:38,  2.00s/it] 20%|█▉        | 212/1071 [07:07<28:30,  1.99s/it] 20%|█▉        | 213/1071 [07:09<28:24,  1.99s/it] 20%|█▉        | 214/1071 [07:11<28:20,  1.98s/it] 20%|██        | 215/1071 [07:13<28:17,  1.98s/it] 20%|██        | 216/1071 [07:15<28:14,  1.98s/it] 20%|██        | 217/1071 [07:17<28:12,  1.98s/it] 20%|██        | 218/1071 [07:19<28:08,  1.98s/it] 20%|██        | 219/1071 [07:21<28:08,  1.98s/it] 21%|██        | 220/1071 [07:23<28:03,  1.98s/it]                                                   21%|██        | 220/1071 [07:23<28:03,  1.98s/it] 21%|██        | 221/1071 [07:25<28:00,  1.98s/it] 21%|██        | 222/1071 [07:27<27:58,  1.98s/it] 21%|██        | 223/1071 [07:29<27:59,  1.98s/it] 21%|██        | 224/1071 [07:31<27:56,  1.98s/it] 21%|██        | 225/1071 [07:33<27:56,  1.98s/it] 21%|██        | 226/1071 [07:35<27:52,  1.98s/it] 21%|██        | 227/1071 [07:37<27:50,  1.98s/it] 21%|██▏       | 228/1071 [07:39<27:47,  1.98s/it] 21%|██▏       | 229/1071 [07:41<27:43,  1.98s/it] 21%|██▏       | 230/1071 [07:43<27:43,  1.98s/it]                                                   21%|██▏       | 230/1071 [07:43<27:43,  1.98s/it] 22%|██▏       | 231/1071 [07:45<27:45,  1.98s/it] 22%|██▏       | 232/1071 [07:47<27:44,  1.98s/it] 22%|██▏       | 233/1071 [07:49<27:41,  1.98s/it] 22%|██▏       | 234/1071 [07:51<27:39,  1.98s/it] 22%|██▏       | 235/1071 [07:53<27:36,  1.98s/it] 22%|██▏       | 236/1071 [07:55<27:34,  1.98s/it] 22%|██▏       | 237/1071 [07:57<27:31,  1.98s/it] 22%|██▏       | 238/1071 [07:59<27:28,  1.98s/it] 22%|██▏       | 239/1071 [08:01<27:27,  1.98s/it] 22%|██▏       | 240/1071 [08:03<27:23,  1.98s/it]                                                   22%|██▏       | 240/1071 [08:03<27:23,  1.98s/it] 23%|██▎       | 241/1071 [08:05<27:22,  1.98s/it] 23%|██▎       | 242/1071 [08:07<27:22,  1.98s/it] 23%|██▎       | 243/1071 [08:08<27:17,  1.98s/it] 23%|██▎       | 244/1071 [08:10<27:15,  1.98s/it] 23%|██▎       | 245/1071 [08:12<27:15,  1.98s/it] 23%|██▎       | 246/1071 [08:14<27:13,  1.98s/it] 23%|██▎       | 247/1071 [08:16<27:12,  1.98s/it] 23%|██▎       | 248/1071 [08:18<27:07,  1.98s/it] 23%|██▎       | 249/1071 [08:20<27:05,  1.98s/it] 23%|██▎       | 250/1071 [08:22<27:04,  1.98s/it]                                                   23%|██▎       | 250/1071 [08:22<27:04,  1.98s/it] 23%|██▎       | 251/1071 [08:24<27:01,  1.98s/it] 24%|██▎       | 252/1071 [08:26<26:58,  1.98s/it] 24%|██▎       | 253/1071 [08:28<26:56,  1.98s/it] 24%|██▎       | 254/1071 [08:30<26:54,  1.98s/it] 24%|██▍       | 255/1071 [08:32<26:53,  1.98s/it] 24%|██▍       | 256/1071 [08:34<26:51,  1.98s/it] 24%|██▍       | 257/1071 [08:36<26:49,  1.98s/it] 24%|██▍       | 258/1071 [08:38<26:47,  1.98s/it] 24%|██▍       | 259/1071 [08:40<26:45,  1.98s/it] 24%|██▍       | 260/1071 [08:42<26:41,  1.98s/it]                                                   24%|██▍       | 260/1071 [08:42<26:41,  1.98s/it] 24%|██▍       | 261/1071 [08:44<26:39,  1.97s/it] 24%|██▍       | 262/1071 [08:46<26:38,  1.98s/it] 25%|██▍       | 263/1071 [08:48<26:35,  1.97s/it] 25%|██▍       | 264/1071 [08:50<26:33,  1.97s/it] 25%|██▍       | 265/1071 [08:52<26:32,  1.98s/it] 25%|██▍       | 266/1071 [08:54<26:31,  1.98s/it] 25%|██▍       | 267/1071 [08:56<26:27,  1.97s/it] 25%|██▌       | 268/1071 [08:58<26:26,  1.98s/it] 25%|██▌       | 269/1071 [09:00<26:24,  1.98s/it] 25%|██▌       | 270/1071 [09:02<26:23,  1.98s/it]                                                   25%|██▌       | 270/1071 [09:02<26:23,  1.98s/it] 25%|██▌       | 271/1071 [09:04<26:20,  1.98s/it] 25%|██▌       | 272/1071 [09:06<26:20,  1.98s/it] 25%|██▌       | 273/1071 [09:08<26:19,  1.98s/it] 26%|██▌       | 274/1071 [09:10<26:17,  1.98s/it] 26%|██▌       | 275/1071 [09:12<26:15,  1.98s/it] 26%|██▌       | 276/1071 [09:14<26:11,  1.98s/it] 26%|██▌       | 277/1071 [09:16<26:10,  1.98s/it] 26%|██▌       | 278/1071 [09:18<26:08,  1.98s/it] 26%|██▌       | 279/1071 [09:20<26:04,  1.98s/it] 26%|██▌       | 280/1071 [09:22<26:03,  1.98s/it]                                                   26%|██▌       | 280/1071 [09:22<26:03,  1.98s/it] 26%|██▌       | 281/1071 [09:24<26:02,  1.98s/it] 26%|██▋       | 282/1071 [09:26<25:59,  1.98s/it] 26%|██▋       | 283/1071 [09:28<25:58,  1.98s/it] 27%|██▋       | 284/1071 [09:30<25:55,  1.98s/it] 27%|██▋       | 285/1071 [09:32<25:55,  1.98s/it] 27%|██▋       | 286/1071 [09:33<25:51,  1.98s/it] 27%|██▋       | 287/1071 [09:35<25:48,  1.97s/it] 27%|██▋       | 288/1071 [09:37<25:49,  1.98s/it] 27%|██▋       | 289/1071 [09:39<25:46,  1.98s/it] 27%|██▋       | 290/1071 [09:41<25:46,  1.98s/it]                                                   27%|██▋       | 290/1071 [09:41<25:46,  1.98s/it] 27%|██▋       | 291/1071 [09:43<25:45,  1.98s/it] 27%|██▋       | 292/1071 [09:45<25:43,  1.98s/it] 27%|██▋       | 293/1071 [09:47<25:41,  1.98s/it] 27%|██▋       | 294/1071 [09:49<25:36,  1.98s/it] 28%|██▊       | 295/1071 [09:51<25:36,  1.98s/it] 28%|██▊       | 296/1071 [09:53<25:33,  1.98s/it] 28%|██▊       | 297/1071 [09:55<25:32,  1.98s/it] 28%|██▊       | 298/1071 [09:57<25:30,  1.98s/it] 28%|██▊       | 299/1071 [09:59<25:28,  1.98s/it] 28%|██▊       | 300/1071 [10:01<25:26,  1.98s/it]                                                   28%|██▊       | 300/1071 [10:01<25:26,  1.98s/it][INFO|trainer.py:4643] 2025-10-25 00:15:47,217 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-25 00:15:47,217 >>   Num examples = 47
[INFO|trainer.py:4648] 2025-10-25 00:15:47,217 >>   Batch size = 8

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|██████████| 2/2 [00:00<00:00,  5.50it/s][A                                                  
                                             [A 28%|██▊       | 300/1071 [10:03<25:26,  1.98s/it]
100%|██████████| 2/2 [00:00<00:00,  5.50it/s][A
                                             [A 28%|██▊       | 301/1071 [10:05<31:47,  2.48s/it] 28%|██▊       | 302/1071 [10:07<29:49,  2.33s/it] 28%|██▊       | 303/1071 [10:09<28:27,  2.22s/it] 28%|██▊       | 304/1071 [10:11<27:29,  2.15s/it] 28%|██▊       | 305/1071 [10:13<26:48,  2.10s/it] 29%|██▊       | 306/1071 [10:15<26:19,  2.06s/it] 29%|██▊       | 307/1071 [10:17<25:58,  2.04s/it] 29%|██▉       | 308/1071 [10:19<25:42,  2.02s/it] 29%|██▉       | 309/1071 [10:21<25:31,  2.01s/it] 29%|██▉       | 310/1071 [10:23<25:22,  2.00s/it]                                                   29%|██▉       | 310/1071 [10:23<25:22,  2.00s/it] 29%|██▉       | 311/1071 [10:25<25:15,  1.99s/it] 29%|██▉       | 312/1071 [10:27<25:09,  1.99s/it] 29%|██▉       | 313/1071 [10:29<25:04,  1.98s/it] 29%|██▉       | 314/1071 [10:31<25:01,  1.98s/it] 29%|██▉       | 315/1071 [10:33<24:57,  1.98s/it] 30%|██▉       | 316/1071 [10:35<24:54,  1.98s/it] 30%|██▉       | 317/1071 [10:37<24:50,  1.98s/it] 30%|██▉       | 318/1071 [10:38<24:48,  1.98s/it] 30%|██▉       | 319/1071 [10:40<24:46,  1.98s/it] 30%|██▉       | 320/1071 [10:42<24:42,  1.97s/it]                                                   30%|██▉       | 320/1071 [10:42<24:42,  1.97s/it] 30%|██▉       | 321/1071 [10:44<24:42,  1.98s/it] 30%|███       | 322/1071 [10:46<24:40,  1.98s/it] 30%|███       | 323/1071 [10:48<24:38,  1.98s/it] 30%|███       | 324/1071 [10:50<24:38,  1.98s/it] 30%|███       | 325/1071 [10:52<24:37,  1.98s/it] 30%|███       | 326/1071 [10:54<24:33,  1.98s/it] 31%|███       | 327/1071 [10:56<24:31,  1.98s/it] 31%|███       | 328/1071 [10:58<24:29,  1.98s/it] 31%|███       | 329/1071 [11:00<24:26,  1.98s/it] 31%|███       | 330/1071 [11:02<24:25,  1.98s/it]                                                   31%|███       | 330/1071 [11:02<24:25,  1.98s/it] 31%|███       | 331/1071 [11:04<24:24,  1.98s/it] 31%|███       | 332/1071 [11:06<24:22,  1.98s/it] 31%|███       | 333/1071 [11:08<24:21,  1.98s/it] 31%|███       | 334/1071 [11:10<24:18,  1.98s/it] 31%|███▏      | 335/1071 [11:12<24:14,  1.98s/it] 31%|███▏      | 336/1071 [11:14<24:12,  1.98s/it] 31%|███▏      | 337/1071 [11:16<24:10,  1.98s/it] 32%|███▏      | 338/1071 [11:18<24:06,  1.97s/it] 32%|███▏      | 339/1071 [11:20<24:04,  1.97s/it] 32%|███▏      | 340/1071 [11:22<24:03,  1.97s/it]                                                   32%|███▏      | 340/1071 [11:22<24:03,  1.97s/it] 32%|███▏      | 341/1071 [11:24<24:01,  1.97s/it] 32%|███▏      | 342/1071 [11:26<24:00,  1.98s/it] 32%|███▏      | 343/1071 [11:28<23:57,  1.97s/it] 32%|███▏      | 344/1071 [11:30<23:54,  1.97s/it] 32%|███▏      | 345/1071 [11:32<23:54,  1.98s/it] 32%|███▏      | 346/1071 [11:34<23:51,  1.97s/it] 32%|███▏      | 347/1071 [11:36<23:49,  1.97s/it] 32%|███▏      | 348/1071 [11:38<23:48,  1.98s/it] 33%|███▎      | 349/1071 [11:40<23:47,  1.98s/it] 33%|███▎      | 350/1071 [11:42<23:42,  1.97s/it]                                                   33%|███▎      | 350/1071 [11:42<23:42,  1.97s/it] 33%|███▎      | 351/1071 [11:44<23:41,  1.97s/it] 33%|███▎      | 352/1071 [11:46<23:37,  1.97s/it] 33%|███▎      | 353/1071 [11:48<23:35,  1.97s/it] 33%|███▎      | 354/1071 [11:50<23:33,  1.97s/it] 33%|███▎      | 355/1071 [11:52<23:31,  1.97s/it] 33%|███▎      | 356/1071 [11:54<23:28,  1.97s/it] 33%|███▎      | 357/1071 [11:56<23:45,  2.00s/it] 33%|███▎      | 358/1071 [12:01<34:40,  2.92s/it] 34%|███▎      | 359/1071 [12:03<31:17,  2.64s/it] 34%|███▎      | 360/1071 [12:05<28:57,  2.44s/it]                                                   34%|███▎      | 360/1071 [12:05<28:57,  2.44s/it] 34%|███▎      | 361/1071 [12:07<27:16,  2.30s/it] 34%|███▍      | 362/1071 [12:09<26:07,  2.21s/it] 34%|███▍      | 363/1071 [12:11<25:18,  2.14s/it] 34%|███▍      | 364/1071 [12:13<24:41,  2.10s/it] 34%|███▍      | 365/1071 [12:15<24:15,  2.06s/it] 34%|███▍      | 366/1071 [12:17<23:57,  2.04s/it] 34%|███▍      | 367/1071 [12:19<23:45,  2.03s/it] 34%|███▍      | 368/1071 [12:21<23:35,  2.01s/it] 34%|███▍      | 369/1071 [12:23<23:27,  2.01s/it] 35%|███▍      | 370/1071 [12:24<23:19,  2.00s/it]                                                   35%|███▍      | 370/1071 [12:25<23:19,  2.00s/it] 35%|███▍      | 371/1071 [12:26<23:17,  2.00s/it] 35%|███▍      | 372/1071 [12:28<23:11,  1.99s/it] 35%|███▍      | 373/1071 [12:30<23:07,  1.99s/it] 35%|███▍      | 374/1071 [12:32<23:02,  1.98s/it] 35%|███▌      | 375/1071 [12:34<23:00,  1.98s/it] 35%|███▌      | 376/1071 [12:36<22:57,  1.98s/it] 35%|███▌      | 377/1071 [12:38<22:54,  1.98s/it] 35%|███▌      | 378/1071 [12:40<22:55,  1.98s/it] 35%|███▌      | 379/1071 [12:42<22:52,  1.98s/it] 35%|███▌      | 380/1071 [12:44<22:49,  1.98s/it]                                                   35%|███▌      | 380/1071 [12:44<22:49,  1.98s/it] 36%|███▌      | 381/1071 [12:46<22:48,  1.98s/it] 36%|███▌      | 382/1071 [12:48<22:47,  1.98s/it] 36%|███▌      | 383/1071 [12:50<22:44,  1.98s/it] 36%|███▌      | 384/1071 [12:52<22:42,  1.98s/it] 36%|███▌      | 385/1071 [12:54<22:41,  1.99s/it] 36%|███▌      | 386/1071 [12:56<22:41,  1.99s/it] 36%|███▌      | 387/1071 [12:58<22:37,  1.99s/it] 36%|███▌      | 388/1071 [13:00<22:34,  1.98s/it] 36%|███▋      | 389/1071 [13:02<22:33,  1.98s/it] 36%|███▋      | 390/1071 [13:04<22:30,  1.98s/it]                                                   36%|███▋      | 390/1071 [13:04<22:30,  1.98s/it] 37%|███▋      | 391/1071 [13:06<22:29,  1.99s/it] 37%|███▋      | 392/1071 [13:08<22:27,  1.98s/it] 37%|███▋      | 393/1071 [13:10<22:26,  1.99s/it] 37%|███▋      | 394/1071 [13:12<22:26,  1.99s/it] 37%|███▋      | 395/1071 [13:14<22:22,  1.99s/it] 37%|███▋      | 396/1071 [13:16<22:19,  1.98s/it] 37%|███▋      | 397/1071 [13:18<22:16,  1.98s/it] 37%|███▋      | 398/1071 [13:20<22:17,  1.99s/it] 37%|███▋      | 399/1071 [13:22<22:15,  1.99s/it] 37%|███▋      | 400/1071 [13:24<22:11,  1.98s/it]                                                   37%|███▋      | 400/1071 [13:24<22:11,  1.98s/it][INFO|trainer.py:4643] 2025-10-25 00:19:10,031 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-25 00:19:10,031 >>   Num examples = 47
[INFO|trainer.py:4648] 2025-10-25 00:19:10,031 >>   Batch size = 8

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|██████████| 2/2 [00:00<00:00,  5.55it/s][A                                                  
                                             [A 37%|███▋      | 400/1071 [13:26<22:11,  1.98s/it]
100%|██████████| 2/2 [00:00<00:00,  5.55it/s][A
                                             [A[INFO|trainer.py:4309] 2025-10-25 00:19:11,588 >> Saving model checkpoint to saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-400
[INFO|configuration_utils.py:491] 2025-10-25 00:19:11,593 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-400/config.json
[INFO|configuration_utils.py:757] 2025-10-25 00:19:11,594 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-400/generation_config.json
[INFO|modeling_utils.py:4189] 2025-10-25 00:19:17,569 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-400/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2421] 2025-10-25 00:19:17,570 >> chat template saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-400/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-25 00:19:17,571 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-25 00:19:17,571 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-400/special_tokens_map.json
[INFO|image_processing_base.py:253] 2025-10-25 00:19:27,301 >> Image processor saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-400/preprocessor_config.json
[INFO|tokenization_utils_base.py:2421] 2025-10-25 00:19:27,810 >> chat template saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-400/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-25 00:19:28,099 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-25 00:19:28,099 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-400/special_tokens_map.json
[INFO|video_processing_utils.py:600] 2025-10-25 00:19:28,933 >> Video processor saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-400/video_preprocessor_config.json
[INFO|processing_utils.py:814] 2025-10-25 00:19:28,934 >> chat template saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-400/chat_template.jinja
 37%|███▋      | 401/1071 [13:45<1:26:22,  7.73s/it] 38%|███▊      | 402/1071 [13:47<1:06:57,  6.00s/it] 38%|███▊      | 403/1071 [13:49<53:21,  4.79s/it]   38%|███▊      | 404/1071 [13:51<43:53,  3.95s/it] 38%|███▊      | 405/1071 [13:53<37:17,  3.36s/it] 38%|███▊      | 406/1071 [13:55<32:40,  2.95s/it] 38%|███▊      | 407/1071 [13:57<29:22,  2.65s/it] 38%|███▊      | 408/1071 [13:59<27:06,  2.45s/it] 38%|███▊      | 409/1071 [14:01<25:30,  2.31s/it] 38%|███▊      | 410/1071 [14:03<24:22,  2.21s/it]                                                   38%|███▊      | 410/1071 [14:03<24:22,  2.21s/it] 38%|███▊      | 411/1071 [14:05<23:33,  2.14s/it] 38%|███▊      | 412/1071 [14:07<22:57,  2.09s/it] 39%|███▊      | 413/1071 [14:09<22:34,  2.06s/it] 39%|███▊      | 414/1071 [14:11<22:15,  2.03s/it] 39%|███▊      | 415/1071 [14:13<22:01,  2.01s/it] 39%|███▉      | 416/1071 [14:15<21:51,  2.00s/it] 39%|███▉      | 417/1071 [14:17<21:43,  1.99s/it] 39%|███▉      | 418/1071 [14:19<21:37,  1.99s/it] 39%|███▉      | 419/1071 [14:21<21:33,  1.98s/it] 39%|███▉      | 420/1071 [14:23<21:29,  1.98s/it]                                                   39%|███▉      | 420/1071 [14:23<21:29,  1.98s/it] 39%|███▉      | 421/1071 [14:25<21:27,  1.98s/it] 39%|███▉      | 422/1071 [14:27<21:23,  1.98s/it] 39%|███▉      | 423/1071 [14:29<21:20,  1.98s/it] 40%|███▉      | 424/1071 [14:31<21:19,  1.98s/it] 40%|███▉      | 425/1071 [14:33<21:18,  1.98s/it] 40%|███▉      | 426/1071 [14:35<21:18,  1.98s/it] 40%|███▉      | 427/1071 [14:37<21:16,  1.98s/it] 40%|███▉      | 428/1071 [14:39<21:13,  1.98s/it] 40%|████      | 429/1071 [14:41<21:11,  1.98s/it] 40%|████      | 430/1071 [14:43<21:09,  1.98s/it]                                                   40%|████      | 430/1071 [14:43<21:09,  1.98s/it] 40%|████      | 431/1071 [14:44<21:06,  1.98s/it] 40%|████      | 432/1071 [14:46<21:04,  1.98s/it] 40%|████      | 433/1071 [14:48<21:02,  1.98s/it] 41%|████      | 434/1071 [14:50<21:03,  1.98s/it] 41%|████      | 435/1071 [14:52<20:58,  1.98s/it] 41%|████      | 436/1071 [14:54<20:57,  1.98s/it] 41%|████      | 437/1071 [14:56<20:54,  1.98s/it] 41%|████      | 438/1071 [14:58<20:52,  1.98s/it] 41%|████      | 439/1071 [15:00<20:48,  1.98s/it] 41%|████      | 440/1071 [15:02<20:46,  1.98s/it]                                                   41%|████      | 440/1071 [15:02<20:46,  1.98s/it] 41%|████      | 441/1071 [15:04<20:44,  1.98s/it] 41%|████▏     | 442/1071 [15:06<20:42,  1.98s/it] 41%|████▏     | 443/1071 [15:08<20:42,  1.98s/it] 41%|████▏     | 444/1071 [15:10<20:39,  1.98s/it] 42%|████▏     | 445/1071 [15:12<20:36,  1.98s/it] 42%|████▏     | 446/1071 [15:14<20:34,  1.98s/it] 42%|████▏     | 447/1071 [15:16<20:33,  1.98s/it] 42%|████▏     | 448/1071 [15:18<20:31,  1.98s/it] 42%|████▏     | 449/1071 [15:20<20:28,  1.97s/it] 42%|████▏     | 450/1071 [15:22<20:27,  1.98s/it]                                                   42%|████▏     | 450/1071 [15:22<20:27,  1.98s/it] 42%|████▏     | 451/1071 [15:24<20:25,  1.98s/it] 42%|████▏     | 452/1071 [15:26<20:23,  1.98s/it] 42%|████▏     | 453/1071 [15:28<20:25,  1.98s/it] 42%|████▏     | 454/1071 [15:30<20:23,  1.98s/it] 42%|████▏     | 455/1071 [15:32<20:20,  1.98s/it] 43%|████▎     | 456/1071 [15:34<20:18,  1.98s/it] 43%|████▎     | 457/1071 [15:36<20:16,  1.98s/it] 43%|████▎     | 458/1071 [15:38<20:14,  1.98s/it] 43%|████▎     | 459/1071 [15:40<20:13,  1.98s/it] 43%|████▎     | 460/1071 [15:42<20:11,  1.98s/it]                                                   43%|████▎     | 460/1071 [15:42<20:11,  1.98s/it] 43%|████▎     | 461/1071 [15:44<20:09,  1.98s/it] 43%|████▎     | 462/1071 [15:46<20:05,  1.98s/it] 43%|████▎     | 463/1071 [15:48<20:04,  1.98s/it] 43%|████▎     | 464/1071 [15:50<20:02,  1.98s/it] 43%|████▎     | 465/1071 [15:52<19:58,  1.98s/it] 44%|████▎     | 466/1071 [15:54<19:57,  1.98s/it] 44%|████▎     | 467/1071 [15:56<19:55,  1.98s/it] 44%|████▎     | 468/1071 [15:58<19:55,  1.98s/it] 44%|████▍     | 469/1071 [16:00<19:52,  1.98s/it] 44%|████▍     | 470/1071 [16:02<19:49,  1.98s/it]                                                   44%|████▍     | 470/1071 [16:02<19:49,  1.98s/it] 44%|████▍     | 471/1071 [16:04<19:46,  1.98s/it] 44%|████▍     | 472/1071 [16:06<19:42,  1.97s/it] 44%|████▍     | 473/1071 [16:08<19:41,  1.98s/it] 44%|████▍     | 474/1071 [16:10<19:39,  1.98s/it] 44%|████▍     | 475/1071 [16:12<19:39,  1.98s/it] 44%|████▍     | 476/1071 [16:14<19:37,  1.98s/it] 45%|████▍     | 477/1071 [16:16<19:34,  1.98s/it] 45%|████▍     | 478/1071 [16:17<19:33,  1.98s/it] 45%|████▍     | 479/1071 [16:19<19:34,  1.98s/it] 45%|████▍     | 480/1071 [16:21<19:31,  1.98s/it]                                                   45%|████▍     | 480/1071 [16:22<19:31,  1.98s/it] 45%|████▍     | 481/1071 [16:23<19:30,  1.98s/it] 45%|████▌     | 482/1071 [16:25<19:29,  1.99s/it] 45%|████▌     | 483/1071 [16:27<19:26,  1.98s/it] 45%|████▌     | 484/1071 [16:29<19:23,  1.98s/it] 45%|████▌     | 485/1071 [16:31<19:20,  1.98s/it] 45%|████▌     | 486/1071 [16:33<19:19,  1.98s/it] 45%|████▌     | 487/1071 [16:35<19:16,  1.98s/it] 46%|████▌     | 488/1071 [16:37<19:13,  1.98s/it] 46%|████▌     | 489/1071 [16:39<19:11,  1.98s/it] 46%|████▌     | 490/1071 [16:41<19:08,  1.98s/it]                                                   46%|████▌     | 490/1071 [16:41<19:08,  1.98s/it] 46%|████▌     | 491/1071 [16:43<19:05,  1.98s/it] 46%|████▌     | 492/1071 [16:45<19:04,  1.98s/it] 46%|████▌     | 493/1071 [16:47<19:02,  1.98s/it] 46%|████▌     | 494/1071 [16:49<19:01,  1.98s/it] 46%|████▌     | 495/1071 [16:51<19:01,  1.98s/it] 46%|████▋     | 496/1071 [16:53<18:58,  1.98s/it] 46%|████▋     | 497/1071 [16:55<18:55,  1.98s/it] 46%|████▋     | 498/1071 [16:57<18:53,  1.98s/it] 47%|████▋     | 499/1071 [16:59<18:51,  1.98s/it] 47%|████▋     | 500/1071 [17:01<18:49,  1.98s/it]                                                   47%|████▋     | 500/1071 [17:01<18:49,  1.98s/it][INFO|trainer.py:4643] 2025-10-25 00:22:47,064 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-25 00:22:47,064 >>   Num examples = 47
[INFO|trainer.py:4648] 2025-10-25 00:22:47,064 >>   Batch size = 8

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|██████████| 2/2 [00:00<00:00,  5.51it/s][A                                                  
                                             [A 47%|████▋     | 500/1071 [17:03<18:49,  1.98s/it]
100%|██████████| 2/2 [00:00<00:00,  5.51it/s][A
                                             [A 47%|████▋     | 501/1071 [17:05<23:26,  2.47s/it] 47%|████▋     | 502/1071 [17:07<22:02,  2.32s/it] 47%|████▋     | 503/1071 [17:09<20:59,  2.22s/it] 47%|████▋     | 504/1071 [17:11<20:17,  2.15s/it] 47%|████▋     | 505/1071 [17:13<19:47,  2.10s/it] 47%|████▋     | 506/1071 [17:15<19:25,  2.06s/it] 47%|████▋     | 507/1071 [17:17<19:10,  2.04s/it] 47%|████▋     | 508/1071 [17:19<18:56,  2.02s/it] 48%|████▊     | 509/1071 [17:20<18:48,  2.01s/it] 48%|████▊     | 510/1071 [17:22<18:41,  2.00s/it]                                                   48%|████▊     | 510/1071 [17:23<18:41,  2.00s/it] 48%|████▊     | 511/1071 [17:24<18:36,  1.99s/it] 48%|████▊     | 512/1071 [17:26<18:32,  1.99s/it] 48%|████▊     | 513/1071 [17:28<18:27,  1.99s/it] 48%|████▊     | 514/1071 [17:30<18:24,  1.98s/it] 48%|████▊     | 515/1071 [17:32<18:21,  1.98s/it] 48%|████▊     | 516/1071 [17:34<18:19,  1.98s/it] 48%|████▊     | 517/1071 [17:36<18:14,  1.98s/it] 48%|████▊     | 518/1071 [17:38<18:14,  1.98s/it] 48%|████▊     | 519/1071 [17:40<18:12,  1.98s/it] 49%|████▊     | 520/1071 [17:42<18:09,  1.98s/it]                                                   49%|████▊     | 520/1071 [17:42<18:09,  1.98s/it] 49%|████▊     | 521/1071 [17:44<18:06,  1.98s/it] 49%|████▊     | 522/1071 [17:46<18:04,  1.98s/it] 49%|████▉     | 523/1071 [17:48<18:03,  1.98s/it] 49%|████▉     | 524/1071 [17:50<18:00,  1.98s/it] 49%|████▉     | 525/1071 [17:52<17:58,  1.97s/it] 49%|████▉     | 526/1071 [17:54<17:58,  1.98s/it] 49%|████▉     | 527/1071 [17:56<17:56,  1.98s/it] 49%|████▉     | 528/1071 [17:58<17:55,  1.98s/it] 49%|████▉     | 529/1071 [18:00<17:55,  1.98s/it] 49%|████▉     | 530/1071 [18:02<17:51,  1.98s/it]                                                   49%|████▉     | 530/1071 [18:02<17:51,  1.98s/it] 50%|████▉     | 531/1071 [18:04<17:48,  1.98s/it] 50%|████▉     | 532/1071 [18:06<17:46,  1.98s/it] 50%|████▉     | 533/1071 [18:08<17:43,  1.98s/it] 50%|████▉     | 534/1071 [18:10<17:42,  1.98s/it] 50%|████▉     | 535/1071 [18:12<17:39,  1.98s/it] 50%|█████     | 536/1071 [18:14<17:37,  1.98s/it] 50%|█████     | 537/1071 [18:16<17:34,  1.98s/it] 50%|█████     | 538/1071 [18:18<17:32,  1.97s/it] 50%|█████     | 539/1071 [18:20<17:32,  1.98s/it] 50%|█████     | 540/1071 [18:22<17:30,  1.98s/it]                                                   50%|█████     | 540/1071 [18:22<17:30,  1.98s/it] 51%|█████     | 541/1071 [18:24<17:28,  1.98s/it] 51%|█████     | 542/1071 [18:26<17:25,  1.98s/it] 51%|█████     | 543/1071 [18:28<17:23,  1.98s/it] 51%|█████     | 544/1071 [18:30<17:20,  1.97s/it] 51%|█████     | 545/1071 [18:32<17:18,  1.97s/it] 51%|█████     | 546/1071 [18:34<17:15,  1.97s/it] 51%|█████     | 547/1071 [18:36<17:13,  1.97s/it] 51%|█████     | 548/1071 [18:38<17:10,  1.97s/it] 51%|█████▏    | 549/1071 [18:40<17:08,  1.97s/it] 51%|█████▏    | 550/1071 [18:42<17:07,  1.97s/it]                                                   51%|█████▏    | 550/1071 [18:42<17:07,  1.97s/it] 51%|█████▏    | 551/1071 [18:44<17:05,  1.97s/it] 52%|█████▏    | 552/1071 [18:45<17:04,  1.97s/it] 52%|█████▏    | 553/1071 [18:47<17:04,  1.98s/it] 52%|█████▏    | 554/1071 [18:49<17:02,  1.98s/it] 52%|█████▏    | 555/1071 [18:51<17:00,  1.98s/it] 52%|█████▏    | 556/1071 [18:53<16:57,  1.98s/it] 52%|█████▏    | 557/1071 [18:55<16:55,  1.98s/it] 52%|█████▏    | 558/1071 [18:57<16:53,  1.98s/it] 52%|█████▏    | 559/1071 [18:59<16:51,  1.98s/it] 52%|█████▏    | 560/1071 [19:01<16:48,  1.97s/it]                                                   52%|█████▏    | 560/1071 [19:01<16:48,  1.97s/it] 52%|█████▏    | 561/1071 [19:03<16:47,  1.97s/it] 52%|█████▏    | 562/1071 [19:05<16:46,  1.98s/it] 53%|█████▎    | 563/1071 [19:07<16:43,  1.98s/it] 53%|█████▎    | 564/1071 [19:09<16:42,  1.98s/it] 53%|█████▎    | 565/1071 [19:11<16:39,  1.98s/it] 53%|█████▎    | 566/1071 [19:13<16:37,  1.98s/it] 53%|█████▎    | 567/1071 [19:15<17:27,  2.08s/it] 53%|█████▎    | 568/1071 [19:17<17:10,  2.05s/it] 53%|█████▎    | 569/1071 [19:19<16:57,  2.03s/it] 53%|█████▎    | 570/1071 [19:21<16:46,  2.01s/it]                                                   53%|█████▎    | 570/1071 [19:21<16:46,  2.01s/it] 53%|█████▎    | 571/1071 [19:23<16:38,  2.00s/it] 53%|█████▎    | 572/1071 [19:25<16:34,  1.99s/it] 54%|█████▎    | 573/1071 [19:27<16:29,  1.99s/it] 54%|█████▎    | 574/1071 [19:29<16:27,  1.99s/it] 54%|█████▎    | 575/1071 [19:31<16:23,  1.98s/it] 54%|█████▍    | 576/1071 [19:33<16:19,  1.98s/it] 54%|█████▍    | 577/1071 [19:35<16:17,  1.98s/it] 54%|█████▍    | 578/1071 [19:37<16:13,  1.98s/it] 54%|█████▍    | 579/1071 [19:39<16:11,  1.98s/it] 54%|█████▍    | 580/1071 [19:41<16:09,  1.98s/it]                                                   54%|█████▍    | 580/1071 [19:41<16:09,  1.98s/it] 54%|█████▍    | 581/1071 [19:43<16:08,  1.98s/it] 54%|█████▍    | 582/1071 [19:45<16:05,  1.98s/it] 54%|█████▍    | 583/1071 [19:47<16:03,  1.98s/it] 55%|█████▍    | 584/1071 [19:49<16:03,  1.98s/it] 55%|█████▍    | 585/1071 [19:51<16:49,  2.08s/it] 55%|█████▍    | 586/1071 [19:53<16:35,  2.05s/it] 55%|█████▍    | 587/1071 [19:55<16:23,  2.03s/it] 55%|█████▍    | 588/1071 [19:57<16:12,  2.01s/it] 55%|█████▍    | 589/1071 [19:59<16:05,  2.00s/it] 55%|█████▌    | 590/1071 [20:01<15:59,  1.99s/it]                                                   55%|█████▌    | 590/1071 [20:01<15:59,  1.99s/it] 55%|█████▌    | 591/1071 [20:03<15:54,  1.99s/it] 55%|█████▌    | 592/1071 [20:05<15:52,  1.99s/it] 55%|█████▌    | 593/1071 [20:07<15:48,  1.98s/it] 55%|█████▌    | 594/1071 [20:09<15:44,  1.98s/it] 56%|█████▌    | 595/1071 [20:11<15:42,  1.98s/it] 56%|█████▌    | 596/1071 [20:13<15:40,  1.98s/it] 56%|█████▌    | 597/1071 [20:15<15:37,  1.98s/it] 56%|█████▌    | 598/1071 [20:17<15:35,  1.98s/it] 56%|█████▌    | 599/1071 [20:19<15:32,  1.98s/it] 56%|█████▌    | 600/1071 [20:21<15:30,  1.98s/it]                                                   56%|█████▌    | 600/1071 [20:21<15:30,  1.98s/it][INFO|trainer.py:4643] 2025-10-25 00:26:07,045 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-25 00:26:07,045 >>   Num examples = 47
[INFO|trainer.py:4648] 2025-10-25 00:26:07,045 >>   Batch size = 8

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|██████████| 2/2 [00:00<00:00,  5.34it/s][A                                                  
                                             [A 56%|█████▌    | 600/1071 [20:23<15:30,  1.98s/it]
100%|██████████| 2/2 [00:00<00:00,  5.34it/s][A
                                             [A 56%|█████▌    | 601/1071 [20:25<18:58,  2.42s/it] 56%|█████▌    | 602/1071 [20:26<17:54,  2.29s/it] 56%|█████▋    | 603/1071 [20:28<17:08,  2.20s/it] 56%|█████▋    | 604/1071 [20:30<16:35,  2.13s/it] 56%|█████▋    | 605/1071 [20:32<16:11,  2.09s/it] 57%|█████▋    | 606/1071 [20:35<16:39,  2.15s/it] 57%|█████▋    | 607/1071 [20:37<16:14,  2.10s/it] 57%|█████▋    | 608/1071 [20:39<15:55,  2.06s/it] 57%|█████▋    | 609/1071 [20:41<15:41,  2.04s/it] 57%|█████▋    | 610/1071 [20:43<15:31,  2.02s/it]                                                   57%|█████▋    | 610/1071 [20:43<15:31,  2.02s/it] 57%|█████▋    | 611/1071 [20:45<15:25,  2.01s/it] 57%|█████▋    | 612/1071 [20:47<15:17,  2.00s/it] 57%|█████▋    | 613/1071 [20:49<15:13,  1.99s/it] 57%|█████▋    | 614/1071 [20:51<15:09,  1.99s/it] 57%|█████▋    | 615/1071 [20:53<15:05,  1.99s/it] 58%|█████▊    | 616/1071 [20:55<15:01,  1.98s/it] 58%|█████▊    | 617/1071 [20:56<14:58,  1.98s/it] 58%|█████▊    | 618/1071 [20:58<14:55,  1.98s/it] 58%|█████▊    | 619/1071 [21:00<14:53,  1.98s/it] 58%|█████▊    | 620/1071 [21:02<14:51,  1.98s/it]                                                   58%|█████▊    | 620/1071 [21:02<14:51,  1.98s/it] 58%|█████▊    | 621/1071 [21:04<14:49,  1.98s/it] 58%|█████▊    | 622/1071 [21:06<14:46,  1.97s/it] 58%|█████▊    | 623/1071 [21:08<14:43,  1.97s/it] 58%|█████▊    | 624/1071 [21:10<14:42,  1.97s/it] 58%|█████▊    | 625/1071 [21:12<14:40,  1.97s/it] 58%|█████▊    | 626/1071 [21:14<14:38,  1.97s/it] 59%|█████▊    | 627/1071 [21:17<15:20,  2.07s/it] 59%|█████▊    | 628/1071 [21:19<15:07,  2.05s/it] 59%|█████▊    | 629/1071 [21:21<14:55,  2.03s/it] 59%|█████▉    | 630/1071 [21:22<14:46,  2.01s/it]                                                   59%|█████▉    | 630/1071 [21:23<14:46,  2.01s/it] 59%|█████▉    | 631/1071 [21:24<14:41,  2.00s/it] 59%|█████▉    | 632/1071 [21:26<14:36,  2.00s/it] 59%|█████▉    | 633/1071 [21:28<14:32,  1.99s/it] 59%|█████▉    | 634/1071 [21:30<14:29,  1.99s/it] 59%|█████▉    | 635/1071 [21:32<14:26,  1.99s/it] 59%|█████▉    | 636/1071 [21:34<14:22,  1.98s/it] 59%|█████▉    | 637/1071 [21:36<14:20,  1.98s/it] 60%|█████▉    | 638/1071 [21:38<14:18,  1.98s/it] 60%|█████▉    | 639/1071 [21:40<14:17,  1.99s/it] 60%|█████▉    | 640/1071 [21:42<14:15,  1.98s/it]                                                   60%|█████▉    | 640/1071 [21:42<14:15,  1.98s/it] 60%|█████▉    | 641/1071 [21:44<14:11,  1.98s/it] 60%|█████▉    | 642/1071 [21:46<14:08,  1.98s/it] 60%|██████    | 643/1071 [21:48<14:05,  1.98s/it] 60%|██████    | 644/1071 [21:50<14:03,  1.98s/it] 60%|██████    | 645/1071 [21:52<14:02,  1.98s/it] 60%|██████    | 646/1071 [21:54<14:01,  1.98s/it] 60%|██████    | 647/1071 [21:56<13:58,  1.98s/it] 61%|██████    | 648/1071 [21:58<13:57,  1.98s/it] 61%|██████    | 649/1071 [22:00<13:55,  1.98s/it] 61%|██████    | 650/1071 [22:02<13:53,  1.98s/it]                                                   61%|██████    | 650/1071 [22:02<13:53,  1.98s/it] 61%|██████    | 651/1071 [22:04<13:51,  1.98s/it] 61%|██████    | 652/1071 [22:06<13:48,  1.98s/it] 61%|██████    | 653/1071 [22:08<13:46,  1.98s/it] 61%|██████    | 654/1071 [22:10<13:44,  1.98s/it] 61%|██████    | 655/1071 [22:12<13:43,  1.98s/it] 61%|██████▏   | 656/1071 [22:14<13:42,  1.98s/it] 61%|██████▏   | 657/1071 [22:16<13:39,  1.98s/it] 61%|██████▏   | 658/1071 [22:18<13:36,  1.98s/it] 62%|██████▏   | 659/1071 [22:20<13:36,  1.98s/it] 62%|██████▏   | 660/1071 [22:22<13:34,  1.98s/it]                                                   62%|██████▏   | 660/1071 [22:22<13:34,  1.98s/it] 62%|██████▏   | 661/1071 [22:24<13:32,  1.98s/it] 62%|██████▏   | 662/1071 [22:26<13:30,  1.98s/it] 62%|██████▏   | 663/1071 [22:28<13:29,  1.98s/it] 62%|██████▏   | 664/1071 [22:30<13:28,  1.99s/it] 62%|██████▏   | 665/1071 [22:32<13:26,  1.99s/it] 62%|██████▏   | 666/1071 [22:34<13:23,  1.98s/it] 62%|██████▏   | 667/1071 [22:36<13:22,  1.99s/it] 62%|██████▏   | 668/1071 [22:38<13:19,  1.98s/it] 62%|██████▏   | 669/1071 [22:40<13:17,  1.98s/it] 63%|██████▎   | 670/1071 [22:42<13:15,  1.98s/it]                                                   63%|██████▎   | 670/1071 [22:42<13:15,  1.98s/it] 63%|██████▎   | 671/1071 [22:44<13:11,  1.98s/it] 63%|██████▎   | 672/1071 [22:46<13:09,  1.98s/it] 63%|██████▎   | 673/1071 [22:48<13:07,  1.98s/it] 63%|██████▎   | 674/1071 [22:50<13:05,  1.98s/it] 63%|██████▎   | 675/1071 [22:52<13:03,  1.98s/it] 63%|██████▎   | 676/1071 [22:54<13:02,  1.98s/it] 63%|██████▎   | 677/1071 [22:56<13:01,  1.98s/it] 63%|██████▎   | 678/1071 [22:58<12:58,  1.98s/it] 63%|██████▎   | 679/1071 [23:00<12:55,  1.98s/it] 63%|██████▎   | 680/1071 [23:02<12:53,  1.98s/it]                                                   63%|██████▎   | 680/1071 [23:02<12:53,  1.98s/it] 64%|██████▎   | 681/1071 [23:03<12:51,  1.98s/it] 64%|██████▎   | 682/1071 [23:05<12:48,  1.98s/it] 64%|██████▍   | 683/1071 [23:07<12:47,  1.98s/it] 64%|██████▍   | 684/1071 [23:09<12:46,  1.98s/it] 64%|██████▍   | 685/1071 [23:11<12:44,  1.98s/it] 64%|██████▍   | 686/1071 [23:13<12:42,  1.98s/it] 64%|██████▍   | 687/1071 [23:15<12:39,  1.98s/it] 64%|██████▍   | 688/1071 [23:17<12:37,  1.98s/it] 64%|██████▍   | 689/1071 [23:19<12:36,  1.98s/it] 64%|██████▍   | 690/1071 [23:21<12:34,  1.98s/it]                                                   64%|██████▍   | 690/1071 [23:21<12:34,  1.98s/it] 65%|██████▍   | 691/1071 [23:23<12:33,  1.98s/it] 65%|██████▍   | 692/1071 [23:25<12:31,  1.98s/it] 65%|██████▍   | 693/1071 [23:27<12:29,  1.98s/it] 65%|██████▍   | 694/1071 [23:29<12:27,  1.98s/it] 65%|██████▍   | 695/1071 [23:31<12:25,  1.98s/it] 65%|██████▍   | 696/1071 [23:33<12:22,  1.98s/it] 65%|██████▌   | 697/1071 [23:35<12:19,  1.98s/it] 65%|██████▌   | 698/1071 [23:37<12:16,  1.97s/it] 65%|██████▌   | 699/1071 [23:39<12:13,  1.97s/it] 65%|██████▌   | 700/1071 [23:41<12:12,  1.97s/it]                                                   65%|██████▌   | 700/1071 [23:41<12:12,  1.97s/it][INFO|trainer.py:4643] 2025-10-25 00:29:27,108 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-25 00:29:27,108 >>   Num examples = 47
[INFO|trainer.py:4648] 2025-10-25 00:29:27,108 >>   Batch size = 8

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|██████████| 2/2 [00:00<00:00,  5.39it/s][A                                                  
                                             [A 65%|██████▌   | 700/1071 [23:43<12:12,  1.97s/it]
100%|██████████| 2/2 [00:00<00:00,  5.39it/s][A
                                             [A 65%|██████▌   | 701/1071 [23:44<14:48,  2.40s/it] 66%|██████▌   | 702/1071 [23:46<13:58,  2.27s/it] 66%|██████▌   | 703/1071 [23:48<13:25,  2.19s/it] 66%|██████▌   | 704/1071 [23:50<13:00,  2.13s/it] 66%|██████▌   | 705/1071 [23:52<12:42,  2.08s/it] 66%|██████▌   | 706/1071 [23:54<12:29,  2.05s/it] 66%|██████▌   | 707/1071 [23:56<12:18,  2.03s/it] 66%|██████▌   | 708/1071 [23:58<12:10,  2.01s/it] 66%|██████▌   | 709/1071 [24:00<12:03,  2.00s/it] 66%|██████▋   | 710/1071 [24:02<11:58,  1.99s/it]                                                   66%|██████▋   | 710/1071 [24:02<11:58,  1.99s/it] 66%|██████▋   | 711/1071 [24:04<11:54,  1.99s/it] 66%|██████▋   | 712/1071 [24:06<11:51,  1.98s/it] 67%|██████▋   | 713/1071 [24:08<11:48,  1.98s/it] 67%|██████▋   | 714/1071 [24:10<11:56,  2.01s/it] 67%|██████▋   | 715/1071 [24:15<17:12,  2.90s/it] 67%|██████▋   | 716/1071 [24:17<15:35,  2.63s/it] 67%|██████▋   | 717/1071 [24:19<14:26,  2.45s/it] 67%|██████▋   | 718/1071 [24:21<13:33,  2.31s/it] 67%|██████▋   | 719/1071 [24:23<12:56,  2.21s/it] 67%|██████▋   | 720/1071 [24:25<12:30,  2.14s/it]                                                   67%|██████▋   | 720/1071 [24:25<12:30,  2.14s/it] 67%|██████▋   | 721/1071 [24:27<12:12,  2.09s/it] 67%|██████▋   | 722/1071 [24:29<11:59,  2.06s/it] 68%|██████▊   | 723/1071 [24:31<11:51,  2.04s/it] 68%|██████▊   | 724/1071 [24:33<11:41,  2.02s/it] 68%|██████▊   | 725/1071 [24:35<11:36,  2.01s/it] 68%|██████▊   | 726/1071 [24:37<11:31,  2.00s/it] 68%|██████▊   | 727/1071 [24:39<11:26,  2.00s/it] 68%|██████▊   | 728/1071 [24:41<11:23,  1.99s/it] 68%|██████▊   | 729/1071 [24:43<11:20,  1.99s/it] 68%|██████▊   | 730/1071 [24:45<11:18,  1.99s/it]                                                   68%|██████▊   | 730/1071 [24:45<11:18,  1.99s/it] 68%|██████▊   | 731/1071 [24:47<11:16,  1.99s/it] 68%|██████▊   | 732/1071 [24:49<11:14,  1.99s/it] 68%|██████▊   | 733/1071 [24:51<11:11,  1.99s/it] 69%|██████▊   | 734/1071 [24:53<11:09,  1.99s/it] 69%|██████▊   | 735/1071 [24:55<11:07,  1.99s/it] 69%|██████▊   | 736/1071 [24:57<11:05,  1.99s/it] 69%|██████▉   | 737/1071 [24:59<11:02,  1.98s/it] 69%|██████▉   | 738/1071 [25:01<11:01,  1.99s/it] 69%|██████▉   | 739/1071 [25:03<10:58,  1.98s/it] 69%|██████▉   | 740/1071 [25:05<10:56,  1.98s/it]                                                   69%|██████▉   | 740/1071 [25:05<10:56,  1.98s/it] 69%|██████▉   | 741/1071 [25:07<10:54,  1.98s/it] 69%|██████▉   | 742/1071 [25:09<10:53,  1.99s/it] 69%|██████▉   | 743/1071 [25:11<10:52,  1.99s/it] 69%|██████▉   | 744/1071 [25:13<10:50,  1.99s/it] 70%|██████▉   | 745/1071 [25:15<10:48,  1.99s/it] 70%|██████▉   | 746/1071 [25:17<10:45,  1.99s/it] 70%|██████▉   | 747/1071 [25:19<10:42,  1.98s/it] 70%|██████▉   | 748/1071 [25:21<10:41,  1.99s/it] 70%|██████▉   | 749/1071 [25:23<10:39,  1.99s/it] 70%|███████   | 750/1071 [25:25<10:37,  1.98s/it]                                                   70%|███████   | 750/1071 [25:25<10:37,  1.98s/it] 70%|███████   | 751/1071 [25:27<10:35,  1.99s/it] 70%|███████   | 752/1071 [25:29<10:34,  1.99s/it] 70%|███████   | 753/1071 [25:31<10:32,  1.99s/it] 70%|███████   | 754/1071 [25:33<10:30,  1.99s/it] 70%|███████   | 755/1071 [25:35<10:28,  1.99s/it] 71%|███████   | 756/1071 [25:37<10:27,  1.99s/it] 71%|███████   | 757/1071 [25:39<10:24,  1.99s/it] 71%|███████   | 758/1071 [25:41<10:22,  1.99s/it] 71%|███████   | 759/1071 [25:43<10:19,  1.99s/it] 71%|███████   | 760/1071 [25:45<10:17,  1.99s/it]                                                   71%|███████   | 760/1071 [25:45<10:17,  1.99s/it] 71%|███████   | 761/1071 [25:47<10:16,  1.99s/it] 71%|███████   | 762/1071 [25:49<10:12,  1.98s/it] 71%|███████   | 763/1071 [25:51<10:09,  1.98s/it] 71%|███████▏  | 764/1071 [25:53<10:06,  1.98s/it] 71%|███████▏  | 765/1071 [25:55<10:04,  1.98s/it] 72%|███████▏  | 766/1071 [25:57<10:03,  1.98s/it] 72%|███████▏  | 767/1071 [25:59<10:01,  1.98s/it] 72%|███████▏  | 768/1071 [26:01<10:00,  1.98s/it] 72%|███████▏  | 769/1071 [26:02<09:58,  1.98s/it] 72%|███████▏  | 770/1071 [26:04<09:55,  1.98s/it]                                                   72%|███████▏  | 770/1071 [26:05<09:55,  1.98s/it] 72%|███████▏  | 771/1071 [26:06<09:53,  1.98s/it] 72%|███████▏  | 772/1071 [26:08<09:51,  1.98s/it] 72%|███████▏  | 773/1071 [26:10<09:49,  1.98s/it] 72%|███████▏  | 774/1071 [26:12<09:46,  1.98s/it] 72%|███████▏  | 775/1071 [26:14<09:45,  1.98s/it] 72%|███████▏  | 776/1071 [26:16<09:43,  1.98s/it] 73%|███████▎  | 777/1071 [26:18<09:41,  1.98s/it] 73%|███████▎  | 778/1071 [26:20<09:40,  1.98s/it] 73%|███████▎  | 779/1071 [26:22<09:37,  1.98s/it] 73%|███████▎  | 780/1071 [26:24<09:35,  1.98s/it]                                                   73%|███████▎  | 780/1071 [26:24<09:35,  1.98s/it] 73%|███████▎  | 781/1071 [26:26<09:33,  1.98s/it] 73%|███████▎  | 782/1071 [26:28<09:32,  1.98s/it] 73%|███████▎  | 783/1071 [26:30<09:31,  1.98s/it] 73%|███████▎  | 784/1071 [26:32<09:29,  1.98s/it] 73%|███████▎  | 785/1071 [26:34<09:27,  1.99s/it] 73%|███████▎  | 786/1071 [26:36<09:25,  1.98s/it] 73%|███████▎  | 787/1071 [26:38<09:21,  1.98s/it] 74%|███████▎  | 788/1071 [26:40<09:19,  1.98s/it] 74%|███████▎  | 789/1071 [26:42<09:16,  1.97s/it] 74%|███████▍  | 790/1071 [26:44<09:15,  1.98s/it]                                                   74%|███████▍  | 790/1071 [26:44<09:15,  1.98s/it] 74%|███████▍  | 791/1071 [26:46<09:14,  1.98s/it] 74%|███████▍  | 792/1071 [26:48<09:12,  1.98s/it] 74%|███████▍  | 793/1071 [26:50<09:10,  1.98s/it] 74%|███████▍  | 794/1071 [26:52<09:09,  1.98s/it] 74%|███████▍  | 795/1071 [26:54<09:06,  1.98s/it] 74%|███████▍  | 796/1071 [26:56<09:04,  1.98s/it] 74%|███████▍  | 797/1071 [26:58<09:01,  1.98s/it] 75%|███████▍  | 798/1071 [27:00<08:59,  1.98s/it] 75%|███████▍  | 799/1071 [27:02<08:58,  1.98s/it] 75%|███████▍  | 800/1071 [27:04<08:55,  1.98s/it]                                                   75%|███████▍  | 800/1071 [27:04<08:55,  1.98s/it][INFO|trainer.py:4643] 2025-10-25 00:32:49,835 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-25 00:32:49,835 >>   Num examples = 47
[INFO|trainer.py:4648] 2025-10-25 00:32:49,835 >>   Batch size = 8

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|██████████| 2/2 [00:00<00:00,  5.34it/s][A                                                  
                                             [A 75%|███████▍  | 800/1071 [27:05<08:55,  1.98s/it]
100%|██████████| 2/2 [00:00<00:00,  5.34it/s][A
                                             [A[INFO|trainer.py:4309] 2025-10-25 00:32:51,226 >> Saving model checkpoint to saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-800
[INFO|configuration_utils.py:491] 2025-10-25 00:32:51,231 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-800/config.json
[INFO|configuration_utils.py:757] 2025-10-25 00:32:51,232 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-800/generation_config.json
[INFO|modeling_utils.py:4189] 2025-10-25 00:32:56,455 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-800/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2421] 2025-10-25 00:32:56,456 >> chat template saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-800/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-25 00:32:56,457 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-25 00:32:56,457 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-800/special_tokens_map.json
[INFO|image_processing_base.py:253] 2025-10-25 00:33:06,595 >> Image processor saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-800/preprocessor_config.json
[INFO|tokenization_utils_base.py:2421] 2025-10-25 00:33:06,945 >> chat template saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-800/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-25 00:33:07,646 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-25 00:33:07,646 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-800/special_tokens_map.json
[INFO|video_processing_utils.py:600] 2025-10-25 00:33:09,259 >> Video processor saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-800/video_preprocessor_config.json
[INFO|processing_utils.py:814] 2025-10-25 00:33:09,477 >> chat template saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-800/chat_template.jinja
 75%|███████▍  | 801/1071 [27:26<35:43,  7.94s/it] 75%|███████▍  | 802/1071 [27:28<27:34,  6.15s/it] 75%|███████▍  | 803/1071 [27:30<21:53,  4.90s/it] 75%|███████▌  | 804/1071 [27:32<17:54,  4.02s/it] 75%|███████▌  | 805/1071 [27:34<15:07,  3.41s/it] 75%|███████▌  | 806/1071 [27:36<13:09,  2.98s/it] 75%|███████▌  | 807/1071 [27:38<11:47,  2.68s/it] 75%|███████▌  | 808/1071 [27:40<10:48,  2.47s/it] 76%|███████▌  | 809/1071 [27:41<10:07,  2.32s/it] 76%|███████▌  | 810/1071 [27:43<09:38,  2.22s/it]                                                   76%|███████▌  | 810/1071 [27:44<09:38,  2.22s/it] 76%|███████▌  | 811/1071 [27:45<09:17,  2.14s/it] 76%|███████▌  | 812/1071 [27:47<09:02,  2.09s/it] 76%|███████▌  | 813/1071 [27:49<08:50,  2.06s/it] 76%|███████▌  | 814/1071 [27:51<08:41,  2.03s/it] 76%|███████▌  | 815/1071 [27:53<08:35,  2.02s/it] 76%|███████▌  | 816/1071 [27:55<08:30,  2.00s/it] 76%|███████▋  | 817/1071 [27:57<08:26,  1.99s/it] 76%|███████▋  | 818/1071 [27:59<08:23,  1.99s/it] 76%|███████▋  | 819/1071 [28:01<08:20,  1.98s/it] 77%|███████▋  | 820/1071 [28:03<08:18,  1.98s/it]                                                   77%|███████▋  | 820/1071 [28:03<08:18,  1.98s/it] 77%|███████▋  | 821/1071 [28:05<08:15,  1.98s/it] 77%|███████▋  | 822/1071 [28:07<08:12,  1.98s/it] 77%|███████▋  | 823/1071 [28:09<08:10,  1.98s/it] 77%|███████▋  | 824/1071 [28:11<08:08,  1.98s/it] 77%|███████▋  | 825/1071 [28:13<08:06,  1.98s/it] 77%|███████▋  | 826/1071 [28:15<08:04,  1.98s/it] 77%|███████▋  | 827/1071 [28:17<08:02,  1.98s/it] 77%|███████▋  | 828/1071 [28:19<08:00,  1.98s/it] 77%|███████▋  | 829/1071 [28:21<07:59,  1.98s/it] 77%|███████▋  | 830/1071 [28:23<07:56,  1.98s/it]                                                   77%|███████▋  | 830/1071 [28:23<07:56,  1.98s/it] 78%|███████▊  | 831/1071 [28:25<07:54,  1.98s/it] 78%|███████▊  | 832/1071 [28:27<07:52,  1.98s/it] 78%|███████▊  | 833/1071 [28:29<07:50,  1.98s/it] 78%|███████▊  | 834/1071 [28:31<07:48,  1.98s/it] 78%|███████▊  | 835/1071 [28:33<07:46,  1.98s/it] 78%|███████▊  | 836/1071 [28:35<07:43,  1.97s/it] 78%|███████▊  | 837/1071 [28:37<07:42,  1.97s/it] 78%|███████▊  | 838/1071 [28:39<07:40,  1.98s/it] 78%|███████▊  | 839/1071 [28:41<07:39,  1.98s/it] 78%|███████▊  | 840/1071 [28:43<07:37,  1.98s/it]                                                   78%|███████▊  | 840/1071 [28:43<07:37,  1.98s/it] 79%|███████▊  | 841/1071 [28:45<07:34,  1.98s/it] 79%|███████▊  | 842/1071 [28:47<07:32,  1.98s/it] 79%|███████▊  | 843/1071 [28:49<07:30,  1.98s/it] 79%|███████▉  | 844/1071 [28:51<07:28,  1.98s/it] 79%|███████▉  | 845/1071 [28:53<07:26,  1.98s/it] 79%|███████▉  | 846/1071 [28:55<07:24,  1.98s/it] 79%|███████▉  | 847/1071 [28:57<07:22,  1.98s/it] 79%|███████▉  | 848/1071 [28:59<07:20,  1.97s/it] 79%|███████▉  | 849/1071 [29:01<07:18,  1.97s/it] 79%|███████▉  | 850/1071 [29:03<07:16,  1.98s/it]                                                   79%|███████▉  | 850/1071 [29:03<07:16,  1.98s/it] 79%|███████▉  | 851/1071 [29:04<07:14,  1.98s/it] 80%|███████▉  | 852/1071 [29:06<07:13,  1.98s/it] 80%|███████▉  | 853/1071 [29:08<07:10,  1.98s/it] 80%|███████▉  | 854/1071 [29:10<07:08,  1.98s/it] 80%|███████▉  | 855/1071 [29:12<07:06,  1.98s/it] 80%|███████▉  | 856/1071 [29:14<07:04,  1.98s/it] 80%|████████  | 857/1071 [29:16<07:02,  1.98s/it] 80%|████████  | 858/1071 [29:18<07:00,  1.97s/it] 80%|████████  | 859/1071 [29:20<06:59,  1.98s/it] 80%|████████  | 860/1071 [29:22<06:57,  1.98s/it]                                                   80%|████████  | 860/1071 [29:22<06:57,  1.98s/it] 80%|████████  | 861/1071 [29:24<06:55,  1.98s/it] 80%|████████  | 862/1071 [29:26<06:53,  1.98s/it] 81%|████████  | 863/1071 [29:28<06:51,  1.98s/it] 81%|████████  | 864/1071 [29:30<06:49,  1.98s/it] 81%|████████  | 865/1071 [29:32<06:47,  1.98s/it] 81%|████████  | 866/1071 [29:34<06:45,  1.98s/it] 81%|████████  | 867/1071 [29:36<06:43,  1.98s/it] 81%|████████  | 868/1071 [29:38<06:42,  1.98s/it] 81%|████████  | 869/1071 [29:40<06:39,  1.98s/it] 81%|████████  | 870/1071 [29:42<06:37,  1.98s/it]                                                   81%|████████  | 870/1071 [29:42<06:37,  1.98s/it] 81%|████████▏ | 871/1071 [29:44<06:35,  1.98s/it] 81%|████████▏ | 872/1071 [29:46<06:33,  1.98s/it] 82%|████████▏ | 873/1071 [29:48<06:31,  1.98s/it] 82%|████████▏ | 874/1071 [29:50<06:29,  1.98s/it] 82%|████████▏ | 875/1071 [29:52<06:27,  1.98s/it] 82%|████████▏ | 876/1071 [29:54<06:25,  1.98s/it] 82%|████████▏ | 877/1071 [29:56<06:23,  1.98s/it] 82%|████████▏ | 878/1071 [29:58<06:21,  1.98s/it] 82%|████████▏ | 879/1071 [30:00<06:20,  1.98s/it] 82%|████████▏ | 880/1071 [30:02<06:18,  1.98s/it]                                                   82%|████████▏ | 880/1071 [30:02<06:18,  1.98s/it] 82%|████████▏ | 881/1071 [30:04<06:16,  1.98s/it] 82%|████████▏ | 882/1071 [30:06<06:14,  1.98s/it] 82%|████████▏ | 883/1071 [30:08<06:12,  1.98s/it] 83%|████████▎ | 884/1071 [30:10<06:10,  1.98s/it] 83%|████████▎ | 885/1071 [30:12<06:08,  1.98s/it] 83%|████████▎ | 886/1071 [30:14<06:06,  1.98s/it] 83%|████████▎ | 887/1071 [30:16<06:04,  1.98s/it] 83%|████████▎ | 888/1071 [30:18<06:02,  1.98s/it] 83%|████████▎ | 889/1071 [30:20<06:00,  1.98s/it] 83%|████████▎ | 890/1071 [30:22<05:58,  1.98s/it]                                                   83%|████████▎ | 890/1071 [30:22<05:58,  1.98s/it] 83%|████████▎ | 891/1071 [30:24<05:56,  1.98s/it] 83%|████████▎ | 892/1071 [30:26<05:54,  1.98s/it] 83%|████████▎ | 893/1071 [30:28<05:52,  1.98s/it] 83%|████████▎ | 894/1071 [30:30<05:50,  1.98s/it] 84%|████████▎ | 895/1071 [30:32<05:48,  1.98s/it] 84%|████████▎ | 896/1071 [30:34<05:46,  1.98s/it] 84%|████████▍ | 897/1071 [30:36<05:44,  1.98s/it] 84%|████████▍ | 898/1071 [30:38<05:42,  1.98s/it] 84%|████████▍ | 899/1071 [30:39<05:40,  1.98s/it] 84%|████████▍ | 900/1071 [30:41<05:38,  1.98s/it]                                                   84%|████████▍ | 900/1071 [30:42<05:38,  1.98s/it][INFO|trainer.py:4643] 2025-10-25 00:36:27,494 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-25 00:36:27,494 >>   Num examples = 47
[INFO|trainer.py:4648] 2025-10-25 00:36:27,494 >>   Batch size = 8

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|██████████| 2/2 [00:00<00:00,  5.39it/s][A                                                  
                                             [A 84%|████████▍ | 900/1071 [30:43<05:38,  1.98s/it]
100%|██████████| 2/2 [00:00<00:00,  5.39it/s][A
                                             [A 84%|████████▍ | 901/1071 [30:45<06:47,  2.39s/it] 84%|████████▍ | 902/1071 [30:47<06:23,  2.27s/it] 84%|████████▍ | 903/1071 [30:49<06:06,  2.18s/it] 84%|████████▍ | 904/1071 [30:51<05:53,  2.12s/it] 85%|████████▍ | 905/1071 [30:53<05:44,  2.08s/it] 85%|████████▍ | 906/1071 [30:55<05:37,  2.05s/it] 85%|████████▍ | 907/1071 [30:57<05:31,  2.02s/it] 85%|████████▍ | 908/1071 [30:59<05:27,  2.01s/it] 85%|████████▍ | 909/1071 [31:01<05:24,  2.00s/it] 85%|████████▍ | 910/1071 [31:03<05:20,  1.99s/it]                                                   85%|████████▍ | 910/1071 [31:03<05:20,  1.99s/it] 85%|████████▌ | 911/1071 [31:05<05:17,  1.99s/it] 85%|████████▌ | 912/1071 [31:07<05:14,  1.98s/it] 85%|████████▌ | 913/1071 [31:09<05:12,  1.98s/it] 85%|████████▌ | 914/1071 [31:11<05:10,  1.98s/it] 85%|████████▌ | 915/1071 [31:12<05:08,  1.98s/it] 86%|████████▌ | 916/1071 [31:14<05:05,  1.97s/it] 86%|████████▌ | 917/1071 [31:16<05:04,  1.97s/it] 86%|████████▌ | 918/1071 [31:18<05:02,  1.98s/it] 86%|████████▌ | 919/1071 [31:20<05:00,  1.98s/it] 86%|████████▌ | 920/1071 [31:22<04:58,  1.98s/it]                                                   86%|████████▌ | 920/1071 [31:22<04:58,  1.98s/it] 86%|████████▌ | 921/1071 [31:24<04:56,  1.98s/it] 86%|████████▌ | 922/1071 [31:26<04:54,  1.98s/it] 86%|████████▌ | 923/1071 [31:28<04:53,  1.98s/it] 86%|████████▋ | 924/1071 [31:30<04:50,  1.98s/it] 86%|████████▋ | 925/1071 [31:32<04:48,  1.98s/it] 86%|████████▋ | 926/1071 [31:34<04:46,  1.98s/it] 87%|████████▋ | 927/1071 [31:36<04:44,  1.98s/it] 87%|████████▋ | 928/1071 [31:38<04:42,  1.97s/it] 87%|████████▋ | 929/1071 [31:40<04:40,  1.98s/it] 87%|████████▋ | 930/1071 [31:42<04:38,  1.98s/it]                                                   87%|████████▋ | 930/1071 [31:42<04:38,  1.98s/it] 87%|████████▋ | 931/1071 [31:44<04:36,  1.98s/it] 87%|████████▋ | 932/1071 [31:46<04:34,  1.98s/it] 87%|████████▋ | 933/1071 [31:48<04:32,  1.97s/it] 87%|████████▋ | 934/1071 [31:50<04:30,  1.97s/it] 87%|████████▋ | 935/1071 [31:52<04:28,  1.97s/it] 87%|████████▋ | 936/1071 [31:54<04:26,  1.97s/it] 87%|████████▋ | 937/1071 [31:56<04:24,  1.98s/it] 88%|████████▊ | 938/1071 [31:58<04:22,  1.98s/it] 88%|████████▊ | 939/1071 [32:00<04:20,  1.98s/it] 88%|████████▊ | 940/1071 [32:02<04:19,  1.98s/it]                                                   88%|████████▊ | 940/1071 [32:02<04:19,  1.98s/it] 88%|████████▊ | 941/1071 [32:04<04:17,  1.98s/it] 88%|████████▊ | 942/1071 [32:06<04:15,  1.98s/it] 88%|████████▊ | 943/1071 [32:08<04:13,  1.98s/it] 88%|████████▊ | 944/1071 [32:10<04:11,  1.98s/it] 88%|████████▊ | 945/1071 [32:12<04:08,  1.98s/it] 88%|████████▊ | 946/1071 [32:14<04:07,  1.98s/it] 88%|████████▊ | 947/1071 [32:16<04:05,  1.98s/it] 89%|████████▊ | 948/1071 [32:18<04:03,  1.98s/it] 89%|████████▊ | 949/1071 [32:20<04:01,  1.98s/it] 89%|████████▊ | 950/1071 [32:22<03:59,  1.98s/it]                                                   89%|████████▊ | 950/1071 [32:22<03:59,  1.98s/it] 89%|████████▉ | 951/1071 [32:24<03:58,  1.98s/it] 89%|████████▉ | 952/1071 [32:26<03:55,  1.98s/it] 89%|████████▉ | 953/1071 [32:28<03:53,  1.98s/it] 89%|████████▉ | 954/1071 [32:30<03:51,  1.98s/it] 89%|████████▉ | 955/1071 [32:32<03:50,  1.98s/it] 89%|████████▉ | 956/1071 [32:34<03:47,  1.98s/it] 89%|████████▉ | 957/1071 [32:36<03:45,  1.98s/it] 89%|████████▉ | 958/1071 [32:38<03:44,  1.98s/it] 90%|████████▉ | 959/1071 [32:40<03:41,  1.98s/it] 90%|████████▉ | 960/1071 [32:42<03:40,  1.98s/it]                                                   90%|████████▉ | 960/1071 [32:42<03:40,  1.98s/it] 90%|████████▉ | 961/1071 [32:44<03:38,  1.99s/it] 90%|████████▉ | 962/1071 [32:45<03:36,  1.98s/it] 90%|████████▉ | 963/1071 [32:47<03:34,  1.98s/it] 90%|█████████ | 964/1071 [32:49<03:32,  1.98s/it] 90%|█████████ | 965/1071 [32:51<03:30,  1.98s/it] 90%|█████████ | 966/1071 [32:53<03:27,  1.98s/it] 90%|█████████ | 967/1071 [32:55<03:25,  1.98s/it] 90%|█████████ | 968/1071 [32:57<03:23,  1.98s/it] 90%|█████████ | 969/1071 [32:59<03:21,  1.98s/it] 91%|█████████ | 970/1071 [33:01<03:19,  1.98s/it]                                                   91%|█████████ | 970/1071 [33:01<03:19,  1.98s/it] 91%|█████████ | 971/1071 [33:03<03:17,  1.98s/it] 91%|█████████ | 972/1071 [33:05<03:15,  1.98s/it] 91%|█████████ | 973/1071 [33:07<03:14,  1.98s/it] 91%|█████████ | 974/1071 [33:09<03:11,  1.98s/it] 91%|█████████ | 975/1071 [33:11<03:09,  1.98s/it] 91%|█████████ | 976/1071 [33:13<03:07,  1.98s/it] 91%|█████████ | 977/1071 [33:15<03:05,  1.98s/it] 91%|█████████▏| 978/1071 [33:17<03:03,  1.98s/it] 91%|█████████▏| 979/1071 [33:19<03:01,  1.98s/it] 92%|█████████▏| 980/1071 [33:21<02:59,  1.98s/it]                                                   92%|█████████▏| 980/1071 [33:21<02:59,  1.98s/it] 92%|█████████▏| 981/1071 [33:23<02:57,  1.97s/it] 92%|█████████▏| 982/1071 [33:25<02:55,  1.97s/it] 92%|█████████▏| 983/1071 [33:27<02:53,  1.97s/it] 92%|█████████▏| 984/1071 [33:29<02:51,  1.97s/it] 92%|█████████▏| 985/1071 [33:31<02:49,  1.98s/it] 92%|█████████▏| 986/1071 [33:33<02:47,  1.98s/it] 92%|█████████▏| 987/1071 [33:35<02:46,  1.98s/it] 92%|█████████▏| 988/1071 [33:37<02:44,  1.98s/it] 92%|█████████▏| 989/1071 [33:39<02:42,  1.98s/it] 92%|█████████▏| 990/1071 [33:41<02:40,  1.98s/it]                                                   92%|█████████▏| 990/1071 [33:41<02:40,  1.98s/it] 93%|█████████▎| 991/1071 [33:43<02:38,  1.98s/it] 93%|█████████▎| 992/1071 [33:45<02:36,  1.98s/it] 93%|█████████▎| 993/1071 [33:47<02:34,  1.98s/it] 93%|█████████▎| 994/1071 [33:49<02:32,  1.98s/it] 93%|█████████▎| 995/1071 [33:51<02:30,  1.98s/it] 93%|█████████▎| 996/1071 [33:53<02:28,  1.97s/it] 93%|█████████▎| 997/1071 [33:55<02:26,  1.98s/it] 93%|█████████▎| 998/1071 [33:57<02:24,  1.98s/it] 93%|█████████▎| 999/1071 [33:59<02:22,  1.98s/it] 93%|█████████▎| 1000/1071 [34:01<02:20,  1.98s/it]                                                    93%|█████████▎| 1000/1071 [34:01<02:20,  1.98s/it][INFO|trainer.py:4643] 2025-10-25 00:39:46,634 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-25 00:39:46,634 >>   Num examples = 47
[INFO|trainer.py:4648] 2025-10-25 00:39:46,634 >>   Batch size = 8

  0%|          | 0/2 [00:00<?, ?it/s][A
100%|██████████| 2/2 [00:00<00:00,  5.48it/s][A                                                   
                                             [A 93%|█████████▎| 1000/1071 [34:02<02:20,  1.98s/it]
100%|██████████| 2/2 [00:00<00:00,  5.48it/s][A
                                             [A 93%|█████████▎| 1001/1071 [34:04<02:47,  2.39s/it] 94%|█████████▎| 1002/1071 [34:06<02:36,  2.27s/it] 94%|█████████▎| 1003/1071 [34:08<02:28,  2.18s/it] 94%|█████████▎| 1004/1071 [34:10<02:22,  2.12s/it] 94%|█████████▍| 1005/1071 [34:12<02:17,  2.08s/it] 94%|█████████▍| 1006/1071 [34:14<02:13,  2.05s/it] 94%|█████████▍| 1007/1071 [34:16<02:09,  2.03s/it] 94%|█████████▍| 1008/1071 [34:18<02:06,  2.01s/it] 94%|█████████▍| 1009/1071 [34:20<02:04,  2.00s/it] 94%|█████████▍| 1010/1071 [34:22<02:01,  1.99s/it]                                                    94%|█████████▍| 1010/1071 [34:22<02:01,  1.99s/it] 94%|█████████▍| 1011/1071 [34:24<01:59,  1.99s/it] 94%|█████████▍| 1012/1071 [34:26<01:57,  1.99s/it] 95%|█████████▍| 1013/1071 [34:28<01:55,  1.98s/it] 95%|█████████▍| 1014/1071 [34:30<01:53,  1.98s/it] 95%|█████████▍| 1015/1071 [34:32<01:50,  1.98s/it] 95%|█████████▍| 1016/1071 [34:34<01:48,  1.98s/it] 95%|█████████▍| 1017/1071 [34:36<01:46,  1.98s/it] 95%|█████████▌| 1018/1071 [34:38<01:44,  1.98s/it] 95%|█████████▌| 1019/1071 [34:40<01:42,  1.98s/it] 95%|█████████▌| 1020/1071 [34:42<01:40,  1.98s/it]                                                    95%|█████████▌| 1020/1071 [34:42<01:40,  1.98s/it] 95%|█████████▌| 1021/1071 [34:44<01:38,  1.98s/it] 95%|█████████▌| 1022/1071 [34:46<01:37,  1.98s/it] 96%|█████████▌| 1023/1071 [34:48<01:34,  1.98s/it] 96%|█████████▌| 1024/1071 [34:49<01:32,  1.98s/it] 96%|█████████▌| 1025/1071 [34:51<01:31,  1.98s/it] 96%|█████████▌| 1026/1071 [34:53<01:29,  1.98s/it] 96%|█████████▌| 1027/1071 [34:55<01:27,  1.98s/it] 96%|█████████▌| 1028/1071 [34:57<01:25,  1.98s/it] 96%|█████████▌| 1029/1071 [34:59<01:23,  1.98s/it] 96%|█████████▌| 1030/1071 [35:01<01:21,  1.98s/it]                                                    96%|█████████▌| 1030/1071 [35:01<01:21,  1.98s/it] 96%|█████████▋| 1031/1071 [35:03<01:19,  1.98s/it] 96%|█████████▋| 1032/1071 [35:05<01:17,  1.98s/it] 96%|█████████▋| 1033/1071 [35:07<01:15,  1.98s/it] 97%|█████████▋| 1034/1071 [35:09<01:13,  1.98s/it] 97%|█████████▋| 1035/1071 [35:11<01:11,  1.98s/it] 97%|█████████▋| 1036/1071 [35:13<01:09,  1.98s/it] 97%|█████████▋| 1037/1071 [35:15<01:07,  1.97s/it] 97%|█████████▋| 1038/1071 [35:17<01:05,  1.98s/it] 97%|█████████▋| 1039/1071 [35:19<01:03,  1.98s/it] 97%|█████████▋| 1040/1071 [35:21<01:01,  1.98s/it]                                                    97%|█████████▋| 1040/1071 [35:21<01:01,  1.98s/it] 97%|█████████▋| 1041/1071 [35:23<00:59,  1.98s/it] 97%|█████████▋| 1042/1071 [35:25<00:57,  1.98s/it] 97%|█████████▋| 1043/1071 [35:27<00:55,  1.97s/it] 97%|█████████▋| 1044/1071 [35:29<00:53,  1.98s/it] 98%|█████████▊| 1045/1071 [35:31<00:51,  1.98s/it] 98%|█████████▊| 1046/1071 [35:33<00:49,  1.97s/it] 98%|█████████▊| 1047/1071 [35:35<00:47,  1.97s/it] 98%|█████████▊| 1048/1071 [35:37<00:45,  1.98s/it] 98%|█████████▊| 1049/1071 [35:39<00:43,  1.98s/it] 98%|█████████▊| 1050/1071 [35:41<00:41,  1.97s/it]                                                    98%|█████████▊| 1050/1071 [35:41<00:41,  1.97s/it] 98%|█████████▊| 1051/1071 [35:43<00:39,  1.98s/it] 98%|█████████▊| 1052/1071 [35:45<00:37,  1.98s/it] 98%|█████████▊| 1053/1071 [35:47<00:35,  1.98s/it] 98%|█████████▊| 1054/1071 [35:49<00:33,  1.98s/it] 99%|█████████▊| 1055/1071 [35:51<00:31,  1.98s/it] 99%|█████████▊| 1056/1071 [35:53<00:29,  1.98s/it] 99%|█████████▊| 1057/1071 [35:55<00:27,  1.98s/it] 99%|█████████▉| 1058/1071 [35:57<00:25,  1.98s/it] 99%|█████████▉| 1059/1071 [35:59<00:23,  1.98s/it] 99%|█████████▉| 1060/1071 [36:01<00:21,  1.98s/it]                                                    99%|█████████▉| 1060/1071 [36:01<00:21,  1.98s/it] 99%|█████████▉| 1061/1071 [36:03<00:19,  1.98s/it] 99%|█████████▉| 1062/1071 [36:05<00:17,  1.98s/it] 99%|█████████▉| 1063/1071 [36:07<00:15,  1.98s/it] 99%|█████████▉| 1064/1071 [36:09<00:13,  1.98s/it] 99%|█████████▉| 1065/1071 [36:11<00:11,  1.98s/it]100%|█████████▉| 1066/1071 [36:13<00:09,  1.97s/it]100%|█████████▉| 1067/1071 [36:14<00:07,  1.97s/it]100%|█████████▉| 1068/1071 [36:16<00:05,  1.97s/it]100%|█████████▉| 1069/1071 [36:18<00:03,  1.97s/it]100%|█████████▉| 1070/1071 [36:20<00:01,  1.97s/it]                                                   100%|█████████▉| 1070/1071 [36:20<00:01,  1.97s/it]100%|██████████| 1071/1071 [36:22<00:00,  2.00s/it][INFO|trainer.py:4309] 2025-10-25 00:42:08,464 >> Saving model checkpoint to saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-1071
[INFO|configuration_utils.py:491] 2025-10-25 00:42:08,479 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-1071/config.json
[INFO|configuration_utils.py:757] 2025-10-25 00:42:08,479 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-1071/generation_config.json
[INFO|modeling_utils.py:4189] 2025-10-25 00:42:12,840 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-1071/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2421] 2025-10-25 00:42:12,842 >> chat template saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-1071/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-25 00:42:12,842 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-1071/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-25 00:42:12,843 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-1071/special_tokens_map.json
[INFO|image_processing_base.py:253] 2025-10-25 00:42:21,948 >> Image processor saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-1071/preprocessor_config.json
[INFO|tokenization_utils_base.py:2421] 2025-10-25 00:42:22,746 >> chat template saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-1071/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-25 00:42:23,139 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-1071/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-25 00:42:23,140 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-1071/special_tokens_map.json
[INFO|video_processing_utils.py:600] 2025-10-25 00:42:24,234 >> Video processor saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-1071/video_preprocessor_config.json
[INFO|processing_utils.py:814] 2025-10-25 00:42:24,234 >> chat template saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/checkpoint-1071/chat_template.jinja
[INFO|trainer.py:2810] 2025-10-25 00:42:24,475 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1071/1071 [36:39<00:00,  2.00s/it]100%|██████████| 1071/1071 [36:39<00:00,  2.05s/it]
[INFO|image_processing_base.py:253] 2025-10-25 00:42:24,481 >> Image processor saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/preprocessor_config.json
[INFO|tokenization_utils_base.py:2421] 2025-10-25 00:42:24,482 >> chat template saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-25 00:42:24,483 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-25 00:42:24,483 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/special_tokens_map.json
[INFO|video_processing_utils.py:600] 2025-10-25 00:42:24,569 >> Video processor saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/video_preprocessor_config.json
[INFO|processing_utils.py:814] 2025-10-25 00:42:24,569 >> chat template saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/chat_template.jinja
[INFO|trainer.py:4309] 2025-10-25 00:42:24,811 >> Saving model checkpoint to saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train
[INFO|configuration_utils.py:491] 2025-10-25 00:42:24,815 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/config.json
[INFO|configuration_utils.py:757] 2025-10-25 00:42:24,816 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/generation_config.json
[INFO|modeling_utils.py:4189] 2025-10-25 00:42:29,767 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2421] 2025-10-25 00:42:29,768 >> chat template saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-25 00:42:29,769 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-25 00:42:29,769 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_ablation_multi_frame_8_train/special_tokens_map.json
[INFO|trainer.py:4643] 2025-10-25 00:42:31,529 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-25 00:42:31,530 >>   Num examples = 47
[INFO|trainer.py:4648] 2025-10-25 00:42:31,530 >>   Batch size = 8
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00,  5.43it/s]100%|██████████| 2/2 [00:00<00:00,  5.41it/s]
[INFO|modelcard.py:456] 2025-10-25 00:42:32,833 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
