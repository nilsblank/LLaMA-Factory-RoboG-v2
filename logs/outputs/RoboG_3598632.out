Using config: examples/train_full/qwen3vl/qwen3vl_roboG_poc_box_qwen_only_video.yaml
[INFO|2025-10-25 01:12:48] llamafactory.launcher:143 >> Initializing 4 distributed tasks at: 127.0.0.1:59159
[2025-10-25 01:13:06,723] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-25 01:13:06,723] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-25 01:13:06,723] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-25 01:13:06,723] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: sentence-transformers not installed, falling back to simple string similarity for LabelEvaluator. Install with `pip install sentence-transformers` for better results.Warning: sentence-transformers not installed, falling back to simple string similarity for LabelEvaluator. Install with `pip install sentence-transformers` for better results.
Warning: sentence-transformers not installed, falling back to simple string similarity for LabelEvaluator. Install with `pip install sentence-transformers` for better results.
Warning: sentence-transformers not installed, falling back to simple string similarity for LabelEvaluator. Install with `pip install sentence-transformers` for better results.

[INFO|2025-10-25 01:13:42] llamafactory.hparams.parser:426 >> Process rank: 2, world size: 4, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-10-25 01:13:42] llamafactory.hparams.parser:426 >> Process rank: 0, world size: 4, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-10-25 01:13:42] llamafactory.hparams.parser:426 >> Process rank: 3, world size: 4, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-10-25 01:13:42] llamafactory.hparams.parser:426 >> Process rank: 1, world size: 4, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-10-25 01:13:45] llamafactory.data.loader:143 >> Loading dataset /home/hk-project-sustainebot/bm3844/datasets/datasets/robogrounder/qwen3-vl/roboG_stagepoc_grounding_only_video_train.jsonl...
[INFO|2025-10-25 01:13:52] llamafactory.data.loader:143 >> Loading dataset /home/hk-project-sustainebot/bm3844/datasets/datasets/robogrounder/qwen3-vl/roboG_stagepoc_grounding_only_video_eval.jsonl...
training example:
input_ids:
[151644, 872, 198, 27, 15, 13, 17, 6486, 29, 151652, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151653, 758, 279, 2766, 11, 264, 12305, 54215, 458, 1633, 13, 9258, 279, 2383, 323, 13934, 315, 279, 2856, 3728, 315, 279, 16282, 291, 1633, 304, 4718, 3561, 13, 151645, 198, 151644, 77091, 198, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 17, 23, 24, 11, 220, 16, 19, 15, 11, 220, 19, 23, 24, 11, 220, 17, 24, 23, 1125, 330, 1502, 788, 330, 32578, 6375, 16707, 921, 73594, 151645, 198]
inputs:
<|im_start|>user
<0.2 seconds><|vision_start|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|vision_end|> In the video, a robot manipulated an object. Output the label and coordinates of the initial location of the interacted object in JSON format.<|im_end|>
<|im_start|>assistant
```json
[
{"bbox_2d": [289, 140, 489, 298], "label": "clothes"}
]
```<|im_end|>

label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 17, 23, 24, 11, 220, 16, 19, 15, 11, 220, 19, 23, 24, 11, 220, 17, 24, 23, 1125, 330, 1502, 788, 330, 32578, 6375, 16707, 921, 73594, 151645, 198]
labels:
```json
[
{"bbox_2d": [289, 140, 489, 298], "label": "clothes"}
]
```<|im_end|>

eval example:
input_ids:
[151644, 872, 198, 27, 15, 13, 17, 6486, 29, 151652, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151653, 758, 279, 2766, 11, 264, 12305, 54215, 458, 1633, 13, 9258, 279, 2383, 323, 13934, 315, 279, 2856, 3728, 315, 279, 16282, 291, 1633, 304, 4718, 3561, 13, 151645, 198, 151644, 77091, 198, 785, 1633, 54215, 553, 279, 12305, 374, 279, 18575, 1633, 624, 11445, 2856, 3728, 374, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 16, 22, 21, 11, 220, 17, 18, 15, 11, 220, 17, 16, 24, 11, 220, 17, 22, 15, 1125, 330, 1502, 788, 330, 34164, 1633, 16707, 921, 73594, 151645, 198]
inputs:
<|im_start|>user
<0.2 seconds><|vision_start|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|video_pad|><|vision_end|> In the video, a robot manipulated an object. Output the label and coordinates of the initial location of the interacted object in JSON format.<|im_end|>
<|im_start|>assistant
The object manipulated by the robot is the orange object.
 Its initial location is:
```json
[
{"bbox_2d": [176, 230, 219, 270], "label": "orange object"}
]
```<|im_end|>

label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 785, 1633, 54215, 553, 279, 12305, 374, 279, 18575, 1633, 624, 11445, 2856, 3728, 374, 510, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 16, 22, 21, 11, 220, 17, 18, 15, 11, 220, 17, 16, 24, 11, 220, 17, 22, 15, 1125, 330, 1502, 788, 330, 34164, 1633, 16707, 921, 73594, 151645, 198]
labels:
The object manipulated by the robot is the orange object.
 Its initial location is:
```json
[
{"bbox_2d": [176, 230, 219, 270], "label": "orange object"}
]
```<|im_end|>

[INFO|2025-10-25 01:17:23] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
[INFO|2025-10-25 01:17:52] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
[INFO|2025-10-25 01:17:52] llamafactory.model.model_utils.attention:143 >> Using FlashAttention-2 for faster training and inference.
[INFO|2025-10-25 01:17:52] llamafactory.model.adapter:143 >> Pure bf16 / BAdam detected, remaining trainable params in half precision.
[INFO|2025-10-25 01:17:52] llamafactory.model.adapter:143 >> Fine-tuning method: Full
[INFO|2025-10-25 01:17:52] llamafactory.model.model_utils.visual:143 >> Set vision model not trainable: ['visual.patch_embed', 'visual.blocks'].
[INFO|2025-10-25 01:17:52] llamafactory.model.model_utils.visual:143 >> Set multi model projector not trainable: visual.merger.
[INFO|2025-10-25 01:17:52] llamafactory.model.loader:143 >> trainable params: 4,106,660,864 || all params: 4,437,815,808 || trainable%: 92.5379
{'loss': 2.0637, 'grad_norm': 50.0, 'learning_rate': 1.5789473684210526e-06, 'epoch': 0.02}
{'loss': 1.6169, 'grad_norm': 24.75, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.04}
{'loss': 0.9801, 'grad_norm': 8.75, 'learning_rate': 5.087719298245615e-06, 'epoch': 0.06}
{'loss': 0.6283, 'grad_norm': 2.21875, 'learning_rate': 6.842105263157896e-06, 'epoch': 0.08}
{'loss': 0.5852, 'grad_norm': 2.53125, 'learning_rate': 8.596491228070176e-06, 'epoch': 0.11}
{'loss': 0.5475, 'grad_norm': 2.375, 'learning_rate': 9.999947261619759e-06, 'epoch': 0.13}
{'loss': 0.546, 'grad_norm': 2.3125, 'learning_rate': 9.998101535124758e-06, 'epoch': 0.15}
{'loss': 0.5324, 'grad_norm': 2.546875, 'learning_rate': 9.993620002046804e-06, 'epoch': 0.17}
{'loss': 0.5181, 'grad_norm': 1.7265625, 'learning_rate': 9.986505025774137e-06, 'epoch': 0.19}
{'loss': 0.5085, 'grad_norm': 2.296875, 'learning_rate': 9.976760358471687e-06, 'epoch': 0.21}
{'eval_loss': 0.4862688183784485, 'eval_runtime': 1.9221, 'eval_samples_per_second': 32.256, 'eval_steps_per_second': 1.041, 'epoch': 0.21}
{'loss': 0.5, 'grad_norm': 1.90625, 'learning_rate': 9.964391139102325e-06, 'epoch': 0.23}
{'loss': 0.4975, 'grad_norm': 2.265625, 'learning_rate': 9.949403890716777e-06, 'epoch': 0.25}
{'loss': 0.4961, 'grad_norm': 2.453125, 'learning_rate': 9.931806517013612e-06, 'epoch': 0.27}
{'loss': 0.4933, 'grad_norm': 2.109375, 'learning_rate': 9.91160829817114e-06, 'epoch': 0.29}
{'loss': 0.4914, 'grad_norm': 2.390625, 'learning_rate': 9.888819885953398e-06, 'epoch': 0.32}
{'loss': 0.4827, 'grad_norm': 2.34375, 'learning_rate': 9.86345329809282e-06, 'epoch': 0.34}
{'loss': 0.4763, 'grad_norm': 2.3125, 'learning_rate': 9.835521911952554e-06, 'epoch': 0.36}
{'loss': 0.4735, 'grad_norm': 2.4375, 'learning_rate': 9.805040457471746e-06, 'epoch': 0.38}
{'loss': 0.4677, 'grad_norm': 2.5, 'learning_rate': 9.772025009397538e-06, 'epoch': 0.4}
{'loss': 0.4723, 'grad_norm': 2.328125, 'learning_rate': 9.736492978807869e-06, 'epoch': 0.42}
{'eval_loss': 0.4630371928215027, 'eval_runtime': 1.7992, 'eval_samples_per_second': 34.46, 'eval_steps_per_second': 1.112, 'epoch': 0.42}
{'loss': 0.464, 'grad_norm': 2.203125, 'learning_rate': 9.698463103929542e-06, 'epoch': 0.44}
{'loss': 0.4632, 'grad_norm': 2.234375, 'learning_rate': 9.657955440256396e-06, 'epoch': 0.46}
{'loss': 0.4505, 'grad_norm': 2.359375, 'learning_rate': 9.614991349972815e-06, 'epoch': 0.48}
{'loss': 0.4705, 'grad_norm': 2.03125, 'learning_rate': 9.569593490688134e-06, 'epoch': 0.51}
{'loss': 0.4604, 'grad_norm': 2.859375, 'learning_rate': 9.521785803487888e-06, 'epoch': 0.53}
{'loss': 0.4581, 'grad_norm': 2.28125, 'learning_rate': 9.471593500308198e-06, 'epoch': 0.55}
{'loss': 0.4549, 'grad_norm': 2.4375, 'learning_rate': 9.419043050639973e-06, 'epoch': 0.57}
{'loss': 0.4453, 'grad_norm': 2.21875, 'learning_rate': 9.364162167569907e-06, 'epoch': 0.59}
{'loss': 0.4531, 'grad_norm': 2.171875, 'learning_rate': 9.306979793165682e-06, 'epoch': 0.61}
{'loss': 0.446, 'grad_norm': 2.078125, 'learning_rate': 9.247526083213008e-06, 'epoch': 0.63}
{'eval_loss': 0.4492369294166565, 'eval_runtime': 1.7984, 'eval_samples_per_second': 34.476, 'eval_steps_per_second': 1.112, 'epoch': 0.63}
{'loss': 0.4388, 'grad_norm': 2.1875, 'learning_rate': 9.185832391312644e-06, 'epoch': 0.65}
{'loss': 0.4422, 'grad_norm': 2.5625, 'learning_rate': 9.121931252345704e-06, 'epoch': 0.67}
{'loss': 0.4329, 'grad_norm': 2.125, 'learning_rate': 9.055856365316012e-06, 'epoch': 0.69}
{'loss': 0.4326, 'grad_norm': 2.25, 'learning_rate': 8.987642575578546e-06, 'epoch': 0.72}
{'loss': 0.4383, 'grad_norm': 2.28125, 'learning_rate': 8.917325856463331e-06, 'epoch': 0.74}
{'loss': 0.4377, 'grad_norm': 2.484375, 'learning_rate': 8.8449432903045e-06, 'epoch': 0.76}
{'loss': 0.4302, 'grad_norm': 2.6875, 'learning_rate': 8.770533048884483e-06, 'epoch': 0.78}
{'loss': 0.4273, 'grad_norm': 2.078125, 'learning_rate': 8.694134373303685e-06, 'epoch': 0.8}
{'loss': 0.4374, 'grad_norm': 2.109375, 'learning_rate': 8.615787553286235e-06, 'epoch': 0.82}
{'loss': 0.4331, 'grad_norm': 2.828125, 'learning_rate': 8.535533905932739e-06, 'epoch': 0.84}
{'eval_loss': 0.43375399708747864, 'eval_runtime': 1.8226, 'eval_samples_per_second': 34.018, 'eval_steps_per_second': 1.097, 'epoch': 0.84}
{'loss': 0.4396, 'grad_norm': 3.140625, 'learning_rate': 8.453415753931223e-06, 'epoch': 0.86}
{'loss': 0.4284, 'grad_norm': 3.25, 'learning_rate': 8.369476403237781e-06, 'epoch': 0.88}
{'loss': 0.4299, 'grad_norm': 2.25, 'learning_rate': 8.283760120238672e-06, 'epoch': 0.91}
{'loss': 0.4325, 'grad_norm': 2.28125, 'learning_rate': 8.196312108405939e-06, 'epoch': 0.93}
{'loss': 0.4376, 'grad_norm': 2.953125, 'learning_rate': 8.107178484458825e-06, 'epoch': 0.95}
{'loss': 0.4277, 'grad_norm': 2.265625, 'learning_rate': 8.016406254043595e-06, 'epoch': 0.97}
{'loss': 0.421, 'grad_norm': 2.5625, 'learning_rate': 7.92404328694457e-06, 'epoch': 0.99}
{'loss': 0.4256, 'grad_norm': 1.921875, 'learning_rate': 7.830138291839426e-06, 'epoch': 1.01}
{'loss': 0.4229, 'grad_norm': 2.296875, 'learning_rate': 7.734740790612137e-06, 'epoch': 1.03}
{'loss': 0.4176, 'grad_norm': 3.609375, 'learning_rate': 7.637901092237005e-06, 'epoch': 1.05}
{'eval_loss': 0.433036744594574, 'eval_runtime': 1.8091, 'eval_samples_per_second': 34.272, 'eval_steps_per_second': 1.106, 'epoch': 1.05}
{'loss': 0.4213, 'grad_norm': 2.71875, 'learning_rate': 7.539670266247672e-06, 'epoch': 1.07}
{'loss': 0.4176, 'grad_norm': 2.640625, 'learning_rate': 7.440100115804991e-06, 'epoch': 1.09}
{'loss': 0.4131, 'grad_norm': 3.0, 'learning_rate': 7.33924315037804e-06, 'epoch': 1.12}
{'loss': 0.4228, 'grad_norm': 2.9375, 'learning_rate': 7.237152558052642e-06, 'epoch': 1.14}
{'loss': 0.4143, 'grad_norm': 2.953125, 'learning_rate': 7.133882177482019e-06, 'epoch': 1.16}
{'loss': 0.4184, 'grad_norm': 3.140625, 'learning_rate': 7.02948646949435e-06, 'epoch': 1.18}
{'loss': 0.4216, 'grad_norm': 2.796875, 'learning_rate': 6.924020488372229e-06, 'epoch': 1.2}
{'loss': 0.4121, 'grad_norm': 3.203125, 'learning_rate': 6.817539852819149e-06, 'epoch': 1.22}
{'loss': 0.4185, 'grad_norm': 3.640625, 'learning_rate': 6.710100716628345e-06, 'epoch': 1.24}
{'loss': 0.4133, 'grad_norm': 2.109375, 'learning_rate': 6.601759739069427e-06, 'epoch': 1.26}
{'eval_loss': 0.4326249659061432, 'eval_runtime': 1.884, 'eval_samples_per_second': 32.909, 'eval_steps_per_second': 1.062, 'epoch': 1.26}
{'loss': 0.4075, 'grad_norm': 2.65625, 'learning_rate': 6.492574055008474e-06, 'epoch': 1.28}
{'loss': 0.4146, 'grad_norm': 3.3125, 'learning_rate': 6.382601244777295e-06, 'epoch': 1.31}
{'loss': 0.4179, 'grad_norm': 3.171875, 'learning_rate': 6.271899303807783e-06, 'epoch': 1.33}
{'loss': 0.4169, 'grad_norm': 2.359375, 'learning_rate': 6.160526612047339e-06, 'epoch': 1.35}
{'loss': 0.4145, 'grad_norm': 2.609375, 'learning_rate': 6.048541903171552e-06, 'epoch': 1.37}
{'loss': 0.4198, 'grad_norm': 3.078125, 'learning_rate': 5.9360042336103e-06, 'epoch': 1.39}
{'loss': 0.4063, 'grad_norm': 2.71875, 'learning_rate': 5.82297295140367e-06, 'epoch': 1.41}
{'loss': 0.4071, 'grad_norm': 2.6875, 'learning_rate': 5.709507664904079e-06, 'epoch': 1.43}
{'loss': 0.407, 'grad_norm': 2.796875, 'learning_rate': 5.5956682113411184e-06, 'epoch': 1.45}
{'loss': 0.4024, 'grad_norm': 2.5, 'learning_rate': 5.481514625265709e-06, 'epoch': 1.47}
{'eval_loss': 0.4331021010875702, 'eval_runtime': 1.6175, 'eval_samples_per_second': 38.331, 'eval_steps_per_second': 1.236, 'epoch': 1.47}
{'loss': 0.4176, 'grad_norm': 3.25, 'learning_rate': 5.367107106890177e-06, 'epoch': 1.49}
{'loss': 0.4157, 'grad_norm': 2.109375, 'learning_rate': 5.252505990340982e-06, 'epoch': 1.52}
{'loss': 0.4104, 'grad_norm': 2.78125, 'learning_rate': 5.137771711840811e-06, 'epoch': 1.54}
{'loss': 0.411, 'grad_norm': 2.765625, 'learning_rate': 5.022964777836853e-06, 'epoch': 1.56}
{'loss': 0.4087, 'grad_norm': 2.65625, 'learning_rate': 4.908145733092013e-06, 'epoch': 1.58}
{'loss': 0.4058, 'grad_norm': 2.359375, 'learning_rate': 4.793375128755934e-06, 'epoch': 1.6}
{'loss': 0.4156, 'grad_norm': 2.84375, 'learning_rate': 4.67871349043265e-06, 'epoch': 1.62}
{'loss': 0.4105, 'grad_norm': 2.625, 'learning_rate': 4.564221286261709e-06, 'epoch': 1.64}
{'loss': 0.4073, 'grad_norm': 2.234375, 'learning_rate': 4.449958895029604e-06, 'epoch': 1.66}
{'loss': 0.4011, 'grad_norm': 2.28125, 'learning_rate': 4.335986574328317e-06, 'epoch': 1.68}
{'eval_loss': 0.42608752846717834, 'eval_runtime': 1.6596, 'eval_samples_per_second': 37.358, 'eval_steps_per_second': 1.205, 'epoch': 1.68}
{'loss': 0.4075, 'grad_norm': 3.171875, 'learning_rate': 4.222364428777786e-06, 'epoch': 1.71}
{'loss': 0.4131, 'grad_norm': 2.578125, 'learning_rate': 4.109152378329036e-06, 'epoch': 1.73}
{'loss': 0.4042, 'grad_norm': 2.5625, 'learning_rate': 3.996410126664705e-06, 'epoch': 1.75}
{'loss': 0.4133, 'grad_norm': 2.234375, 'learning_rate': 3.884197129713617e-06, 'epoch': 1.77}
{'loss': 0.409, 'grad_norm': 2.34375, 'learning_rate': 3.7725725642960047e-06, 'epoch': 1.79}
{'loss': 0.4114, 'grad_norm': 2.25, 'learning_rate': 3.6615952969159354e-06, 'epoch': 1.81}
{'loss': 0.4128, 'grad_norm': 2.5625, 'learning_rate': 3.5513238527173775e-06, 'epoch': 1.83}
{'loss': 0.4071, 'grad_norm': 2.59375, 'learning_rate': 3.4418163846202945e-06, 'epoch': 1.85}
{'loss': 0.4164, 'grad_norm': 2.8125, 'learning_rate': 3.333130642653024e-06, 'epoch': 1.87}
{'loss': 0.4148, 'grad_norm': 2.671875, 'learning_rate': 3.2253239434971363e-06, 'epoch': 1.89}
{'eval_loss': 0.42648953199386597, 'eval_runtime': 1.7518, 'eval_samples_per_second': 35.391, 'eval_steps_per_second': 1.142, 'epoch': 1.89}
{'loss': 0.4065, 'grad_norm': 2.5, 'learning_rate': 3.118453140260823e-06, 'epoch': 1.92}
{'loss': 0.4052, 'grad_norm': 2.484375, 'learning_rate': 3.012574592496749e-06, 'epoch': 1.94}
{'loss': 0.4058, 'grad_norm': 3.65625, 'learning_rate': 2.907744136480194e-06, 'epoch': 1.96}
{'loss': 0.4007, 'grad_norm': 2.265625, 'learning_rate': 2.804017055763149e-06, 'epoch': 1.98}
{'loss': 0.4099, 'grad_norm': 2.328125, 'learning_rate': 2.7014480520198882e-06, 'epoch': 2.0}
{'loss': 0.4047, 'grad_norm': 2.328125, 'learning_rate': 2.600091216199423e-06, 'epoch': 2.02}
{'loss': 0.4005, 'grad_norm': 2.3125, 'learning_rate': 2.5000000000000015e-06, 'epoch': 2.04}
{'loss': 0.396, 'grad_norm': 2.75, 'learning_rate': 2.4012271876807473e-06, 'epoch': 2.06}
{'loss': 0.412, 'grad_norm': 2.6875, 'learning_rate': 2.3038248682252695e-06, 'epoch': 2.08}
{'loss': 0.3999, 'grad_norm': 2.109375, 'learning_rate': 2.207844407871929e-06, 'epoch': 2.11}
{'eval_loss': 0.42766135931015015, 'eval_runtime': 1.7141, 'eval_samples_per_second': 36.172, 'eval_steps_per_second': 1.167, 'epoch': 2.11}
{'loss': 0.4001, 'grad_norm': 5.78125, 'learning_rate': 2.113336423025269e-06, 'epoch': 2.13}
{'loss': 0.4056, 'grad_norm': 2.890625, 'learning_rate': 2.0203507535628565e-06, 'epoch': 2.15}
{'loss': 0.4041, 'grad_norm': 2.65625, 'learning_rate': 1.928936436551661e-06, 'epoch': 2.17}
{'loss': 0.4104, 'grad_norm': 2.34375, 'learning_rate': 1.8391416803877853e-06, 'epoch': 2.19}
{'loss': 0.3989, 'grad_norm': 3.609375, 'learning_rate': 1.7510138393732029e-06, 'epoch': 2.21}
{'loss': 0.4028, 'grad_norm': 2.53125, 'learning_rate': 1.6645993887429345e-06, 'epoch': 2.23}
{'loss': 0.4031, 'grad_norm': 3.15625, 'learning_rate': 1.5799439001557847e-06, 'epoch': 2.25}
{'loss': 0.3982, 'grad_norm': 2.515625, 'learning_rate': 1.4970920176616066e-06, 'epoch': 2.27}
{'loss': 0.4016, 'grad_norm': 2.578125, 'learning_rate': 1.4160874341577447e-06, 'epoch': 2.29}
{'loss': 0.4001, 'grad_norm': 2.5625, 'learning_rate': 1.3369728683470774e-06, 'epoch': 2.32}
{'eval_loss': 0.4280250668525696, 'eval_runtime': 1.8192, 'eval_samples_per_second': 34.081, 'eval_steps_per_second': 1.099, 'epoch': 2.32}
{'loss': 0.3993, 'grad_norm': 2.6875, 'learning_rate': 1.259790042209823e-06, 'epoch': 2.34}
{'loss': 0.4055, 'grad_norm': 2.4375, 'learning_rate': 1.1845796590009684e-06, 'epoch': 2.36}
{'loss': 0.4018, 'grad_norm': 3.234375, 'learning_rate': 1.1113813817849312e-06, 'epoch': 2.38}
{'loss': 0.4037, 'grad_norm': 2.609375, 'learning_rate': 1.0402338125187933e-06, 'epoch': 2.4}
{'loss': 0.405, 'grad_norm': 2.78125, 'learning_rate': 9.711744716951093e-07, 'epoch': 2.42}
{'loss': 0.3957, 'grad_norm': 6.375, 'learning_rate': 9.042397785550405e-07, 'epoch': 2.44}
{'loss': 0.4008, 'grad_norm': 2.578125, 'learning_rate': 8.3946503188225e-07, 'epoch': 2.46}
{'loss': 0.3948, 'grad_norm': 2.109375, 'learning_rate': 7.768843913876756e-07, 'epoch': 2.48}
{'loss': 0.4035, 'grad_norm': 3.1875, 'learning_rate': 7.165308596950182e-07, 'epoch': 2.51}
{'loss': 0.4091, 'grad_norm': 3.1875, 'learning_rate': 6.584362649364262e-07, 'epoch': 2.53}
{'eval_loss': 0.427985280752182, 'eval_runtime': 1.6728, 'eval_samples_per_second': 37.063, 'eval_steps_per_second': 1.196, 'epoch': 2.53}
{'loss': 0.405, 'grad_norm': 2.546875, 'learning_rate': 6.026312439675553e-07, 'epoch': 2.55}
{'loss': 0.4068, 'grad_norm': 2.171875, 'learning_rate': 5.491452262108777e-07, 'epoch': 2.57}
{'loss': 0.3936, 'grad_norm': 2.515625, 'learning_rate': 4.980064181357319e-07, 'epoch': 2.59}
{'loss': 0.3997, 'grad_norm': 2.375, 'learning_rate': 4.4924178838331554e-07, 'epoch': 2.61}
{'loss': 0.4005, 'grad_norm': 2.15625, 'learning_rate': 4.0287705354446147e-07, 'epoch': 2.63}
{'loss': 0.4066, 'grad_norm': 3.234375, 'learning_rate': 3.5893666459769327e-07, 'epoch': 2.65}
{'loss': 0.4096, 'grad_norm': 2.6875, 'learning_rate': 3.174437940147268e-07, 'epoch': 2.67}
{'loss': 0.4079, 'grad_norm': 2.46875, 'learning_rate': 2.7842032354019e-07, 'epoch': 2.69}
{'loss': 0.4052, 'grad_norm': 2.484375, 'learning_rate': 2.4188683265204125e-07, 'epoch': 2.72}
{'loss': 0.3979, 'grad_norm': 2.328125, 'learning_rate': 2.0786258770873647e-07, 'epoch': 2.74}
{'eval_loss': 0.4281826913356781, 'eval_runtime': 1.7482, 'eval_samples_per_second': 35.464, 'eval_steps_per_second': 1.144, 'epoch': 2.74}
{'loss': 0.4052, 'grad_norm': 2.125, 'learning_rate': 1.7636553178889792e-07, 'epoch': 2.76}
{'loss': 0.4019, 'grad_norm': 2.640625, 'learning_rate': 1.4741227522882096e-07, 'epoch': 2.78}
{'loss': 0.3963, 'grad_norm': 2.140625, 'learning_rate': 1.210180868628219e-07, 'epoch': 2.8}
{'loss': 0.4023, 'grad_norm': 2.609375, 'learning_rate': 9.719688597104315e-08, 'epoch': 2.82}
{'loss': 0.4029, 'grad_norm': 2.609375, 'learning_rate': 7.59612349389599e-08, 'epoch': 2.84}
{'loss': 0.4036, 'grad_norm': 2.4375, 'learning_rate': 5.7322332632458454e-08, 'epoch': 2.86}
{'loss': 0.404, 'grad_norm': 2.1875, 'learning_rate': 4.129000849198872e-08, 'epoch': 2.88}
{'loss': 0.3974, 'grad_norm': 2.34375, 'learning_rate': 2.7872717348891852e-08, 'epoch': 2.91}
{'loss': 0.4013, 'grad_norm': 2.359375, 'learning_rate': 1.7077534966650767e-08, 'epoch': 2.93}
{'loss': 0.4033, 'grad_norm': 2.5625, 'learning_rate': 8.910154309400565e-09, 'epoch': 2.95}
{'eval_loss': 0.42757686972618103, 'eval_runtime': 1.5243, 'eval_samples_per_second': 40.674, 'eval_steps_per_second': 1.312, 'epoch': 2.95}
{'loss': 0.3968, 'grad_norm': 2.59375, 'learning_rate': 3.3748825396817675e-09, 'epoch': 2.97}
{'loss': 0.4015, 'grad_norm': 2.734375, 'learning_rate': 4.746387470044855e-10, 'epoch': 2.99}
{'train_runtime': 1020.8551, 'train_samples_per_second': 89.222, 'train_steps_per_second': 1.396, 'train_loss': 0.45063094005250093, 'epoch': 3.0}
***** train metrics *****
  epoch                    =         3.0
  total_flos               = 396707737GF
  train_loss               =      0.4506
  train_runtime            =  0:17:00.85
  train_samples_per_second =      89.222
  train_steps_per_second   =       1.396
Figure saved at: saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_grounding_only_video_train/training_loss.png
Figure saved at: saves/qwen3_5vl-4b/full/sft/roboG_stagepoc_grounding_only_video_train/training_eval_loss.png
[WARNING|2025-10-25 01:34:59] llamafactory.extras.ploting:148 >> No metric eval_accuracy to plot.
***** eval metrics *****
  epoch                   =        3.0
  eval_loss               =     0.4269
  eval_runtime            = 0:00:01.40
  eval_samples_per_second =     44.154
  eval_steps_per_second   =      1.424
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mQwen/Qwen3-VL-4B-Instruct_roboG_stagepoc_grounding_only_video_train_sft[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35m../../../../../hkfs/home/project/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/wandb/run-20251025_011754-egu9kigl/logs[0m

============================= JOB FEEDBACK =============================

Job ID: 3598632
Cluster: hk
User/Group: bm3844/hk-project-sustainebot
Account: hk-project-p0024638
State: COMPLETED (exit code 0)
Partition: accelerated-h100
Nodes: 1
Cores per node: 32
Nodelist: hkn0918
CPU Utilized: 06:22:16
CPU Efficiency: 50.02% of 12:44:16 core-walltime
Job Wall-clock time: 00:23:53
Starttime: Sat Oct 25 01:11:21 2025
Endtime: Sat Oct 25 01:35:14 2025
Memory Utilized: 34.70 GB
Memory Efficiency: 4.63% of 750.00 GB (750.00 GB/node)
Energy Consumed: 2470906 Joule / 686.362777777778 Watthours
Average node power draw: 1724.28890439637 Watt
