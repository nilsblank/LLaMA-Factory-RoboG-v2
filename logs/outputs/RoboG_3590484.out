Using config: examples/train_full/qwen2_5vl_roboG_poc_two_frames_det_cotrain_lora.yaml
[INFO|2025-10-22 11:21:57] llamafactory.launcher:143 >> Initializing 4 distributed tasks at: 127.0.0.1:39119
[WARNING|2025-10-22 11:22:12] llamafactory.extras.misc:154 >> Version checking has been disabled, may lead to unexpected behaviors.
[2025-10-22 11:22:18,657] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-22 11:22:18,657] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-22 11:22:18,658] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-22 11:22:18,658] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: sentence-transformers not installed, falling back to simple string similarity for LabelEvaluator. Install with `pip install sentence-transformers` for better results.
Warning: sentence-transformers not installed, falling back to simple string similarity for LabelEvaluator. Install with `pip install sentence-transformers` for better results.
Warning: sentence-transformers not installed, falling back to simple string similarity for LabelEvaluator. Install with `pip install sentence-transformers` for better results.Warning: sentence-transformers not installed, falling back to simple string similarity for LabelEvaluator. Install with `pip install sentence-transformers` for better results.

[INFO|2025-10-22 11:23:23] llamafactory.hparams.parser:143 >> Set `ddp_find_unused_parameters` to False in DDP training since LoRA is enabled.
[INFO|2025-10-22 11:23:23] llamafactory.hparams.parser:426 >> Process rank: 3, world size: 4, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-10-22 11:23:23] llamafactory.hparams.parser:426 >> Process rank: 1, world size: 4, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-10-22 11:23:23] llamafactory.hparams.parser:426 >> Process rank: 0, world size: 4, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-10-22 11:23:23] llamafactory.hparams.parser:426 >> Process rank: 2, world size: 4, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-10-22 11:23:27] llamafactory.data.loader:143 >> Loading dataset /home/hk-project-sustainebot/bm3844/datasets/datasets/robogrounder/roboG_stagepoc_two_frames_detection_cotrain_train.jsonl...
[INFO|2025-10-22 11:23:57] llamafactory.data.loader:143 >> Loading dataset /home/hk-project-sustainebot/bm3844/datasets/datasets/robogrounder/roboG_stagepoc_ablation_two_frames_eval.jsonl...
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 16246, 279, 1378, 2168, 1573, 323, 1283, 279, 16230, 11, 8253, 1128, 1633, 279, 12305, 476, 3738, 16282, 291, 448, 13, 9258, 279, 2383, 323, 3728, 315, 279, 16282, 291, 1633, 304, 279, 1156, 4034, 304, 4718, 3561, 13, 151645, 198, 151644, 77091, 198, 641, 1948, 279, 5335, 11, 458, 1633, 5497, 13, 576, 12305, 16282, 291, 448, 279, 15097, 624, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 17, 21, 15, 11, 220, 17, 17, 20, 11, 220, 19, 19, 19, 11, 220, 19, 18, 20, 1125, 330, 1502, 788, 330, 32578, 6375, 16707, 921, 73594, 151645, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|><|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|> Given the two image before and after the interaction, determine what object the robot or human interacted with. Output the label and location of the interacted object in the first frame in JSON format.<|im_end|>
<|im_start|>assistant
In between the images, an object changed. The robot interacted with the clothes.
```json
[
{"bbox_2d": [260, 225, 444, 435], "label": "clothes"}
]
```<|im_end|>

label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 641, 1948, 279, 5335, 11, 458, 1633, 5497, 13, 576, 12305, 16282, 291, 448, 279, 15097, 624, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 17, 21, 15, 11, 220, 17, 17, 20, 11, 220, 19, 19, 19, 11, 220, 19, 18, 20, 1125, 330, 1502, 788, 330, 32578, 6375, 16707, 921, 73594, 151645, 198]
labels:
In between the images, an object changed. The robot interacted with the clothes.
```json
[
{"bbox_2d": [260, 225, 444, 435], "label": "clothes"}
]
```<|im_end|>

eval example:
input_ids:
[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 10294, 279, 1378, 5335, 323, 24523, 279, 1633, 429, 572, 16634, 553, 279, 12305, 476, 3738, 13, 9258, 279, 2383, 323, 30618, 3745, 315, 279, 16282, 291, 1633, 304, 4718, 3561, 369, 279, 2661, 1156, 4034, 13, 151645, 198, 151644, 77091, 198]
inputs:
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|><|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|> Review the two images and locate the object that was engaged by the robot or human. Output the label and bounding box of the interacted object in JSON format for the given first frame.<|im_end|>
<|im_start|>assistant

label_ids:
[785, 12305, 16282, 291, 448, 279, 14961, 26334, 624, 73594, 2236, 198, 9640, 4913, 58456, 62, 17, 67, 788, 508, 17, 21, 18, 11, 220, 17, 19, 17, 11, 220, 18, 20, 22, 11, 220, 18, 15, 16, 1125, 330, 1502, 788, 330, 81914, 26334, 16707, 921, 73594, 151645, 198]
labels:
The robot interacted with the silver lid.
```json
[
{"bbox_2d": [263, 242, 357, 301], "label": "silver lid"}
]
```<|im_end|>

[INFO|2025-10-22 11:26:21] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
[INFO|2025-10-22 11:26:35] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
[INFO|2025-10-22 11:26:35] llamafactory.model.model_utils.attention:143 >> Using FlashAttention-2 for faster training and inference.
[INFO|2025-10-22 11:26:35] llamafactory.model.adapter:143 >> Pure bf16 / BAdam detected, remaining trainable params in half precision.
[INFO|2025-10-22 11:26:35] llamafactory.model.adapter:143 >> Fine-tuning method: LoRA
[INFO|2025-10-22 11:26:35] llamafactory.model.model_utils.misc:143 >> Found linear modules: k_proj,down_proj,o_proj,gate_proj,v_proj,q_proj,up_proj
[INFO|2025-10-22 11:26:35] llamafactory.model.model_utils.visual:143 >> Set vision model not trainable: ['visual.patch_embed', 'visual.blocks'].
[INFO|2025-10-22 11:26:35] llamafactory.model.model_utils.visual:143 >> Set multi model projector not trainable: visual.merger.
[INFO|2025-10-22 11:26:46] llamafactory.model.loader:143 >> trainable params: 59,867,136 || all params: 3,814,490,112 || trainable%: 1.5695
{'loss': 0.1914, 'grad_norm': 0.5321316719055176, 'learning_rate': 1.6731451105335482e-06, 'epoch': 2.69}
{'loss': 0.1981, 'grad_norm': 0.6183049082756042, 'learning_rate': 1.6015297412869767e-06, 'epoch': 2.7}
{'loss': 0.2024, 'grad_norm': 0.6329867839813232, 'learning_rate': 1.5314387167782972e-06, 'epoch': 2.71}
{'loss': 0.202, 'grad_norm': 0.586722731590271, 'learning_rate': 1.4628757992835506e-06, 'epoch': 2.71}
{'loss': 0.1902, 'grad_norm': 0.6142339706420898, 'learning_rate': 1.3958446690545868e-06, 'epoch': 2.72}
{'loss': 0.1919, 'grad_norm': 0.7863948941230774, 'learning_rate': 1.3303489241214995e-06, 'epoch': 2.73}
{'loss': 0.1888, 'grad_norm': 0.5775219202041626, 'learning_rate': 1.2663920800994977e-06, 'epoch': 2.73}
{'loss': 0.1893, 'grad_norm': 0.5674098134040833, 'learning_rate': 1.2039775700002164e-06, 'epoch': 2.74}
{'loss': 0.1868, 'grad_norm': 0.6640961170196533, 'learning_rate': 1.1431087440474174e-06, 'epoch': 2.75}
{'loss': 0.1893, 'grad_norm': 0.6262499094009399, 'learning_rate': 1.0837888694971864e-06, 'epoch': 2.75}
{'eval_rouge-1': 69.16078020833334, 'eval_rouge-2': 60.21837291666666, 'eval_rouge-l': 77.67118854166667, 'eval_bleu-4': 61.212146875, 'eval_runtime': 15.244, 'eval_samples_per_second': 5.445, 'eval_steps_per_second': 0.197, 'epoch': 2.75}
***** eval metrics *****
  BoundingBoxMAP_eval/map = 0.0579
***** eval metrics *****
  BoundingBoxMAP_eval/map_50 = 0.1143
***** eval metrics *****
  BoundingBoxMAP_eval/map_75 = 0.0564
***** eval metrics *****
  BoundingBoxMAP_eval/map_small = 0.0
***** eval metrics *****
  BoundingBoxMAP_eval/map_medium = 0.0597
***** eval metrics *****
  BoundingBoxMAP_eval/map_large = 0.1362
***** eval metrics *****
  BoundingBoxMAP_eval/mar_1 = 0.1952
***** eval metrics *****
  BoundingBoxMAP_eval/mar_10 = 0.1952
***** eval metrics *****
  BoundingBoxMAP_eval/mar_100 = 0.1952
***** eval metrics *****
  BoundingBoxMAP_eval/mar_small = 0.0
***** eval metrics *****
  BoundingBoxMAP_eval/mar_medium = 0.1537
***** eval metrics *****
  BoundingBoxMAP_eval/mar_large = 0.4538
***** eval metrics *****
  BoundingBoxMAP_eval/map_per_class = -1.0
***** eval metrics *****
  BoundingBoxMAP_eval/mar_100_per_class = -1.0
***** eval metrics *****
  BoundingBoxMAP_eval/classes = 1.0
***** eval metrics *****
  BoundingBoxMAP_eval/iou = 0.286
***** eval metrics *****
  LabelAccuracy_eval/accuracy = 0.2771
***** eval metrics *****
  LabelAccuracy_eval/precision = 1.0
***** eval metrics *****
  LabelAccuracy_eval/recall = 0.2771
***** eval metrics *****
  LabelAccuracy_eval/f1_score = 0.434
{'loss': 0.1903, 'grad_norm': 0.6570116877555847, 'learning_rate': 1.02602113046253e-06, 'epoch': 2.76}
{'loss': 0.1893, 'grad_norm': 0.7732148766517639, 'learning_rate': 9.698086277424723e-07, 'epoch': 2.77}
{'loss': 0.1937, 'grad_norm': 0.6300728917121887, 'learning_rate': 9.151543786556249e-07, 'epoch': 2.77}
{'loss': 0.1832, 'grad_norm': 0.6568320989608765, 'learning_rate': 8.620613168782199e-07, 'epoch': 2.78}
{'loss': 0.1929, 'grad_norm': 0.626692533493042, 'learning_rate': 8.105322922866155e-07, 'epoch': 2.79}
{'loss': 0.1905, 'grad_norm': 0.7202426791191101, 'learning_rate': 7.605700708043584e-07, 'epoch': 2.79}
{'loss': 0.1852, 'grad_norm': 0.7467613220214844, 'learning_rate': 7.121773342536997e-07, 'epoch': 2.8}
{'loss': 0.1931, 'grad_norm': 0.7274293303489685, 'learning_rate': 6.653566802116462e-07, 'epoch': 2.81}
{'loss': 0.1896, 'grad_norm': 0.708784282207489, 'learning_rate': 6.201106218705255e-07, 'epoch': 2.81}
{'loss': 0.2021, 'grad_norm': 0.6244552731513977, 'learning_rate': 5.764415879030871e-07, 'epoch': 2.82}
{'eval_rouge-1': 69.31107916666666, 'eval_rouge-2': 60.39461875000001, 'eval_rouge-l': 77.80404270833334, 'eval_bleu-4': 61.58275312499999, 'eval_runtime': 13.9774, 'eval_samples_per_second': 5.938, 'eval_steps_per_second': 0.215, 'epoch': 2.82}
***** eval metrics *****
  BoundingBoxMAP_eval/map = 0.0658
***** eval metrics *****
  BoundingBoxMAP_eval/map_50 = 0.1273
***** eval metrics *****
  BoundingBoxMAP_eval/map_75 = 0.0618
***** eval metrics *****
  BoundingBoxMAP_eval/map_small = 0.0
***** eval metrics *****
  BoundingBoxMAP_eval/map_medium = 0.0688
***** eval metrics *****
  BoundingBoxMAP_eval/map_large = 0.1522
***** eval metrics *****
  BoundingBoxMAP_eval/mar_1 = 0.2108
***** eval metrics *****
  BoundingBoxMAP_eval/mar_10 = 0.2108
***** eval metrics *****
  BoundingBoxMAP_eval/mar_100 = 0.2108
***** eval metrics *****
  BoundingBoxMAP_eval/mar_small = 0.0
***** eval metrics *****
  BoundingBoxMAP_eval/mar_medium = 0.1731
***** eval metrics *****
  BoundingBoxMAP_eval/mar_large = 0.4538
***** eval metrics *****
  BoundingBoxMAP_eval/map_per_class = -1.0
***** eval metrics *****
  BoundingBoxMAP_eval/mar_100_per_class = -1.0
***** eval metrics *****
  BoundingBoxMAP_eval/classes = 1.0
***** eval metrics *****
  BoundingBoxMAP_eval/iou = 0.3048
***** eval metrics *****
  LabelAccuracy_eval/accuracy = 0.2892
***** eval metrics *****
  LabelAccuracy_eval/precision = 1.0
***** eval metrics *****
  LabelAccuracy_eval/recall = 0.2892
***** eval metrics *****
  LabelAccuracy_eval/f1_score = 0.4486
{'loss': 0.1893, 'grad_norm': 0.6654685735702515, 'learning_rate': 5.343519223321469e-07, 'epoch': 2.83}
{'loss': 0.1957, 'grad_norm': 0.6399047374725342, 'learning_rate': 4.93843884404761e-07, 'epoch': 2.83}
{'loss': 0.1854, 'grad_norm': 0.6693398356437683, 'learning_rate': 4.5491964847094613e-07, 'epoch': 2.84}
{'loss': 0.1912, 'grad_norm': 0.6020379662513733, 'learning_rate': 4.175813038669862e-07, 'epoch': 2.85}
{'loss': 0.186, 'grad_norm': 0.5738497972488403, 'learning_rate': 3.81830854803269e-07, 'epoch': 2.85}
{'loss': 0.1999, 'grad_norm': 0.6395899057388306, 'learning_rate': 3.476702202567117e-07, 'epoch': 2.86}
{'loss': 0.1907, 'grad_norm': 0.7691870331764221, 'learning_rate': 3.1510123386775723e-07, 'epoch': 2.87}
{'loss': 0.1891, 'grad_norm': 0.6073123216629028, 'learning_rate': 2.841256438419426e-07, 'epoch': 2.87}
{'loss': 0.1884, 'grad_norm': 0.6290059089660645, 'learning_rate': 2.5474511285606404e-07, 'epoch': 2.88}
{'loss': 0.1827, 'grad_norm': 0.5839987397193909, 'learning_rate': 2.2696121796894509e-07, 'epoch': 2.89}
{'eval_rouge-1': 69.27868854166667, 'eval_rouge-2': 60.352865625, 'eval_rouge-l': 77.78586250000001, 'eval_bleu-4': 61.55002291666667, 'eval_runtime': 13.995, 'eval_samples_per_second': 5.931, 'eval_steps_per_second': 0.214, 'epoch': 2.89}
***** eval metrics *****
  BoundingBoxMAP_eval/map = 0.0593
***** eval metrics *****
  BoundingBoxMAP_eval/map_50 = 0.1273
***** eval metrics *****
  BoundingBoxMAP_eval/map_75 = 0.0512
***** eval metrics *****
  BoundingBoxMAP_eval/map_small = 0.0
***** eval metrics *****
  BoundingBoxMAP_eval/map_medium = 0.0578
***** eval metrics *****
  BoundingBoxMAP_eval/map_large = 0.151
***** eval metrics *****
  BoundingBoxMAP_eval/mar_1 = 0.2048
***** eval metrics *****
  BoundingBoxMAP_eval/mar_10 = 0.2048
***** eval metrics *****
  BoundingBoxMAP_eval/mar_100 = 0.2048
***** eval metrics *****
  BoundingBoxMAP_eval/mar_small = 0.0
***** eval metrics *****
  BoundingBoxMAP_eval/mar_medium = 0.1657
***** eval metrics *****
  BoundingBoxMAP_eval/mar_large = 0.4538
***** eval metrics *****
  BoundingBoxMAP_eval/map_per_class = -1.0
***** eval metrics *****
  BoundingBoxMAP_eval/mar_100_per_class = -1.0
***** eval metrics *****
  BoundingBoxMAP_eval/classes = 1.0
***** eval metrics *****
  BoundingBoxMAP_eval/iou = 0.3044
***** eval metrics *****
  LabelAccuracy_eval/accuracy = 0.2892
***** eval metrics *****
  LabelAccuracy_eval/precision = 1.0
***** eval metrics *****
  LabelAccuracy_eval/recall = 0.2892
***** eval metrics *****
  LabelAccuracy_eval/f1_score = 0.4486
{'loss': 0.196, 'grad_norm': 0.728431761264801, 'learning_rate': 2.0077545053675095e-07, 'epoch': 2.89}
{'loss': 0.1906, 'grad_norm': 0.9375991821289062, 'learning_rate': 1.7618921613296922e-07, 'epoch': 2.9}
{'loss': 0.1905, 'grad_norm': 0.6928588151931763, 'learning_rate': 1.5320383447294694e-07, 'epoch': 2.91}
{'loss': 0.1856, 'grad_norm': 0.6571727395057678, 'learning_rate': 1.3182053934305715e-07, 'epoch': 2.91}
{'loss': 0.1899, 'grad_norm': 0.6247668266296387, 'learning_rate': 1.1204047853446863e-07, 'epoch': 2.92}
{'loss': 0.1859, 'grad_norm': 0.6641478538513184, 'learning_rate': 9.386471378154182e-08, 'epoch': 2.93}
{'loss': 0.1854, 'grad_norm': 0.5968944430351257, 'learning_rate': 7.729422070483105e-08, 'epoch': 2.93}
{'loss': 0.1883, 'grad_norm': 0.6644884943962097, 'learning_rate': 6.232988875871982e-08, 'epoch': 2.94}
{'loss': 0.1901, 'grad_norm': 0.668233335018158, 'learning_rate': 4.897252118368889e-08, 'epoch': 2.95}
{'loss': 0.1934, 'grad_norm': 0.7024891376495361, 'learning_rate': 3.7222834963170914e-08, 'epoch': 2.96}
{'eval_rouge-1': 69.173928125, 'eval_rouge-2': 60.258204166666665, 'eval_rouge-l': 77.71409583333333, 'eval_bleu-4': 61.30393229166666, 'eval_runtime': 14.1678, 'eval_samples_per_second': 5.858, 'eval_steps_per_second': 0.212, 'epoch': 2.96}
***** eval metrics *****
  BoundingBoxMAP_eval/map = 0.0553
***** eval metrics *****
  BoundingBoxMAP_eval/map_50 = 0.1143
***** eval metrics *****
  BoundingBoxMAP_eval/map_75 = 0.0564
***** eval metrics *****
  BoundingBoxMAP_eval/map_small = 0.0
***** eval metrics *****
  BoundingBoxMAP_eval/map_medium = 0.0603
***** eval metrics *****
  BoundingBoxMAP_eval/map_large = 0.1198
***** eval metrics *****
  BoundingBoxMAP_eval/mar_1 = 0.194
***** eval metrics *****
  BoundingBoxMAP_eval/mar_10 = 0.194
***** eval metrics *****
  BoundingBoxMAP_eval/mar_100 = 0.194
***** eval metrics *****
  BoundingBoxMAP_eval/mar_small = 0.0
***** eval metrics *****
  BoundingBoxMAP_eval/mar_medium = 0.1627
***** eval metrics *****
  BoundingBoxMAP_eval/mar_large = 0.4
***** eval metrics *****
  BoundingBoxMAP_eval/map_per_class = -1.0
***** eval metrics *****
  BoundingBoxMAP_eval/mar_100_per_class = -1.0
***** eval metrics *****
  BoundingBoxMAP_eval/classes = 1.0
***** eval metrics *****
  BoundingBoxMAP_eval/iou = 0.2874
***** eval metrics *****
  LabelAccuracy_eval/accuracy = 0.2771
***** eval metrics *****
  LabelAccuracy_eval/precision = 1.0
***** eval metrics *****
  LabelAccuracy_eval/recall = 0.2771
***** eval metrics *****
  LabelAccuracy_eval/f1_score = 0.434
{'loss': 0.19, 'grad_norm': 0.70595782995224, 'learning_rate': 2.7081460785101098e-08, 'epoch': 2.96}
{'loss': 0.1809, 'grad_norm': 0.6142755746841431, 'learning_rate': 1.8548943008037666e-08, 'epoch': 2.97}
{'loss': 0.1894, 'grad_norm': 0.6422532796859741, 'learning_rate': 1.1625739631948573e-08, 'epoch': 2.98}
{'loss': 0.1863, 'grad_norm': 0.5631076097488403, 'learning_rate': 6.312222273637813e-09, 'epoch': 2.98}
{'loss': 0.1883, 'grad_norm': 0.6047497987747192, 'learning_rate': 2.608676146781397e-09, 'epoch': 2.99}
{'loss': 0.1903, 'grad_norm': 0.700128972530365, 'learning_rate': 5.153000466362468e-10, 'epoch': 3.0}
{'train_runtime': 1526.7792, 'train_samples_per_second': 187.147, 'train_steps_per_second': 2.926, 'train_loss': 0.01990638599583626, 'epoch': 3.0}
***** train metrics *****
  epoch                    =          3.0
  total_flos               = 4453065016GF
  train_loss               =       0.0199
  train_runtime            =   0:25:26.77
  train_samples_per_second =      187.147
  train_steps_per_second   =        2.926
Figure saved at: saves/qwen2_5vl-3b/lora/sft/roboG_stagepoc_two_frames_detection_cotrain_train/training_loss.png
[WARNING|2025-10-22 11:52:16] llamafactory.extras.ploting:148 >> No metric eval_loss to plot.
[WARNING|2025-10-22 11:52:16] llamafactory.extras.ploting:148 >> No metric eval_accuracy to plot.
[WARNING|2025-10-22 11:52:16] llamafactory.train.sft.workflow:154 >> Batch generation can be very slow. Consider using `scripts/vllm_infer.py` instead.
***** predict metrics *****
  predict_bleu-4             =    61.1701
  predict_rouge-1            =    71.9371
  predict_rouge-2            =    59.8481
  predict_rouge-l            =    78.0062
  predict_runtime            = 0:00:15.71
  predict_samples_per_second =       5.28
  predict_steps_per_second   =      0.191
[INFO|2025-10-22 11:52:32] llamafactory.train.sft.trainer:143 >> Saving prediction results to saves/qwen2_5vl-3b/lora/sft/roboG_stagepoc_two_frames_detection_cotrain_train/generated_predictions.jsonl
***** eval metrics *****
  BoundingBoxMAP_eval/map = 0.0512
***** eval metrics *****
  BoundingBoxMAP_eval/map_50 = 0.1008
***** eval metrics *****
  BoundingBoxMAP_eval/map_75 = 0.0548
***** eval metrics *****
  BoundingBoxMAP_eval/map_small = 0.0
***** eval metrics *****
  BoundingBoxMAP_eval/map_medium = 0.0455
***** eval metrics *****
  BoundingBoxMAP_eval/map_large = 0.1286
***** eval metrics *****
  BoundingBoxMAP_eval/mar_1 = 0.1964
***** eval metrics *****
  BoundingBoxMAP_eval/mar_10 = 0.1964
***** eval metrics *****
  BoundingBoxMAP_eval/mar_100 = 0.1964
***** eval metrics *****
  BoundingBoxMAP_eval/mar_small = 0.0
***** eval metrics *****
  BoundingBoxMAP_eval/mar_medium = 0.1612
***** eval metrics *****
  BoundingBoxMAP_eval/mar_large = 0.4231
***** eval metrics *****
  BoundingBoxMAP_eval/map_per_class = -1.0
***** eval metrics *****
  BoundingBoxMAP_eval/mar_100_per_class = -1.0
***** eval metrics *****
  BoundingBoxMAP_eval/classes = 1.0
***** eval metrics *****
  BoundingBoxMAP_eval/iou = 0.284
***** eval metrics *****
  LabelAccuracy_eval/accuracy = 0.3012
***** eval metrics *****
  LabelAccuracy_eval/precision = 1.0
***** eval metrics *****
  LabelAccuracy_eval/recall = 0.3012
***** eval metrics *****
  LabelAccuracy_eval/f1_score = 0.463
***** eval metrics *****
  epoch                   =        3.0
  eval_bleu-4             =    64.1562
  eval_rouge-1            =    73.6702
  eval_rouge-2            =    62.2957
  eval_rouge-l            =    79.4976
  eval_runtime            = 0:00:15.58
  eval_samples_per_second =      5.324
  eval_steps_per_second   =      0.192
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mQwen/Qwen2.5-VL-3B-Instruct_roboG_stagepoc_two_frames_detection_cotrain_train_sft[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35m../../../../../hkfs/home/project/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/wandb/run-20251022_112649-kbus5yoh/logs[0m

============================= JOB FEEDBACK =============================

Job ID: 3590484
Cluster: hk
User/Group: bm3844/hk-project-sustainebot
Account: hk-project-p0024638
State: COMPLETED (exit code 0)
Partition: accelerated
Nodes: 1
Cores per node: 64
Nodelist: hkn0436
CPU Utilized: 04:11:34
CPU Efficiency: 12.03% of 1-10:51:44 core-walltime
Job Wall-clock time: 00:32:41
Starttime: Wed Oct 22 11:20:15 2025
Endtime: Wed Oct 22 11:52:56 2025
Memory Utilized: 32.67 GB
Memory Efficiency: 6.72% of 485.84 GB (485.84 GB/node)
Energy Consumed: 9612239 Joule / 2670.06638888889 Watthours
Average node power draw: 4901.7027027027 Watt
