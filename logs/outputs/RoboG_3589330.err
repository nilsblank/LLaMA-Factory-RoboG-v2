GpuFreq=control_disabled
[W1021 16:53:40.691131453 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W1021 16:53:40.691129933 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W1021 16:53:40.691172115 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W1021 16:53:40.691249618 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[INFO|tokenization_utils_base.py:2095] 2025-10-21 16:53:41,467 >> loading file vocab.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/vocab.json
[INFO|tokenization_utils_base.py:2095] 2025-10-21 16:53:41,467 >> loading file merges.txt from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/merges.txt
[INFO|tokenization_utils_base.py:2095] 2025-10-21 16:53:41,467 >> loading file tokenizer.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2025-10-21 16:53:41,467 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-10-21 16:53:41,467 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-10-21 16:53:41,467 >> loading file tokenizer_config.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2025-10-21 16:53:41,467 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2025-10-21 16:53:41,637 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:383] 2025-10-21 16:53:42,160 >> loading configuration file preprocessor_config.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/preprocessor_config.json
[INFO|image_processing_base.py:383] 2025-10-21 16:53:42,404 >> loading configuration file preprocessor_config.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/preprocessor_config.json
[INFO|image_processing_base.py:428] 2025-10-21 16:53:42,410 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "input_data_format": null,
  "max_pixels": null,
  "merge_size": 2,
  "min_pixels": null,
  "pad_size": null,
  "patch_size": 16,
  "processor_class": "Qwen3VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 16777216,
    "shortest_edge": 65536
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2095] 2025-10-21 16:53:42,667 >> loading file vocab.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/vocab.json
[INFO|tokenization_utils_base.py:2095] 2025-10-21 16:53:42,667 >> loading file merges.txt from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/merges.txt
[INFO|tokenization_utils_base.py:2095] 2025-10-21 16:53:42,667 >> loading file tokenizer.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2025-10-21 16:53:42,667 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-10-21 16:53:42,667 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2025-10-21 16:53:42,667 >> loading file tokenizer_config.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2025-10-21 16:53:42,667 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2025-10-21 16:53:42,826 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:726] 2025-10-21 16:53:43,186 >> loading configuration file video_preprocessor_config.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/video_preprocessor_config.json
[INFO|video_processing_utils.py:770] 2025-10-21 16:53:43,187 >> Video processor Qwen3VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": true,
  "fps": 2,
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "input_data_format": null,
  "max_frames": 768,
  "merge_size": 2,
  "min_frames": 4,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 16,
  "processor_class": "Qwen3VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 25165824,
    "shortest_edge": 4096
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen3VLVideoProcessor"
}

[INFO|processing_utils.py:1116] 2025-10-21 16:53:44,029 >> loading configuration file processor_config.json from cache at None
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1021 16:53:44.594276489 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1021 16:53:44.617332473 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1021 16:53:44.708953086 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[INFO|processing_utils.py:1199] 2025-10-21 16:53:44,310 >> Processor Qwen3VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "input_data_format": null,
  "max_pixels": null,
  "merge_size": 2,
  "min_pixels": null,
  "pad_size": null,
  "patch_size": 16,
  "processor_class": "Qwen3VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 16777216,
    "shortest_edge": 65536
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen3-VL-4B-Instruct', vocab_size=151643, model_max_length=262144, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151665: AddedToken("<tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151666: AddedToken("</tool_response>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151667: AddedToken("<think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151668: AddedToken("</think>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
}
)
- video_processor: Qwen3VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": true,
  "fps": 2,
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "input_data_format": null,
  "max_frames": 768,
  "merge_size": 2,
  "min_frames": 4,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 16,
  "processor_class": "Qwen3VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 25165824,
    "shortest_edge": 4096
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen3VLVideoProcessor"
}


{
  "processor_class": "Qwen3VLProcessor"
}

Converting format of dataset (num_proc=128):   0%|          | 0/56026 [00:00<?, ? examples/s]Converting format of dataset (num_proc=128):   0%|          | 21/56026 [00:00<05:13, 178.68 examples/s]Converting format of dataset (num_proc=128):   1%|▏         | 812/56026 [00:00<00:12, 4402.52 examples/s]Converting format of dataset (num_proc=128):   3%|▎         | 1459/56026 [00:00<00:10, 5288.98 examples/s]Converting format of dataset (num_proc=128):   4%|▎         | 2094/56026 [00:00<00:09, 5689.10 examples/s]Converting format of dataset (num_proc=128):   5%|▍         | 2743/56026 [00:00<00:08, 5962.18 examples/s]Converting format of dataset (num_proc=128):   6%|▌         | 3386/56026 [00:00<00:08, 6109.99 examples/s]Converting format of dataset (num_proc=128):   7%|▋         | 4008/56026 [00:00<00:08, 6119.43 examples/s]Converting format of dataset (num_proc=128):   8%|▊         | 4663/56026 [00:00<00:08, 6254.93 examples/s]Converting format of dataset (num_proc=128):   9%|▉         | 5320/56026 [00:00<00:07, 6343.54 examples/s]Converting format of dataset (num_proc=128):  11%|█         | 5968/56026 [00:01<00:07, 6374.59 examples/s]Converting format of dataset (num_proc=128):  12%|█▏        | 6610/56026 [00:01<00:07, 6367.30 examples/s]Converting format of dataset (num_proc=128):  13%|█▎        | 7256/56026 [00:01<00:07, 6392.55 examples/s]Converting format of dataset (num_proc=128):  14%|█▍        | 7947/56026 [00:01<00:07, 6544.73 examples/s]Converting format of dataset (num_proc=128):  15%|█▌        | 8603/56026 [00:01<00:07, 6382.12 examples/s]Converting format of dataset (num_proc=128):  17%|█▋        | 9256/56026 [00:01<00:07, 6402.89 examples/s]Converting format of dataset (num_proc=128):  18%|█▊        | 9899/56026 [00:01<00:07, 6404.13 examples/s]Converting format of dataset (num_proc=128):  19%|█▉        | 10562/56026 [00:01<00:07, 6439.49 examples/s]Converting format of dataset (num_proc=128):  20%|██        | 11223/56026 [00:01<00:06, 6484.57 examples/s]Converting format of dataset (num_proc=128):  21%|██        | 11875/56026 [00:01<00:06, 6328.63 examples/s]Converting format of dataset (num_proc=128):  22%|██▏       | 12527/56026 [00:02<00:06, 6380.15 examples/s]Converting format of dataset (num_proc=128):  24%|██▎       | 13181/56026 [00:02<00:06, 6423.17 examples/s]Converting format of dataset (num_proc=128):  25%|██▍       | 13826/56026 [00:02<00:06, 6382.88 examples/s]Converting format of dataset (num_proc=128):  26%|██▌       | 14469/56026 [00:02<00:06, 6387.89 examples/s]Converting format of dataset (num_proc=128):  27%|██▋       | 15137/56026 [00:02<00:06, 6472.91 examples/s]Converting format of dataset (num_proc=128):  28%|██▊       | 15785/56026 [00:02<00:06, 6433.75 examples/s]Converting format of dataset (num_proc=128):  29%|██▉       | 16429/56026 [00:02<00:06, 6316.92 examples/s]Converting format of dataset (num_proc=128):  31%|███       | 17104/56026 [00:02<00:06, 6434.72 examples/s]Converting format of dataset (num_proc=128):  32%|███▏      | 17750/56026 [00:02<00:06, 6326.98 examples/s]Converting format of dataset (num_proc=128):  33%|███▎      | 18418/56026 [00:02<00:05, 6422.18 examples/s]Converting format of dataset (num_proc=128):  34%|███▍      | 19071/56026 [00:03<00:05, 6444.00 examples/s]Converting format of dataset (num_proc=128):  35%|███▌      | 19717/56026 [00:03<00:05, 6415.32 examples/s]Converting format of dataset (num_proc=128):  36%|███▋      | 20379/56026 [00:03<00:05, 6468.49 examples/s]Converting format of dataset (num_proc=128):  38%|███▊      | 21030/56026 [00:03<00:05, 6441.40 examples/s]Converting format of dataset (num_proc=128):  39%|███▊      | 21677/56026 [00:03<00:05, 6314.91 examples/s]Converting format of dataset (num_proc=128):  40%|███▉      | 22368/56026 [00:03<00:05, 6464.10 examples/s]Converting format of dataset (num_proc=128):  41%|████      | 23035/56026 [00:03<00:05, 6524.12 examples/s]Converting format of dataset (num_proc=128):  42%|████▏     | 23688/56026 [00:03<00:05, 6452.02 examples/s]Converting format of dataset (num_proc=128):  43%|████▎     | 24335/56026 [00:03<00:04, 6379.06 examples/s]Converting format of dataset (num_proc=128):  45%|████▍     | 24986/56026 [00:03<00:04, 6410.31 examples/s]Converting format of dataset (num_proc=128):  46%|████▌     | 25630/56026 [00:04<00:04, 6402.74 examples/s]Converting format of dataset (num_proc=128):  47%|████▋     | 26272/56026 [00:04<00:04, 6372.84 examples/s]Converting format of dataset (num_proc=128):  48%|████▊     | 26911/56026 [00:04<00:04, 6320.32 examples/s]Converting format of dataset (num_proc=128):  49%|████▉     | 27572/56026 [00:04<00:04, 6344.67 examples/s]Converting format of dataset (num_proc=128):  50%|█████     | 28228/56026 [00:04<00:04, 6403.70 examples/s]Converting format of dataset (num_proc=128):  52%|█████▏    | 28883/56026 [00:04<00:04, 6445.70 examples/s]Converting format of dataset (num_proc=128):  53%|█████▎    | 29530/56026 [00:04<00:04, 6450.51 examples/s]Converting format of dataset (num_proc=128):  54%|█████▍    | 30177/56026 [00:04<00:04, 6366.97 examples/s]Converting format of dataset (num_proc=128):  55%|█████▌    | 30834/56026 [00:04<00:03, 6423.68 examples/s]Converting format of dataset (num_proc=128):  56%|█████▌    | 31481/56026 [00:05<00:03, 6434.46 examples/s]Converting format of dataset (num_proc=128):  57%|█████▋    | 32125/56026 [00:05<00:03, 6369.36 examples/s]Converting format of dataset (num_proc=128):  59%|█████▊    | 32803/56026 [00:05<00:03, 6481.74 examples/s]Converting format of dataset (num_proc=128):  60%|█████▉    | 33453/56026 [00:05<00:03, 6472.58 examples/s]Converting format of dataset (num_proc=128):  61%|██████    | 34102/56026 [00:05<00:03, 6362.73 examples/s]Converting format of dataset (num_proc=128):  62%|██████▏   | 34773/56026 [00:05<00:03, 6445.52 examples/s]Converting format of dataset (num_proc=128):  63%|██████▎   | 35421/56026 [00:05<00:03, 6230.74 examples/s]Converting format of dataset (num_proc=128):  64%|██████▍   | 36046/56026 [00:05<00:03, 5989.68 examples/s]Converting format of dataset (num_proc=128):  66%|██████▌   | 36723/56026 [00:05<00:03, 6204.50 examples/s]Converting format of dataset (num_proc=128):  67%|██████▋   | 37377/56026 [00:05<00:02, 6298.18 examples/s]Converting format of dataset (num_proc=128):  68%|██████▊   | 38012/56026 [00:06<00:02, 6255.84 examples/s]Converting format of dataset (num_proc=128):  69%|██████▉   | 38663/56026 [00:06<00:02, 6314.28 examples/s]Converting format of dataset (num_proc=128):  70%|███████   | 39354/56026 [00:06<00:02, 6478.49 examples/s]Converting format of dataset (num_proc=128):  71%|███████▏  | 40005/56026 [00:06<00:02, 6437.35 examples/s]Converting format of dataset (num_proc=128):  73%|███████▎  | 40651/56026 [00:06<00:02, 6100.85 examples/s]Converting format of dataset (num_proc=128):  74%|███████▎  | 41315/56026 [00:06<00:02, 6232.89 examples/s]Converting format of dataset (num_proc=128):  75%|███████▍  | 41944/56026 [00:06<00:02, 6224.84 examples/s]Converting format of dataset (num_proc=128):  76%|███████▌  | 42571/56026 [00:06<00:02, 6139.85 examples/s]Converting format of dataset (num_proc=128):  77%|███████▋  | 43246/56026 [00:06<00:02, 6316.07 examples/s]Converting format of dataset (num_proc=128):  78%|███████▊  | 43884/56026 [00:06<00:01, 6330.01 examples/s]Converting format of dataset (num_proc=128):  79%|███████▉  | 44520/56026 [00:07<00:01, 6082.94 examples/s]Converting format of dataset (num_proc=128):  81%|████████  | 45224/56026 [00:07<00:01, 6354.29 examples/s]Converting format of dataset (num_proc=128):  82%|████████▏ | 45865/56026 [00:07<00:01, 6337.38 examples/s]Converting format of dataset (num_proc=128):  83%|████████▎ | 46514/56026 [00:07<00:01, 6380.39 examples/s]Converting format of dataset (num_proc=128):  84%|████████▍ | 47181/56026 [00:07<00:01, 6460.16 examples/s]Converting format of dataset (num_proc=128):  85%|████████▌ | 47831/56026 [00:07<00:01, 6343.11 examples/s]Converting format of dataset (num_proc=128):  87%|████████▋ | 48471/56026 [00:07<00:01, 6358.23 examples/s]Converting format of dataset (num_proc=128):  88%|████████▊ | 49110/56026 [00:07<00:01, 6329.66 examples/s]Converting format of dataset (num_proc=128):  89%|████████▉ | 49745/56026 [00:07<00:01, 6118.89 examples/s]Converting format of dataset (num_proc=128):  90%|████████▉ | 50400/56026 [00:08<00:00, 6239.15 examples/s]Converting format of dataset (num_proc=128):  91%|█████████ | 51056/56026 [00:08<00:00, 6317.64 examples/s]Converting format of dataset (num_proc=128):  92%|█████████▏| 51691/56026 [00:08<00:00, 6012.27 examples/s]Converting format of dataset (num_proc=128):  93%|█████████▎| 52336/56026 [00:08<00:00, 6127.99 examples/s]Converting format of dataset (num_proc=128):  95%|█████████▍| 52990/56026 [00:08<00:00, 6210.73 examples/s]Converting format of dataset (num_proc=128):  96%|█████████▌| 53616/56026 [00:08<00:00, 6158.70 examples/s]Converting format of dataset (num_proc=128):  97%|█████████▋| 54316/56026 [00:08<00:00, 6402.97 examples/s]Converting format of dataset (num_proc=128):  98%|█████████▊| 54961/56026 [00:08<00:00, 5819.73 examples/s]Converting format of dataset (num_proc=128):  99%|█████████▉| 55634/56026 [00:08<00:00, 6030.88 examples/s]Converting format of dataset (num_proc=128): 100%|██████████| 56026/56026 [00:09<00:00, 6205.04 examples/s]
num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
Converting format of dataset (num_proc=83):   0%|          | 0/83 [00:00<?, ? examples/s]Converting format of dataset (num_proc=83):  11%|█         | 9/83 [00:00<00:00, 85.90 examples/s]Converting format of dataset (num_proc=83): 100%|██████████| 83/83 [00:00<00:00, 296.80 examples/s]
/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1021 16:53:58.993849165 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
Running tokenizer on dataset (num_proc=128):   0%|          | 0/56026 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=128):   1%|          | 437/56026 [00:45<1:36:05,  9.64 examples/s]Running tokenizer on dataset (num_proc=128):   2%|▏         | 875/56026 [00:45<39:29, 23.28 examples/s]  Running tokenizer on dataset (num_proc=128):   2%|▏         | 1312/56026 [00:45<21:41, 42.05 examples/s]Running tokenizer on dataset (num_proc=128):   4%|▍         | 2186/56026 [00:46<09:40, 92.77 examples/s]Running tokenizer on dataset (num_proc=128):   5%|▍         | 2624/56026 [00:46<06:54, 128.86 examples/s]Running tokenizer on dataset (num_proc=128):   5%|▌         | 3062/56026 [00:47<05:14, 168.45 examples/s]Running tokenizer on dataset (num_proc=128):   6%|▌         | 3500/56026 [00:47<03:44, 233.74 examples/s]Running tokenizer on dataset (num_proc=128):   7%|▋         | 3937/56026 [00:49<03:31, 246.45 examples/s]Running tokenizer on dataset (num_proc=128):   8%|▊         | 4374/56026 [00:49<02:39, 323.54 examples/s]Running tokenizer on dataset (num_proc=128):   9%|▊         | 4811/56026 [00:51<02:45, 310.09 examples/s]Running tokenizer on dataset (num_proc=128):   9%|▉         | 5248/56026 [00:51<02:10, 389.94 examples/s]Running tokenizer on dataset (num_proc=128):  10%|█         | 5685/56026 [00:52<02:03, 408.38 examples/s]Running tokenizer on dataset (num_proc=128):  11%|█         | 6123/56026 [00:59<05:21, 155.21 examples/s]Running tokenizer on dataset (num_proc=128):  12%|█▏        | 6560/56026 [01:00<04:18, 191.14 examples/s]Running tokenizer on dataset (num_proc=128):  13%|█▎        | 7435/56026 [01:02<03:14, 249.74 examples/s]Running tokenizer on dataset (num_proc=128):  14%|█▍        | 7872/56026 [01:03<02:49, 284.58 examples/s]Running tokenizer on dataset (num_proc=128):  15%|█▍        | 8309/56026 [01:04<02:34, 309.34 examples/s]Running tokenizer on dataset (num_proc=128):  16%|█▌        | 8746/56026 [01:07<03:25, 229.70 examples/s]Running tokenizer on dataset (num_proc=128):  16%|█▋        | 9184/56026 [01:08<02:52, 270.85 examples/s]Running tokenizer on dataset (num_proc=128):  17%|█▋        | 9622/56026 [01:08<02:06, 367.97 examples/s]Running tokenizer on dataset (num_proc=128):  18%|█▊        | 10060/56026 [01:09<01:38, 466.11 examples/s]Running tokenizer on dataset (num_proc=128):  19%|█▊        | 10498/56026 [01:09<01:13, 615.69 examples/s]Running tokenizer on dataset (num_proc=128):  20%|█▉        | 10936/56026 [01:10<01:15, 600.28 examples/s]Running tokenizer on dataset (num_proc=128):  20%|██        | 11374/56026 [01:10<01:04, 696.77 examples/s]Running tokenizer on dataset (num_proc=128):  21%|██        | 11812/56026 [01:10<00:51, 859.97 examples/s]Running tokenizer on dataset (num_proc=128):  22%|██▏       | 12250/56026 [01:11<00:54, 802.10 examples/s]Running tokenizer on dataset (num_proc=128):  23%|██▎       | 12688/56026 [01:11<00:48, 901.81 examples/s]Running tokenizer on dataset (num_proc=128):  23%|██▎       | 13126/56026 [01:12<00:53, 803.67 examples/s]Running tokenizer on dataset (num_proc=128):  24%|██▍       | 13564/56026 [01:13<00:57, 734.12 examples/s]Running tokenizer on dataset (num_proc=128):  25%|██▍       | 14002/56026 [01:13<00:53, 779.21 examples/s]Running tokenizer on dataset (num_proc=128):  26%|██▌       | 14440/56026 [01:13<00:42, 976.28 examples/s]Running tokenizer on dataset (num_proc=128):  27%|██▋       | 14878/56026 [01:13<00:33, 1242.87 examples/s]Running tokenizer on dataset (num_proc=128):  27%|██▋       | 15316/56026 [01:14<00:36, 1107.69 examples/s]Running tokenizer on dataset (num_proc=128):  28%|██▊       | 15754/56026 [01:16<01:12, 555.53 examples/s] Running tokenizer on dataset (num_proc=128):  29%|██▉       | 16191/56026 [01:16<01:06, 598.72 examples/s]Running tokenizer on dataset (num_proc=128):  30%|██▉       | 16629/56026 [01:18<01:33, 420.67 examples/s]Running tokenizer on dataset (num_proc=128):  30%|███       | 17066/56026 [01:18<01:08, 565.82 examples/s]Running tokenizer on dataset (num_proc=128):  32%|███▏      | 17942/56026 [01:18<00:40, 933.83 examples/s]Running tokenizer on dataset (num_proc=128):  34%|███▎      | 18818/56026 [01:19<00:30, 1203.25 examples/s]Running tokenizer on dataset (num_proc=128):  34%|███▍      | 19256/56026 [01:19<00:25, 1425.95 examples/s]Running tokenizer on dataset (num_proc=128):  35%|███▌      | 19693/56026 [01:19<00:26, 1363.74 examples/s]Running tokenizer on dataset (num_proc=128):  37%|███▋      | 20569/56026 [01:19<00:17, 2063.98 examples/s]Running tokenizer on dataset (num_proc=128):  37%|███▋      | 21007/56026 [01:19<00:15, 2225.95 examples/s]Running tokenizer on dataset (num_proc=128):  38%|███▊      | 21445/56026 [01:20<00:13, 2499.71 examples/s]Running tokenizer on dataset (num_proc=128):  39%|███▉      | 21883/56026 [01:20<00:13, 2549.89 examples/s]Running tokenizer on dataset (num_proc=128):  40%|███▉      | 22321/56026 [01:20<00:21, 1589.49 examples/s]Running tokenizer on dataset (num_proc=128):  41%|████      | 22759/56026 [01:21<00:23, 1419.85 examples/s]Running tokenizer on dataset (num_proc=128):  41%|████▏     | 23196/56026 [01:21<00:29, 1102.25 examples/s]Running tokenizer on dataset (num_proc=128):  43%|████▎     | 24072/56026 [01:21<00:18, 1691.39 examples/s]Running tokenizer on dataset (num_proc=128):  44%|████▎     | 24510/56026 [01:22<00:19, 1656.14 examples/s]Running tokenizer on dataset (num_proc=128):  45%|████▍     | 24948/56026 [01:22<00:21, 1465.13 examples/s]Running tokenizer on dataset (num_proc=128):  45%|████▌     | 25386/56026 [01:22<00:21, 1411.78 examples/s]Running tokenizer on dataset (num_proc=128):  46%|████▌     | 25824/56026 [01:23<00:23, 1297.81 examples/s]Running tokenizer on dataset (num_proc=128):  48%|████▊     | 26700/56026 [01:23<00:18, 1595.23 examples/s]Running tokenizer on dataset (num_proc=128):  48%|████▊     | 27137/56026 [01:24<00:25, 1136.94 examples/s]Running tokenizer on dataset (num_proc=128):  51%|█████     | 28451/56026 [01:24<00:13, 2044.63 examples/s]Running tokenizer on dataset (num_proc=128):  52%|█████▏    | 28889/56026 [01:24<00:13, 1961.11 examples/s]Running tokenizer on dataset (num_proc=128):  52%|█████▏    | 29327/56026 [01:25<00:18, 1406.89 examples/s]Running tokenizer on dataset (num_proc=128):  53%|█████▎    | 29765/56026 [01:25<00:19, 1345.21 examples/s]Running tokenizer on dataset (num_proc=128):  54%|█████▍    | 30203/56026 [01:26<00:17, 1481.07 examples/s]Running tokenizer on dataset (num_proc=128):  55%|█████▌    | 31079/56026 [01:26<00:13, 1794.95 examples/s]Running tokenizer on dataset (num_proc=128):  57%|█████▋    | 31955/56026 [01:26<00:09, 2541.92 examples/s]Running tokenizer on dataset (num_proc=128):  58%|█████▊    | 32393/56026 [01:27<00:13, 1810.32 examples/s]Running tokenizer on dataset (num_proc=128):  59%|█████▊    | 32831/56026 [01:27<00:12, 1838.63 examples/s]Running tokenizer on dataset (num_proc=128):  59%|█████▉    | 33269/56026 [01:27<00:11, 2066.17 examples/s]Running tokenizer on dataset (num_proc=128):  60%|██████    | 33707/56026 [01:27<00:11, 2021.15 examples/s]Running tokenizer on dataset (num_proc=128):  61%|██████    | 34145/56026 [01:28<00:14, 1516.14 examples/s]Running tokenizer on dataset (num_proc=128):  63%|██████▎   | 35020/56026 [01:28<00:11, 1847.93 examples/s]Running tokenizer on dataset (num_proc=128):  63%|██████▎   | 35458/56026 [01:28<00:11, 1841.16 examples/s]Running tokenizer on dataset (num_proc=128):  66%|██████▌   | 36772/56026 [01:28<00:05, 3228.34 examples/s]Running tokenizer on dataset (num_proc=128):  67%|██████▋   | 37647/56026 [01:29<00:06, 3048.31 examples/s]Running tokenizer on dataset (num_proc=128):  70%|██████▉   | 38961/56026 [01:29<00:04, 4063.91 examples/s]Running tokenizer on dataset (num_proc=128):  72%|███████▏  | 40274/56026 [01:29<00:03, 4617.31 examples/s]Running tokenizer on dataset (num_proc=128):  73%|███████▎  | 41149/56026 [01:29<00:03, 4589.62 examples/s]Running tokenizer on dataset (num_proc=128):  75%|███████▌  | 42025/56026 [01:30<00:04, 2900.59 examples/s]Running tokenizer on dataset (num_proc=128):  76%|███████▌  | 42462/56026 [01:30<00:05, 2426.67 examples/s]Running tokenizer on dataset (num_proc=128):  77%|███████▋  | 43338/56026 [01:30<00:04, 2556.78 examples/s]Running tokenizer on dataset (num_proc=128):  78%|███████▊  | 43775/56026 [01:31<00:06, 1793.09 examples/s]Running tokenizer on dataset (num_proc=128):  79%|███████▉  | 44212/56026 [01:31<00:06, 1814.57 examples/s]Running tokenizer on dataset (num_proc=128):  80%|████████  | 45087/56026 [01:31<00:04, 2286.64 examples/s]Running tokenizer on dataset (num_proc=128):  81%|████████▏ | 45525/56026 [01:32<00:04, 2500.66 examples/s]Running tokenizer on dataset (num_proc=128):  83%|████████▎ | 46399/56026 [01:32<00:03, 2932.88 examples/s]Running tokenizer on dataset (num_proc=128):  84%|████████▍ | 47275/56026 [01:32<00:02, 3343.62 examples/s]Running tokenizer on dataset (num_proc=128):  86%|████████▌ | 48150/56026 [01:32<00:01, 4099.82 examples/s]Running tokenizer on dataset (num_proc=128):  88%|████████▊ | 49025/56026 [01:32<00:01, 3885.17 examples/s]Running tokenizer on dataset (num_proc=128):  90%|████████▉ | 50338/56026 [01:32<00:01, 5345.41 examples/s]Running tokenizer on dataset (num_proc=128):  92%|█████████▏| 51652/56026 [01:33<00:00, 5488.46 examples/s]Running tokenizer on dataset (num_proc=128):  94%|█████████▍| 52526/56026 [01:33<00:00, 4142.62 examples/s]Running tokenizer on dataset (num_proc=128):  95%|█████████▌| 53400/56026 [01:33<00:00, 4093.99 examples/s]Running tokenizer on dataset (num_proc=128):  97%|█████████▋| 54275/56026 [01:34<00:00, 3117.66 examples/s]Running tokenizer on dataset (num_proc=128):  98%|█████████▊| 54712/56026 [01:34<00:00, 3232.70 examples/s]Running tokenizer on dataset (num_proc=128):  98%|█████████▊| 55150/56026 [01:34<00:00, 3230.70 examples/s]Running tokenizer on dataset (num_proc=128):  99%|█████████▉| 55588/56026 [01:34<00:00, 2586.02 examples/s]Running tokenizer on dataset (num_proc=128): 100%|██████████| 56026/56026 [01:36<00:00, 714.44 examples/s] Running tokenizer on dataset (num_proc=128): 100%|██████████| 56026/56026 [01:36<00:00, 578.12 examples/s]
num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
Running tokenizer on dataset (num_proc=83):   0%|          | 0/83 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=83):   1%|          | 1/83 [00:00<01:01,  1.33 examples/s]Running tokenizer on dataset (num_proc=83):   2%|▏         | 2/83 [00:00<00:31,  2.60 examples/s]Running tokenizer on dataset (num_proc=83):   5%|▍         | 4/83 [00:01<00:16,  4.83 examples/s]Running tokenizer on dataset (num_proc=83):  11%|█         | 9/83 [00:01<00:06, 12.19 examples/s]Running tokenizer on dataset (num_proc=83):  13%|█▎        | 11/83 [00:01<00:05, 13.15 examples/s]Running tokenizer on dataset (num_proc=83):  16%|█▌        | 13/83 [00:01<00:05, 13.93 examples/s]Running tokenizer on dataset (num_proc=83):  18%|█▊        | 15/83 [00:01<00:04, 14.66 examples/s]Running tokenizer on dataset (num_proc=83):  20%|██        | 17/83 [00:01<00:04, 15.54 examples/s]Running tokenizer on dataset (num_proc=83):  23%|██▎       | 19/83 [00:01<00:04, 15.72 examples/s]Running tokenizer on dataset (num_proc=83):  25%|██▌       | 21/83 [00:01<00:03, 15.64 examples/s]Running tokenizer on dataset (num_proc=83):  28%|██▊       | 23/83 [00:02<00:03, 16.29 examples/s]Running tokenizer on dataset (num_proc=83):  30%|███       | 25/83 [00:02<00:03, 16.64 examples/s]Running tokenizer on dataset (num_proc=83):  33%|███▎      | 27/83 [00:02<00:03, 14.46 examples/s]Running tokenizer on dataset (num_proc=83):  36%|███▌      | 30/83 [00:02<00:03, 15.47 examples/s]Running tokenizer on dataset (num_proc=83):  40%|███▉      | 33/83 [00:02<00:02, 18.03 examples/s]Running tokenizer on dataset (num_proc=83):  42%|████▏     | 35/83 [00:02<00:02, 17.80 examples/s]Running tokenizer on dataset (num_proc=83):  45%|████▍     | 37/83 [00:02<00:02, 17.45 examples/s]Running tokenizer on dataset (num_proc=83):  47%|████▋     | 39/83 [00:02<00:02, 17.23 examples/s]Running tokenizer on dataset (num_proc=83):  49%|████▉     | 41/83 [00:03<00:02, 17.31 examples/s]Running tokenizer on dataset (num_proc=83):  52%|█████▏    | 43/83 [00:03<00:02, 17.19 examples/s]Running tokenizer on dataset (num_proc=83):  54%|█████▍    | 45/83 [00:03<00:02, 17.19 examples/s]Running tokenizer on dataset (num_proc=83):  58%|█████▊    | 48/83 [00:03<00:02, 17.01 examples/s]Running tokenizer on dataset (num_proc=83):  60%|██████    | 50/83 [00:03<00:01, 17.06 examples/s]Running tokenizer on dataset (num_proc=83):  63%|██████▎   | 52/83 [00:03<00:01, 16.91 examples/s]Running tokenizer on dataset (num_proc=83):  65%|██████▌   | 54/83 [00:03<00:01, 16.96 examples/s]Running tokenizer on dataset (num_proc=83):  67%|██████▋   | 56/83 [00:03<00:01, 16.93 examples/s]Running tokenizer on dataset (num_proc=83):  70%|██████▉   | 58/83 [00:04<00:01, 16.90 examples/s]Running tokenizer on dataset (num_proc=83):  72%|███████▏  | 60/83 [00:04<00:01, 16.85 examples/s]Running tokenizer on dataset (num_proc=83):  75%|███████▍  | 62/83 [00:04<00:01, 17.01 examples/s]Running tokenizer on dataset (num_proc=83):  77%|███████▋  | 64/83 [00:04<00:01, 14.80 examples/s]Running tokenizer on dataset (num_proc=83):  81%|████████  | 67/83 [00:04<00:00, 17.76 examples/s]Running tokenizer on dataset (num_proc=83):  83%|████████▎ | 69/83 [00:04<00:00, 17.68 examples/s]Running tokenizer on dataset (num_proc=83):  86%|████████▌ | 71/83 [00:04<00:00, 17.58 examples/s]Running tokenizer on dataset (num_proc=83):  88%|████████▊ | 73/83 [00:05<00:00, 15.03 examples/s]Running tokenizer on dataset (num_proc=83):  92%|█████████▏| 76/83 [00:05<00:00, 17.62 examples/s]Running tokenizer on dataset (num_proc=83):  94%|█████████▍| 78/83 [00:05<00:00, 17.85 examples/s]Running tokenizer on dataset (num_proc=83):  96%|█████████▋| 80/83 [00:05<00:00, 17.77 examples/s]Running tokenizer on dataset (num_proc=83): 100%|██████████| 83/83 [00:05<00:00, 17.71 examples/s]Running tokenizer on dataset (num_proc=83): 100%|██████████| 83/83 [00:05<00:00, 14.69 examples/s]
[INFO|configuration_utils.py:765] 2025-10-21 16:55:48,813 >> loading configuration file config.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/config.json
[INFO|configuration_utils.py:839] 2025-10-21 16:55:48,816 >> Model config Qwen3VLConfig {
  "architectures": [
    "Qwen3VLForConditionalGeneration"
  ],
  "image_token_id": 151655,
  "model_type": "qwen3_vl",
  "text_config": {
    "attention_bias": false,
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "dtype": "bfloat16",
    "eos_token_id": 151645,
    "head_dim": 128,
    "hidden_act": "silu",
    "hidden_size": 2560,
    "initializer_range": 0.02,
    "intermediate_size": 9728,
    "max_position_embeddings": 262144,
    "model_type": "qwen3_vl_text",
    "num_attention_heads": 32,
    "num_hidden_layers": 36,
    "num_key_value_heads": 8,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_interleaved": true,
      "mrope_section": [
        24,
        20,
        20
      ],
      "rope_type": "default"
    },
    "rope_theta": 5000000,
    "tie_word_embeddings": true,
    "use_cache": true,
    "vocab_size": 151936
  },
  "tie_word_embeddings": true,
  "transformers_version": "4.57.1",
  "video_token_id": 151656,
  "vision_config": {
    "deepstack_visual_indexes": [
      5,
      11,
      17
    ],
    "depth": 24,
    "hidden_act": "gelu_pytorch_tanh",
    "hidden_size": 1024,
    "in_channels": 3,
    "initializer_range": 0.02,
    "intermediate_size": 4096,
    "model_type": "qwen3_vl",
    "num_heads": 16,
    "num_position_embeddings": 2304,
    "out_hidden_size": 2560,
    "patch_size": 16,
    "spatial_merge_size": 2,
    "temporal_patch_size": 2
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652
}

num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
[WARNING|logging.py:328] 2025-10-21 16:55:49,030 >> `torch_dtype` is deprecated! Use `dtype` instead!
num_proc must be <= 83. Reducing num_proc to 83 for dataset of size 83.
[INFO|modeling_utils.py:1172] 2025-10-21 16:55:49,031 >> loading weights file model.safetensors from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/model.safetensors.index.json
[INFO|modeling_utils.py:2341] 2025-10-21 16:55:49,033 >> Instantiating Qwen3VLForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:986] 2025-10-21 16:55:49,041 >> Generate config GenerationConfig {
  "use_cache": false
}

[INFO|modeling_utils.py:2341] 2025-10-21 16:55:49,044 >> Instantiating Qwen3VLVisionModel model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:2341] 2025-10-21 16:55:49,056 >> Instantiating Qwen3VLTextModel model under default dtype torch.bfloat16.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.12s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.20s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.57s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.95s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.98s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 12.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 13.16s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.94s/it]
[INFO|configuration_utils.py:941] 2025-10-21 16:56:15,569 >> loading configuration file generation_config.json from cache at /home/hk-project-sustainebot/bm3844/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/generation_config.json
[INFO|configuration_utils.py:986] 2025-10-21 16:56:15,569 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.7,
  "top_k": 20,
  "top_p": 0.8
}

[INFO|dynamic_module_utils.py:423] 2025-10-21 16:56:15,688 >> Could not locate the custom_generate/generate.py inside Qwen/Qwen3-VL-4B-Instruct.
The model is already on multiple devices. Skipping the move to device specified in `args`.
[WARNING|trainer.py:906] 2025-10-21 16:56:15,709 >> The model is already on multiple devices. Skipping the move to device specified in `args`.
The model is already on multiple devices. Skipping the move to device specified in `args`.
[INFO|trainer.py:749] 2025-10-21 16:56:15,746 >> Using auto half precision backend
The model is already on multiple devices. Skipping the move to device specified in `args`.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 151645, 'bos_token_id': None, 'pad_token_id': 151643}.
[WARNING|trainer.py:982] 2025-10-21 16:56:16,023 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 151645, 'bos_token_id': None, 'pad_token_id': 151643}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 151645, 'bos_token_id': None, 'pad_token_id': 151643}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 151645, 'bos_token_id': None, 'pad_token_id': 151643}.
[INFO|trainer.py:1335] 2025-10-21 16:56:22,882 >> skipped Embedding(2304, 1024): 2.25M params
[INFO|trainer.py:1335] 2025-10-21 16:56:22,883 >> skipped Embedding(151936, 2560): 373.1875M params
[INFO|trainer.py:1338] 2025-10-21 16:56:22,883 >> skipped: 373.1875M params
[INFO|trainer.py:2519] 2025-10-21 16:56:23,070 >> ***** Running training *****
[INFO|trainer.py:2520] 2025-10-21 16:56:23,070 >>   Num examples = 56,026
[INFO|trainer.py:2521] 2025-10-21 16:56:23,070 >>   Num Epochs = 3
[INFO|trainer.py:2522] 2025-10-21 16:56:23,070 >>   Instantaneous batch size per device = 16
[INFO|trainer.py:2525] 2025-10-21 16:56:23,070 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:2526] 2025-10-21 16:56:23,070 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:2527] 2025-10-21 16:56:23,070 >>   Total optimization steps = 2,628
[INFO|trainer.py:2528] 2025-10-21 16:56:23,072 >>   Number of trainable parameters = 4,106,660,864
[INFO|integration_utils.py:867] 2025-10-21 16:56:23,073 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: niblank to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.22.0
wandb: Run data is saved locally in /hkfs/home/project/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/wandb/run-20251021_165623-ny5w6xja
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ${model_name_or_path}_${dataset}_${stage}
wandb: ⭐️ View project at https://wandb.ai/niblank/llamafactory
wandb: 🚀 View run at https://wandb.ai/niblank/llamafactory/runs/ny5w6xja
  0%|          | 0/2628 [00:00<?, ?it/s]  0%|          | 1/2628 [00:03<2:51:43,  3.92s/it]  0%|          | 2/2628 [00:05<2:00:36,  2.76s/it]  0%|          | 3/2628 [00:07<1:41:54,  2.33s/it]  0%|          | 4/2628 [00:09<1:33:03,  2.13s/it]  0%|          | 5/2628 [00:11<1:27:47,  2.01s/it]  0%|          | 6/2628 [00:13<1:24:42,  1.94s/it]  0%|          | 7/2628 [00:14<1:22:47,  1.90s/it]  0%|          | 8/2628 [00:16<1:21:25,  1.86s/it]  0%|          | 9/2628 [00:18<1:20:46,  1.85s/it]  0%|          | 10/2628 [00:20<1:20:01,  1.83s/it]                                                     0%|          | 10/2628 [00:20<1:20:01,  1.83s/it]  0%|          | 11/2628 [00:22<1:19:50,  1.83s/it]  0%|          | 12/2628 [00:23<1:19:26,  1.82s/it]  0%|          | 13/2628 [00:25<1:19:18,  1.82s/it]  1%|          | 14/2628 [00:27<1:19:05,  1.82s/it]  1%|          | 15/2628 [00:29<1:18:54,  1.81s/it]  1%|          | 16/2628 [00:31<1:18:44,  1.81s/it]  1%|          | 17/2628 [00:32<1:18:42,  1.81s/it]  1%|          | 18/2628 [00:34<1:18:35,  1.81s/it]  1%|          | 19/2628 [00:36<1:18:32,  1.81s/it]  1%|          | 20/2628 [00:38<1:18:32,  1.81s/it]                                                     1%|          | 20/2628 [00:38<1:18:32,  1.81s/it]  1%|          | 21/2628 [00:40<1:18:31,  1.81s/it]  1%|          | 22/2628 [00:42<1:18:21,  1.80s/it]  1%|          | 23/2628 [00:43<1:18:24,  1.81s/it]  1%|          | 24/2628 [00:45<1:18:19,  1.80s/it]  1%|          | 25/2628 [00:47<1:18:19,  1.81s/it]  1%|          | 26/2628 [00:49<1:18:18,  1.81s/it]  1%|          | 27/2628 [00:51<1:18:12,  1.80s/it]  1%|          | 28/2628 [00:52<1:18:20,  1.81s/it]  1%|          | 29/2628 [00:54<1:18:09,  1.80s/it]  1%|          | 30/2628 [00:56<1:18:14,  1.81s/it]                                                     1%|          | 30/2628 [00:56<1:18:14,  1.81s/it]  1%|          | 31/2628 [00:58<1:18:19,  1.81s/it]  1%|          | 32/2628 [01:00<1:18:09,  1.81s/it]  1%|▏         | 33/2628 [01:01<1:18:05,  1.81s/it]  1%|▏         | 34/2628 [01:03<1:17:59,  1.80s/it]  1%|▏         | 35/2628 [01:05<1:18:09,  1.81s/it]  1%|▏         | 36/2628 [01:07<1:18:06,  1.81s/it]  1%|▏         | 37/2628 [01:09<1:18:01,  1.81s/it]  1%|▏         | 38/2628 [01:10<1:18:01,  1.81s/it]  1%|▏         | 39/2628 [01:12<1:18:03,  1.81s/it]  2%|▏         | 40/2628 [01:14<1:18:02,  1.81s/it]                                                     2%|▏         | 40/2628 [01:14<1:18:02,  1.81s/it]  2%|▏         | 41/2628 [01:16<1:17:55,  1.81s/it]  2%|▏         | 42/2628 [01:18<1:17:48,  1.81s/it]  2%|▏         | 43/2628 [01:19<1:17:41,  1.80s/it]  2%|▏         | 44/2628 [01:21<1:17:35,  1.80s/it]  2%|▏         | 45/2628 [01:23<1:17:46,  1.81s/it]  2%|▏         | 46/2628 [01:25<1:17:36,  1.80s/it]  2%|▏         | 47/2628 [01:27<1:17:31,  1.80s/it]  2%|▏         | 48/2628 [01:28<1:17:43,  1.81s/it]  2%|▏         | 49/2628 [01:30<1:17:42,  1.81s/it]  2%|▏         | 50/2628 [01:32<1:17:27,  1.80s/it]                                                     2%|▏         | 50/2628 [01:32<1:17:27,  1.80s/it]  2%|▏         | 51/2628 [01:34<1:17:34,  1.81s/it]  2%|▏         | 52/2628 [01:36<1:17:28,  1.80s/it]  2%|▏         | 53/2628 [01:37<1:17:25,  1.80s/it]  2%|▏         | 54/2628 [01:39<1:17:17,  1.80s/it]  2%|▏         | 55/2628 [01:41<1:17:26,  1.81s/it]  2%|▏         | 56/2628 [01:43<1:17:23,  1.81s/it]  2%|▏         | 57/2628 [01:45<1:17:19,  1.80s/it]  2%|▏         | 58/2628 [01:46<1:17:11,  1.80s/it]  2%|▏         | 59/2628 [01:48<1:17:09,  1.80s/it]  2%|▏         | 60/2628 [01:50<1:17:06,  1.80s/it]                                                     2%|▏         | 60/2628 [01:50<1:17:06,  1.80s/it]  2%|▏         | 61/2628 [01:52<1:17:07,  1.80s/it]  2%|▏         | 62/2628 [01:54<1:16:59,  1.80s/it]  2%|▏         | 63/2628 [01:56<1:16:56,  1.80s/it]  2%|▏         | 64/2628 [01:57<1:17:05,  1.80s/it]  2%|▏         | 65/2628 [01:59<1:17:01,  1.80s/it]  3%|▎         | 66/2628 [02:01<1:16:58,  1.80s/it]  3%|▎         | 67/2628 [02:03<1:16:55,  1.80s/it]  3%|▎         | 68/2628 [02:05<1:16:51,  1.80s/it]  3%|▎         | 69/2628 [02:06<1:16:48,  1.80s/it]  3%|▎         | 70/2628 [02:08<1:16:44,  1.80s/it]                                                     3%|▎         | 70/2628 [02:08<1:16:44,  1.80s/it]  3%|▎         | 71/2628 [02:10<1:16:48,  1.80s/it]  3%|▎         | 72/2628 [02:12<1:16:45,  1.80s/it]  3%|▎         | 73/2628 [02:14<1:16:41,  1.80s/it]  3%|▎         | 74/2628 [02:15<1:16:51,  1.81s/it]  3%|▎         | 75/2628 [02:17<1:16:46,  1.80s/it]  3%|▎         | 76/2628 [02:19<1:16:42,  1.80s/it]  3%|▎         | 77/2628 [02:21<1:16:44,  1.81s/it]  3%|▎         | 78/2628 [02:23<1:16:36,  1.80s/it]  3%|▎         | 79/2628 [02:24<1:16:38,  1.80s/it]  3%|▎         | 80/2628 [02:26<1:16:32,  1.80s/it]                                                     3%|▎         | 80/2628 [02:26<1:16:32,  1.80s/it]  3%|▎         | 81/2628 [02:28<1:16:34,  1.80s/it]  3%|▎         | 82/2628 [02:30<1:16:26,  1.80s/it]  3%|▎         | 83/2628 [02:32<1:16:23,  1.80s/it]  3%|▎         | 84/2628 [02:33<1:16:21,  1.80s/it]  3%|▎         | 85/2628 [02:35<1:16:19,  1.80s/it]  3%|▎         | 86/2628 [02:37<1:16:17,  1.80s/it]  3%|▎         | 87/2628 [02:39<1:16:13,  1.80s/it]  3%|▎         | 88/2628 [02:41<1:16:13,  1.80s/it]  3%|▎         | 89/2628 [02:42<1:16:09,  1.80s/it]  3%|▎         | 90/2628 [02:44<1:16:06,  1.80s/it]                                                     3%|▎         | 90/2628 [02:44<1:16:06,  1.80s/it]  3%|▎         | 91/2628 [02:46<1:16:08,  1.80s/it]  4%|▎         | 92/2628 [02:48<1:16:13,  1.80s/it]  4%|▎         | 93/2628 [02:50<1:16:08,  1.80s/it]  4%|▎         | 94/2628 [02:51<1:16:05,  1.80s/it]  4%|▎         | 95/2628 [02:53<1:16:16,  1.81s/it]  4%|▎         | 96/2628 [02:55<1:16:09,  1.80s/it]  4%|▎         | 97/2628 [02:57<1:16:01,  1.80s/it]  4%|▎         | 98/2628 [02:59<1:16:08,  1.81s/it]  4%|▍         | 99/2628 [03:00<1:16:15,  1.81s/it]  4%|▍         | 100/2628 [03:02<1:16:08,  1.81s/it]                                                      4%|▍         | 100/2628 [03:02<1:16:08,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 16:59:27,555 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 16:59:27,555 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 16:59:27,555 >>   Batch size = 8
[WARNING|utils.py:2443] 2025-10-21 16:59:28,038 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 16:59:31,377 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:03<00:01,  1.83s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 16:59:35,100 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:08<00:00,  3.22s/it][ABuilding prefix dict from the default dictionary ...
Building prefix dict from the default dictionary ...
Building prefix dict from the default dictionary ...
Building prefix dict from the default dictionary ...
Dumping model to file cache /scratch/slurm_tmpdir/job_3589330/jieba.cache
Dumping model to file cache /scratch/slurm_tmpdir/job_3589330/jieba.cache
Dumping model to file cache /scratch/slurm_tmpdir/job_3589330/jieba.cache
Dumping model to file cache /scratch/slurm_tmpdir/job_3589330/jieba.cache
Loading model cost 0.386 seconds.
Prefix dict has been built successfully.
Loading model cost 0.389 seconds.
Prefix dict has been built successfully.
Loading model cost 0.391 seconds.
Prefix dict has been built successfully.
Loading model cost 0.402 seconds.
Prefix dict has been built successfully.
                                                    
                                             [A  4%|▍         | 100/2628 [03:15<1:16:08,  1.81s/it]
100%|██████████| 3/3 [00:09<00:00,  3.22s/it][A
                                             [A  4%|▍         | 101/2628 [03:18<4:06:52,  5.86s/it]  4%|▍         | 102/2628 [03:19<3:15:33,  4.65s/it]  4%|▍         | 103/2628 [03:21<2:39:35,  3.79s/it]  4%|▍         | 104/2628 [03:23<2:14:20,  3.19s/it]  4%|▍         | 105/2628 [03:25<1:56:43,  2.78s/it]  4%|▍         | 106/2628 [03:27<1:44:33,  2.49s/it]  4%|▍         | 107/2628 [03:28<1:35:49,  2.28s/it]  4%|▍         | 108/2628 [03:30<1:29:42,  2.14s/it]  4%|▍         | 109/2628 [03:32<1:25:35,  2.04s/it]  4%|▍         | 110/2628 [03:34<1:22:44,  1.97s/it]                                                      4%|▍         | 110/2628 [03:34<1:22:44,  1.97s/it]  4%|▍         | 111/2628 [03:36<1:20:39,  1.92s/it]  4%|▍         | 112/2628 [03:37<1:19:06,  1.89s/it]  4%|▍         | 113/2628 [03:39<1:18:00,  1.86s/it]  4%|▍         | 114/2628 [03:41<1:17:15,  1.84s/it]  4%|▍         | 115/2628 [03:43<1:16:42,  1.83s/it]  4%|▍         | 116/2628 [03:45<1:16:24,  1.83s/it]  4%|▍         | 117/2628 [03:46<1:16:04,  1.82s/it]  4%|▍         | 118/2628 [03:48<1:15:46,  1.81s/it]  5%|▍         | 119/2628 [03:50<1:15:42,  1.81s/it]  5%|▍         | 120/2628 [03:52<1:15:44,  1.81s/it]                                                      5%|▍         | 120/2628 [03:52<1:15:44,  1.81s/it]  5%|▍         | 121/2628 [03:54<1:15:34,  1.81s/it]  5%|▍         | 122/2628 [03:55<1:15:40,  1.81s/it]  5%|▍         | 123/2628 [03:57<1:15:41,  1.81s/it]  5%|▍         | 124/2628 [03:59<1:15:33,  1.81s/it]  5%|▍         | 125/2628 [04:01<1:15:25,  1.81s/it]  5%|▍         | 126/2628 [04:03<1:15:16,  1.81s/it]  5%|▍         | 127/2628 [04:04<1:15:12,  1.80s/it]  5%|▍         | 128/2628 [04:06<1:15:21,  1.81s/it]  5%|▍         | 129/2628 [04:08<1:15:38,  1.82s/it]  5%|▍         | 130/2628 [04:10<1:15:22,  1.81s/it]                                                      5%|▍         | 130/2628 [04:10<1:15:22,  1.81s/it]  5%|▍         | 131/2628 [04:12<1:15:30,  1.81s/it]  5%|▌         | 132/2628 [04:14<1:15:17,  1.81s/it]  5%|▌         | 133/2628 [04:15<1:15:19,  1.81s/it]  5%|▌         | 134/2628 [04:17<1:15:10,  1.81s/it]  5%|▌         | 135/2628 [04:19<1:15:05,  1.81s/it]  5%|▌         | 136/2628 [04:21<1:14:55,  1.80s/it]  5%|▌         | 137/2628 [04:23<1:14:53,  1.80s/it]  5%|▌         | 138/2628 [04:24<1:14:43,  1.80s/it]  5%|▌         | 139/2628 [04:26<1:14:42,  1.80s/it]  5%|▌         | 140/2628 [04:28<1:14:43,  1.80s/it]                                                      5%|▌         | 140/2628 [04:28<1:14:43,  1.80s/it]  5%|▌         | 141/2628 [04:30<1:14:41,  1.80s/it]  5%|▌         | 142/2628 [04:32<1:14:46,  1.80s/it]  5%|▌         | 143/2628 [04:33<1:14:41,  1.80s/it]  5%|▌         | 144/2628 [04:35<1:14:46,  1.81s/it]  6%|▌         | 145/2628 [04:37<1:14:41,  1.80s/it]  6%|▌         | 146/2628 [04:39<1:14:36,  1.80s/it]  6%|▌         | 147/2628 [04:41<1:14:44,  1.81s/it]  6%|▌         | 148/2628 [04:42<1:14:33,  1.80s/it]  6%|▌         | 149/2628 [04:44<1:14:27,  1.80s/it]  6%|▌         | 150/2628 [04:46<1:14:22,  1.80s/it]                                                      6%|▌         | 150/2628 [04:46<1:14:22,  1.80s/it]  6%|▌         | 151/2628 [04:48<1:14:21,  1.80s/it]  6%|▌         | 152/2628 [04:50<1:14:16,  1.80s/it]  6%|▌         | 153/2628 [04:51<1:14:23,  1.80s/it]  6%|▌         | 154/2628 [04:53<1:14:24,  1.80s/it]  6%|▌         | 155/2628 [04:55<1:14:20,  1.80s/it]  6%|▌         | 156/2628 [04:57<1:14:11,  1.80s/it]  6%|▌         | 157/2628 [04:59<1:14:10,  1.80s/it]  6%|▌         | 158/2628 [05:00<1:14:01,  1.80s/it]  6%|▌         | 159/2628 [05:02<1:13:57,  1.80s/it]  6%|▌         | 160/2628 [05:04<1:14:06,  1.80s/it]                                                      6%|▌         | 160/2628 [05:04<1:14:06,  1.80s/it]  6%|▌         | 161/2628 [05:06<1:14:03,  1.80s/it]  6%|▌         | 162/2628 [05:08<1:13:58,  1.80s/it]  6%|▌         | 163/2628 [05:09<1:13:58,  1.80s/it]  6%|▌         | 164/2628 [05:11<1:14:04,  1.80s/it]  6%|▋         | 165/2628 [05:13<1:14:10,  1.81s/it]  6%|▋         | 166/2628 [05:15<1:14:03,  1.80s/it]  6%|▋         | 167/2628 [05:17<1:13:55,  1.80s/it]  6%|▋         | 168/2628 [05:18<1:13:49,  1.80s/it]  6%|▋         | 169/2628 [05:20<1:13:56,  1.80s/it]  6%|▋         | 170/2628 [05:22<1:14:04,  1.81s/it]                                                      6%|▋         | 170/2628 [05:22<1:14:04,  1.81s/it]  7%|▋         | 171/2628 [05:24<1:13:54,  1.81s/it]  7%|▋         | 172/2628 [05:26<1:14:06,  1.81s/it]  7%|▋         | 173/2628 [05:27<1:13:58,  1.81s/it]  7%|▋         | 174/2628 [05:29<1:13:47,  1.80s/it]  7%|▋         | 175/2628 [05:31<1:13:39,  1.80s/it]  7%|▋         | 176/2628 [05:33<1:13:31,  1.80s/it]  7%|▋         | 177/2628 [05:35<1:13:28,  1.80s/it]  7%|▋         | 178/2628 [05:36<1:13:35,  1.80s/it]  7%|▋         | 179/2628 [05:38<1:13:43,  1.81s/it]  7%|▋         | 180/2628 [05:40<1:13:38,  1.80s/it]                                                      7%|▋         | 180/2628 [05:40<1:13:38,  1.80s/it]  7%|▋         | 181/2628 [05:42<1:13:47,  1.81s/it]  7%|▋         | 182/2628 [05:44<1:13:37,  1.81s/it]  7%|▋         | 183/2628 [05:46<1:13:42,  1.81s/it]  7%|▋         | 184/2628 [05:47<1:13:44,  1.81s/it]  7%|▋         | 185/2628 [05:49<1:13:34,  1.81s/it]  7%|▋         | 186/2628 [05:51<1:13:25,  1.80s/it]  7%|▋         | 187/2628 [05:53<1:13:17,  1.80s/it]  7%|▋         | 188/2628 [05:55<1:13:11,  1.80s/it]  7%|▋         | 189/2628 [05:56<1:13:21,  1.80s/it]  7%|▋         | 190/2628 [05:58<1:13:12,  1.80s/it]                                                      7%|▋         | 190/2628 [05:58<1:13:12,  1.80s/it]  7%|▋         | 191/2628 [06:00<1:13:11,  1.80s/it]  7%|▋         | 192/2628 [06:02<1:13:08,  1.80s/it]  7%|▋         | 193/2628 [06:04<1:13:03,  1.80s/it]  7%|▋         | 194/2628 [06:05<1:12:56,  1.80s/it]  7%|▋         | 195/2628 [06:07<1:12:58,  1.80s/it]  7%|▋         | 196/2628 [06:09<1:12:56,  1.80s/it]  7%|▋         | 197/2628 [06:11<1:13:01,  1.80s/it]  8%|▊         | 198/2628 [06:13<1:12:58,  1.80s/it]  8%|▊         | 199/2628 [06:14<1:13:01,  1.80s/it]  8%|▊         | 200/2628 [06:16<1:12:55,  1.80s/it]                                                      8%|▊         | 200/2628 [06:16<1:12:55,  1.80s/it][INFO|trainer.py:4643] 2025-10-21 17:02:41,508 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 17:02:41,508 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 17:02:41,508 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:02:42,125 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:02:45,255 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:02<00:01,  1.33s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:02:47,979 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:05<00:00,  1.84s/it][A                                                    
                                             [A  8%|▊         | 200/2628 [06:25<1:12:55,  1.80s/it]
100%|██████████| 3/3 [00:05<00:00,  1.84s/it][A
                                             [A  8%|▊         | 201/2628 [06:27<3:03:42,  4.54s/it]  8%|▊         | 202/2628 [06:29<2:30:39,  3.73s/it]  8%|▊         | 203/2628 [06:31<2:07:13,  3.15s/it]  8%|▊         | 204/2628 [06:33<1:50:45,  2.74s/it]  8%|▊         | 205/2628 [06:34<1:39:25,  2.46s/it]  8%|▊         | 206/2628 [06:36<1:31:25,  2.26s/it]  8%|▊         | 207/2628 [06:38<1:25:46,  2.13s/it]  8%|▊         | 208/2628 [06:40<1:21:46,  2.03s/it]  8%|▊         | 209/2628 [06:42<1:18:57,  1.96s/it]  8%|▊         | 210/2628 [06:43<1:16:59,  1.91s/it]                                                      8%|▊         | 210/2628 [06:43<1:16:59,  1.91s/it]  8%|▊         | 211/2628 [06:45<1:15:50,  1.88s/it]  8%|▊         | 212/2628 [06:47<1:14:49,  1.86s/it]  8%|▊         | 213/2628 [06:49<1:14:05,  1.84s/it]  8%|▊         | 214/2628 [06:51<1:13:54,  1.84s/it]  8%|▊         | 215/2628 [06:52<1:13:26,  1.83s/it]  8%|▊         | 216/2628 [06:54<1:13:07,  1.82s/it]  8%|▊         | 217/2628 [06:56<1:12:50,  1.81s/it]  8%|▊         | 218/2628 [06:58<1:12:48,  1.81s/it]  8%|▊         | 219/2628 [07:00<1:12:38,  1.81s/it]  8%|▊         | 220/2628 [07:01<1:12:29,  1.81s/it]                                                      8%|▊         | 220/2628 [07:01<1:12:29,  1.81s/it]  8%|▊         | 221/2628 [07:03<1:12:32,  1.81s/it]  8%|▊         | 222/2628 [07:05<1:12:33,  1.81s/it]  8%|▊         | 223/2628 [07:07<1:12:29,  1.81s/it]  9%|▊         | 224/2628 [07:09<1:12:27,  1.81s/it]  9%|▊         | 225/2628 [07:10<1:12:17,  1.81s/it]  9%|▊         | 226/2628 [07:12<1:12:16,  1.81s/it]  9%|▊         | 227/2628 [07:14<1:12:14,  1.81s/it]  9%|▊         | 228/2628 [07:16<1:12:07,  1.80s/it]  9%|▊         | 229/2628 [07:18<1:12:15,  1.81s/it]  9%|▉         | 230/2628 [07:19<1:12:04,  1.80s/it]                                                      9%|▉         | 230/2628 [07:19<1:12:04,  1.80s/it]  9%|▉         | 231/2628 [07:21<1:11:58,  1.80s/it]  9%|▉         | 232/2628 [07:23<1:11:54,  1.80s/it]  9%|▉         | 233/2628 [07:25<1:11:49,  1.80s/it]  9%|▉         | 234/2628 [07:27<1:11:46,  1.80s/it]  9%|▉         | 235/2628 [07:28<1:11:55,  1.80s/it]  9%|▉         | 236/2628 [07:30<1:11:52,  1.80s/it]  9%|▉         | 237/2628 [07:32<1:11:49,  1.80s/it]  9%|▉         | 238/2628 [07:34<1:11:54,  1.81s/it]  9%|▉         | 239/2628 [07:36<1:12:00,  1.81s/it]  9%|▉         | 240/2628 [07:37<1:11:53,  1.81s/it]                                                      9%|▉         | 240/2628 [07:37<1:11:53,  1.81s/it]  9%|▉         | 241/2628 [07:39<1:11:48,  1.80s/it]  9%|▉         | 242/2628 [07:41<1:11:55,  1.81s/it]  9%|▉         | 243/2628 [07:43<1:11:45,  1.81s/it]  9%|▉         | 244/2628 [07:45<1:11:42,  1.80s/it]  9%|▉         | 245/2628 [07:46<1:11:36,  1.80s/it]  9%|▉         | 246/2628 [07:48<1:11:40,  1.81s/it]  9%|▉         | 247/2628 [07:50<1:11:35,  1.80s/it]  9%|▉         | 248/2628 [07:52<1:11:35,  1.80s/it]  9%|▉         | 249/2628 [07:54<1:11:28,  1.80s/it] 10%|▉         | 250/2628 [07:56<1:11:32,  1.81s/it]                                                     10%|▉         | 250/2628 [07:56<1:11:32,  1.81s/it] 10%|▉         | 251/2628 [07:57<1:11:24,  1.80s/it] 10%|▉         | 252/2628 [07:59<1:11:21,  1.80s/it] 10%|▉         | 253/2628 [08:01<1:11:18,  1.80s/it] 10%|▉         | 254/2628 [08:03<1:11:15,  1.80s/it] 10%|▉         | 255/2628 [08:05<1:11:23,  1.81s/it] 10%|▉         | 256/2628 [08:06<1:11:18,  1.80s/it] 10%|▉         | 257/2628 [08:08<1:11:20,  1.81s/it] 10%|▉         | 258/2628 [08:10<1:11:12,  1.80s/it] 10%|▉         | 259/2628 [08:12<1:11:12,  1.80s/it] 10%|▉         | 260/2628 [08:14<1:11:05,  1.80s/it]                                                     10%|▉         | 260/2628 [08:14<1:11:05,  1.80s/it] 10%|▉         | 261/2628 [08:15<1:11:16,  1.81s/it] 10%|▉         | 262/2628 [08:17<1:11:23,  1.81s/it] 10%|█         | 263/2628 [08:19<1:11:24,  1.81s/it] 10%|█         | 264/2628 [08:21<1:11:12,  1.81s/it] 10%|█         | 265/2628 [08:23<1:11:15,  1.81s/it] 10%|█         | 266/2628 [08:24<1:11:08,  1.81s/it] 10%|█         | 267/2628 [08:26<1:11:00,  1.80s/it] 10%|█         | 268/2628 [08:28<1:10:58,  1.80s/it] 10%|█         | 269/2628 [08:30<1:11:03,  1.81s/it] 10%|█         | 270/2628 [08:32<1:10:58,  1.81s/it]                                                     10%|█         | 270/2628 [08:32<1:10:58,  1.81s/it] 10%|█         | 271/2628 [08:33<1:10:54,  1.81s/it] 10%|█         | 272/2628 [08:35<1:10:52,  1.80s/it] 10%|█         | 273/2628 [08:37<1:10:51,  1.81s/it] 10%|█         | 274/2628 [08:39<1:10:54,  1.81s/it] 10%|█         | 275/2628 [08:41<1:10:47,  1.81s/it] 11%|█         | 276/2628 [08:42<1:10:38,  1.80s/it] 11%|█         | 277/2628 [08:44<1:10:38,  1.80s/it] 11%|█         | 278/2628 [08:46<1:10:34,  1.80s/it] 11%|█         | 279/2628 [08:48<1:10:26,  1.80s/it] 11%|█         | 280/2628 [08:50<1:10:41,  1.81s/it]                                                     11%|█         | 280/2628 [08:50<1:10:41,  1.81s/it] 11%|█         | 281/2628 [08:51<1:10:47,  1.81s/it] 11%|█         | 282/2628 [08:53<1:10:48,  1.81s/it] 11%|█         | 283/2628 [08:55<1:10:38,  1.81s/it] 11%|█         | 284/2628 [08:57<1:10:43,  1.81s/it] 11%|█         | 285/2628 [08:59<1:10:31,  1.81s/it] 11%|█         | 286/2628 [09:01<1:10:35,  1.81s/it] 11%|█         | 287/2628 [09:02<1:10:26,  1.81s/it] 11%|█         | 288/2628 [09:04<1:10:30,  1.81s/it] 11%|█         | 289/2628 [09:06<1:10:37,  1.81s/it] 11%|█         | 290/2628 [09:08<1:10:30,  1.81s/it]                                                     11%|█         | 290/2628 [09:08<1:10:30,  1.81s/it] 11%|█         | 291/2628 [09:10<1:10:33,  1.81s/it] 11%|█         | 292/2628 [09:11<1:10:19,  1.81s/it] 11%|█         | 293/2628 [09:13<1:10:28,  1.81s/it] 11%|█         | 294/2628 [09:15<1:10:18,  1.81s/it] 11%|█         | 295/2628 [09:17<1:10:14,  1.81s/it] 11%|█▏        | 296/2628 [09:19<1:10:18,  1.81s/it] 11%|█▏        | 297/2628 [09:20<1:10:09,  1.81s/it] 11%|█▏        | 298/2628 [09:22<1:10:02,  1.80s/it] 11%|█▏        | 299/2628 [09:24<1:10:12,  1.81s/it] 11%|█▏        | 300/2628 [09:26<1:10:06,  1.81s/it]                                                     11%|█▏        | 300/2628 [09:26<1:10:06,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 17:05:51,168 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 17:05:51,168 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 17:05:51,168 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:05:51,685 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:06:50,003 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:58<00:29, 29.12s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:07:48,305 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [01:56<00:00, 41.31s/it][A                                                    
                                             [A 11%|█▏        | 300/2628 [12:22<1:10:06,  1.81s/it]
100%|██████████| 3/3 [01:56<00:00, 41.31s/it][A
                                             [A 11%|█▏        | 301/2628 [12:23<35:15:45, 54.55s/it] 11%|█▏        | 302/2628 [12:25<25:01:21, 38.73s/it] 12%|█▏        | 303/2628 [12:27<17:51:29, 27.65s/it] 12%|█▏        | 304/2628 [12:29<12:50:46, 19.90s/it] 12%|█▏        | 305/2628 [12:31<9:20:14, 14.47s/it]  12%|█▏        | 306/2628 [12:32<6:52:54, 10.67s/it] 12%|█▏        | 307/2628 [12:34<5:09:45,  8.01s/it] 12%|█▏        | 308/2628 [12:36<3:57:35,  6.14s/it] 12%|█▏        | 309/2628 [12:38<3:07:12,  4.84s/it] 12%|█▏        | 310/2628 [12:40<2:31:50,  3.93s/it]                                                     12%|█▏        | 310/2628 [12:40<2:31:50,  3.93s/it] 12%|█▏        | 311/2628 [12:41<2:07:16,  3.30s/it] 12%|█▏        | 312/2628 [12:43<1:49:51,  2.85s/it] 12%|█▏        | 313/2628 [12:45<1:37:43,  2.53s/it] 12%|█▏        | 314/2628 [12:47<1:29:11,  2.31s/it] 12%|█▏        | 315/2628 [12:49<1:23:10,  2.16s/it] 12%|█▏        | 316/2628 [12:51<1:19:08,  2.05s/it] 12%|█▏        | 317/2628 [12:52<1:16:11,  1.98s/it] 12%|█▏        | 318/2628 [12:54<1:14:14,  1.93s/it] 12%|█▏        | 319/2628 [12:56<1:12:44,  1.89s/it] 12%|█▏        | 320/2628 [12:58<1:11:40,  1.86s/it]                                                     12%|█▏        | 320/2628 [12:58<1:11:40,  1.86s/it] 12%|█▏        | 321/2628 [13:00<1:11:02,  1.85s/it] 12%|█▏        | 322/2628 [13:01<1:10:25,  1.83s/it] 12%|█▏        | 323/2628 [13:03<1:09:58,  1.82s/it] 12%|█▏        | 324/2628 [13:05<1:09:42,  1.82s/it] 12%|█▏        | 325/2628 [13:07<1:09:28,  1.81s/it] 12%|█▏        | 326/2628 [13:09<1:09:31,  1.81s/it] 12%|█▏        | 327/2628 [13:10<1:09:27,  1.81s/it] 12%|█▏        | 328/2628 [13:12<1:09:15,  1.81s/it] 13%|█▎        | 329/2628 [13:14<1:09:04,  1.80s/it] 13%|█▎        | 330/2628 [13:16<1:08:59,  1.80s/it]                                                     13%|█▎        | 330/2628 [13:16<1:08:59,  1.80s/it] 13%|█▎        | 331/2628 [13:18<1:08:59,  1.80s/it] 13%|█▎        | 332/2628 [13:19<1:08:55,  1.80s/it] 13%|█▎        | 333/2628 [13:21<1:09:01,  1.80s/it] 13%|█▎        | 334/2628 [13:23<1:09:06,  1.81s/it] 13%|█▎        | 335/2628 [13:25<1:08:59,  1.81s/it] 13%|█▎        | 336/2628 [13:27<1:09:04,  1.81s/it] 13%|█▎        | 337/2628 [13:28<1:09:05,  1.81s/it] 13%|█▎        | 338/2628 [13:30<1:08:56,  1.81s/it] 13%|█▎        | 339/2628 [13:32<1:08:47,  1.80s/it] 13%|█▎        | 340/2628 [13:34<1:08:42,  1.80s/it]                                                     13%|█▎        | 340/2628 [13:34<1:08:42,  1.80s/it] 13%|█▎        | 341/2628 [13:36<1:08:49,  1.81s/it] 13%|█▎        | 342/2628 [13:37<1:08:42,  1.80s/it] 13%|█▎        | 343/2628 [13:39<1:08:48,  1.81s/it] 13%|█▎        | 344/2628 [13:41<1:08:38,  1.80s/it] 13%|█▎        | 345/2628 [13:43<1:08:33,  1.80s/it] 13%|█▎        | 346/2628 [13:45<1:08:25,  1.80s/it] 13%|█▎        | 347/2628 [13:46<1:08:21,  1.80s/it] 13%|█▎        | 348/2628 [13:48<1:08:30,  1.80s/it] 13%|█▎        | 349/2628 [13:50<1:08:25,  1.80s/it] 13%|█▎        | 350/2628 [13:52<1:08:19,  1.80s/it]                                                     13%|█▎        | 350/2628 [13:52<1:08:19,  1.80s/it] 13%|█▎        | 351/2628 [13:54<1:08:25,  1.80s/it] 13%|█▎        | 352/2628 [13:55<1:08:18,  1.80s/it] 13%|█▎        | 353/2628 [13:57<1:08:13,  1.80s/it] 13%|█▎        | 354/2628 [13:59<1:08:12,  1.80s/it] 14%|█▎        | 355/2628 [14:01<1:08:12,  1.80s/it] 14%|█▎        | 356/2628 [14:03<1:08:07,  1.80s/it] 14%|█▎        | 357/2628 [14:04<1:08:19,  1.81s/it] 14%|█▎        | 358/2628 [14:06<1:08:12,  1.80s/it] 14%|█▎        | 359/2628 [14:08<1:08:09,  1.80s/it] 14%|█▎        | 360/2628 [14:10<1:08:05,  1.80s/it]                                                     14%|█▎        | 360/2628 [14:10<1:08:05,  1.80s/it] 14%|█▎        | 361/2628 [14:12<1:08:03,  1.80s/it] 14%|█▍        | 362/2628 [14:13<1:08:10,  1.81s/it] 14%|█▍        | 363/2628 [14:15<1:08:15,  1.81s/it] 14%|█▍        | 364/2628 [14:17<1:08:18,  1.81s/it] 14%|█▍        | 365/2628 [14:19<1:08:12,  1.81s/it] 14%|█▍        | 366/2628 [14:21<1:08:01,  1.80s/it] 14%|█▍        | 367/2628 [14:22<1:08:08,  1.81s/it] 14%|█▍        | 368/2628 [14:24<1:08:01,  1.81s/it] 14%|█▍        | 369/2628 [14:26<1:07:56,  1.80s/it] 14%|█▍        | 370/2628 [14:28<1:07:52,  1.80s/it]                                                     14%|█▍        | 370/2628 [14:28<1:07:52,  1.80s/it] 14%|█▍        | 371/2628 [14:30<1:07:53,  1.80s/it] 14%|█▍        | 372/2628 [14:32<1:07:53,  1.81s/it] 14%|█▍        | 373/2628 [14:33<1:07:59,  1.81s/it] 14%|█▍        | 374/2628 [14:35<1:07:58,  1.81s/it] 14%|█▍        | 375/2628 [14:37<1:07:56,  1.81s/it] 14%|█▍        | 376/2628 [14:39<1:07:55,  1.81s/it] 14%|█▍        | 377/2628 [14:41<1:07:42,  1.80s/it] 14%|█▍        | 378/2628 [14:42<1:07:47,  1.81s/it] 14%|█▍        | 379/2628 [14:44<1:07:46,  1.81s/it] 14%|█▍        | 380/2628 [14:46<1:07:39,  1.81s/it]                                                     14%|█▍        | 380/2628 [14:46<1:07:39,  1.81s/it] 14%|█▍        | 381/2628 [14:48<1:07:32,  1.80s/it] 15%|█▍        | 382/2628 [14:50<1:07:27,  1.80s/it] 15%|█▍        | 383/2628 [14:51<1:07:23,  1.80s/it] 15%|█▍        | 384/2628 [14:53<1:07:23,  1.80s/it] 15%|█▍        | 385/2628 [14:55<1:07:20,  1.80s/it] 15%|█▍        | 386/2628 [14:57<1:07:19,  1.80s/it] 15%|█▍        | 387/2628 [14:59<1:07:24,  1.80s/it] 15%|█▍        | 388/2628 [15:00<1:07:22,  1.80s/it] 15%|█▍        | 389/2628 [15:02<1:07:16,  1.80s/it] 15%|█▍        | 390/2628 [15:04<1:07:15,  1.80s/it]                                                     15%|█▍        | 390/2628 [15:04<1:07:15,  1.80s/it] 15%|█▍        | 391/2628 [15:06<1:07:09,  1.80s/it] 15%|█▍        | 392/2628 [15:08<1:07:15,  1.80s/it] 15%|█▍        | 393/2628 [15:09<1:07:23,  1.81s/it] 15%|█▍        | 394/2628 [15:11<1:07:17,  1.81s/it] 15%|█▌        | 395/2628 [15:13<1:07:10,  1.81s/it] 15%|█▌        | 396/2628 [15:15<1:07:05,  1.80s/it] 15%|█▌        | 397/2628 [15:17<1:06:58,  1.80s/it] 15%|█▌        | 398/2628 [15:18<1:06:56,  1.80s/it] 15%|█▌        | 399/2628 [15:20<1:07:07,  1.81s/it] 15%|█▌        | 400/2628 [15:22<1:07:07,  1.81s/it]                                                     15%|█▌        | 400/2628 [15:22<1:07:07,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 17:11:47,381 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 17:11:47,381 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 17:11:47,381 >>   Batch size = 8
[WARNING|utils.py:2443] 2025-10-21 17:11:47,854 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:11:50,202 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:02<00:01,  1.12s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:11:52,513 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:04<00:00,  1.62s/it][A                                                    
                                             [A 15%|█▌        | 400/2628 [15:30<1:07:07,  1.81s/it]
100%|██████████| 3/3 [00:04<00:00,  1.62s/it][A
                                             [A 15%|█▌        | 401/2628 [15:31<2:31:14,  4.07s/it] 15%|█▌        | 402/2628 [15:33<2:05:51,  3.39s/it] 15%|█▌        | 403/2628 [15:35<1:48:18,  2.92s/it] 15%|█▌        | 404/2628 [15:37<1:35:55,  2.59s/it] 15%|█▌        | 405/2628 [15:39<1:27:12,  2.35s/it] 15%|█▌        | 406/2628 [15:40<1:21:11,  2.19s/it] 15%|█▌        | 407/2628 [15:42<1:16:57,  2.08s/it] 16%|█▌        | 408/2628 [15:44<1:13:51,  2.00s/it] 16%|█▌        | 409/2628 [15:46<1:11:39,  1.94s/it] 16%|█▌        | 410/2628 [15:48<1:10:07,  1.90s/it]                                                     16%|█▌        | 410/2628 [15:48<1:10:07,  1.90s/it] 16%|█▌        | 411/2628 [15:49<1:09:01,  1.87s/it] 16%|█▌        | 412/2628 [15:51<1:08:21,  1.85s/it] 16%|█▌        | 413/2628 [15:53<1:07:54,  1.84s/it] 16%|█▌        | 414/2628 [15:55<1:07:23,  1.83s/it] 16%|█▌        | 415/2628 [15:57<1:07:04,  1.82s/it] 16%|█▌        | 416/2628 [15:59<1:07:04,  1.82s/it] 16%|█▌        | 417/2628 [16:00<1:06:52,  1.81s/it] 16%|█▌        | 418/2628 [16:02<1:06:49,  1.81s/it] 16%|█▌        | 419/2628 [16:04<1:06:38,  1.81s/it] 16%|█▌        | 420/2628 [16:06<1:06:26,  1.81s/it]                                                     16%|█▌        | 420/2628 [16:06<1:06:26,  1.81s/it] 16%|█▌        | 421/2628 [16:08<1:06:20,  1.80s/it] 16%|█▌        | 422/2628 [16:09<1:06:13,  1.80s/it] 16%|█▌        | 423/2628 [16:11<1:06:07,  1.80s/it] 16%|█▌        | 424/2628 [16:13<1:06:20,  1.81s/it] 16%|█▌        | 425/2628 [16:15<1:06:15,  1.80s/it] 16%|█▌        | 426/2628 [16:17<1:06:12,  1.80s/it] 16%|█▌        | 427/2628 [16:18<1:06:07,  1.80s/it] 16%|█▋        | 428/2628 [16:20<1:06:01,  1.80s/it] 16%|█▋        | 429/2628 [16:22<1:06:04,  1.80s/it] 16%|█▋        | 430/2628 [16:24<1:06:00,  1.80s/it]                                                     16%|█▋        | 430/2628 [16:24<1:06:00,  1.80s/it] 16%|█▋        | 431/2628 [16:26<1:05:55,  1.80s/it] 16%|█▋        | 432/2628 [16:27<1:05:59,  1.80s/it] 16%|█▋        | 433/2628 [16:29<1:05:53,  1.80s/it] 17%|█▋        | 434/2628 [16:31<1:05:58,  1.80s/it] 17%|█▋        | 435/2628 [16:33<1:06:05,  1.81s/it] 17%|█▋        | 436/2628 [16:35<1:06:04,  1.81s/it] 17%|█▋        | 437/2628 [16:36<1:05:53,  1.80s/it] 17%|█▋        | 438/2628 [16:38<1:05:50,  1.80s/it] 17%|█▋        | 439/2628 [16:40<1:05:53,  1.81s/it] 17%|█▋        | 440/2628 [16:42<1:05:55,  1.81s/it]                                                     17%|█▋        | 440/2628 [16:42<1:05:55,  1.81s/it] 17%|█▋        | 441/2628 [16:44<1:05:53,  1.81s/it] 17%|█▋        | 442/2628 [16:45<1:05:54,  1.81s/it] 17%|█▋        | 443/2628 [16:47<1:05:48,  1.81s/it] 17%|█▋        | 444/2628 [16:49<1:05:41,  1.80s/it] 17%|█▋        | 445/2628 [16:51<1:05:42,  1.81s/it] 17%|█▋        | 446/2628 [16:53<1:05:47,  1.81s/it] 17%|█▋        | 447/2628 [16:54<1:05:44,  1.81s/it] 17%|█▋        | 448/2628 [16:56<1:05:35,  1.81s/it] 17%|█▋        | 449/2628 [16:58<1:05:29,  1.80s/it] 17%|█▋        | 450/2628 [17:00<1:05:23,  1.80s/it]                                                     17%|█▋        | 450/2628 [17:00<1:05:23,  1.80s/it] 17%|█▋        | 451/2628 [17:02<1:05:24,  1.80s/it] 17%|█▋        | 452/2628 [17:03<1:05:20,  1.80s/it] 17%|█▋        | 453/2628 [17:05<1:05:18,  1.80s/it] 17%|█▋        | 454/2628 [17:07<1:05:16,  1.80s/it] 17%|█▋        | 455/2628 [17:09<1:05:14,  1.80s/it] 17%|█▋        | 456/2628 [17:11<1:05:10,  1.80s/it] 17%|█▋        | 457/2628 [17:12<1:05:20,  1.81s/it] 17%|█▋        | 458/2628 [17:14<1:05:16,  1.80s/it] 17%|█▋        | 459/2628 [17:16<1:05:13,  1.80s/it] 18%|█▊        | 460/2628 [17:18<1:05:21,  1.81s/it]                                                     18%|█▊        | 460/2628 [17:18<1:05:21,  1.81s/it] 18%|█▊        | 461/2628 [17:20<1:05:15,  1.81s/it] 18%|█▊        | 462/2628 [17:22<1:05:07,  1.80s/it] 18%|█▊        | 463/2628 [17:23<1:05:13,  1.81s/it] 18%|█▊        | 464/2628 [17:25<1:05:15,  1.81s/it] 18%|█▊        | 465/2628 [17:27<1:05:03,  1.80s/it] 18%|█▊        | 466/2628 [17:29<1:04:56,  1.80s/it] 18%|█▊        | 467/2628 [17:31<1:04:55,  1.80s/it] 18%|█▊        | 468/2628 [17:32<1:04:58,  1.80s/it] 18%|█▊        | 469/2628 [17:34<1:04:58,  1.81s/it] 18%|█▊        | 470/2628 [17:36<1:04:53,  1.80s/it]                                                     18%|█▊        | 470/2628 [17:36<1:04:53,  1.80s/it] 18%|█▊        | 471/2628 [17:38<1:04:49,  1.80s/it] 18%|█▊        | 472/2628 [17:40<1:04:47,  1.80s/it] 18%|█▊        | 473/2628 [17:41<1:04:47,  1.80s/it] 18%|█▊        | 474/2628 [17:43<1:04:41,  1.80s/it] 18%|█▊        | 475/2628 [17:45<1:04:48,  1.81s/it] 18%|█▊        | 476/2628 [17:47<1:04:44,  1.80s/it] 18%|█▊        | 477/2628 [17:49<1:04:49,  1.81s/it] 18%|█▊        | 478/2628 [17:50<1:04:41,  1.81s/it] 18%|█▊        | 479/2628 [17:52<1:04:37,  1.80s/it] 18%|█▊        | 480/2628 [17:54<1:04:41,  1.81s/it]                                                     18%|█▊        | 480/2628 [17:54<1:04:41,  1.81s/it] 18%|█▊        | 481/2628 [17:56<1:04:35,  1.80s/it] 18%|█▊        | 482/2628 [17:58<1:04:30,  1.80s/it] 18%|█▊        | 483/2628 [17:59<1:04:35,  1.81s/it] 18%|█▊        | 484/2628 [18:01<1:04:29,  1.80s/it] 18%|█▊        | 485/2628 [18:03<1:04:24,  1.80s/it] 18%|█▊        | 486/2628 [18:05<1:04:21,  1.80s/it] 19%|█▊        | 487/2628 [18:07<1:04:19,  1.80s/it] 19%|█▊        | 488/2628 [18:08<1:04:20,  1.80s/it] 19%|█▊        | 489/2628 [18:10<1:04:18,  1.80s/it] 19%|█▊        | 490/2628 [18:12<1:04:23,  1.81s/it]                                                     19%|█▊        | 490/2628 [18:12<1:04:23,  1.81s/it] 19%|█▊        | 491/2628 [18:14<1:04:15,  1.80s/it] 19%|█▊        | 492/2628 [18:16<1:04:10,  1.80s/it] 19%|█▉        | 493/2628 [18:17<1:04:04,  1.80s/it] 19%|█▉        | 494/2628 [18:19<1:04:01,  1.80s/it] 19%|█▉        | 495/2628 [18:21<1:03:58,  1.80s/it] 19%|█▉        | 496/2628 [18:23<1:04:04,  1.80s/it] 19%|█▉        | 497/2628 [18:25<1:04:13,  1.81s/it] 19%|█▉        | 498/2628 [18:26<1:04:15,  1.81s/it] 19%|█▉        | 499/2628 [18:28<1:04:04,  1.81s/it] 19%|█▉        | 500/2628 [18:30<1:03:56,  1.80s/it]                                                     19%|█▉        | 500/2628 [18:30<1:03:56,  1.80s/it][INFO|trainer.py:4643] 2025-10-21 17:14:55,425 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 17:14:55,425 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 17:14:55,425 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:14:55,918 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:15:52,798 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:58<00:29, 29.17s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:16:51,217 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [01:56<00:00, 41.23s/it][A                                                    
                                             [A 19%|█▉        | 500/2628 [21:24<1:03:56,  1.80s/it]
100%|██████████| 3/3 [01:56<00:00, 41.23s/it][A
                                             [A/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/eval/evaluators.py:207: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
  boxes = torch.tensor(box_list) if box_list else torch.empty((0, 4))
/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/eval/evaluators.py:207: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
  boxes = torch.tensor(box_list) if box_list else torch.empty((0, 4))
/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/eval/evaluators.py:207: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
  boxes = torch.tensor(box_list) if box_list else torch.empty((0, 4))
/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/eval/evaluators.py:207: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
  boxes = torch.tensor(box_list) if box_list else torch.empty((0, 4))
 19%|█▉        | 501/2628 [21:26<31:55:16, 54.03s/it] 19%|█▉        | 502/2628 [21:28<22:39:13, 38.36s/it] 19%|█▉        | 503/2628 [21:30<16:10:17, 27.40s/it] 19%|█▉        | 504/2628 [21:31<11:38:06, 19.72s/it] 19%|█▉        | 505/2628 [21:33<8:27:29, 14.34s/it]  19%|█▉        | 506/2628 [21:35<6:14:15, 10.58s/it] 19%|█▉        | 507/2628 [21:37<4:40:55,  7.95s/it] 19%|█▉        | 508/2628 [21:39<3:35:36,  6.10s/it] 19%|█▉        | 509/2628 [21:40<2:49:52,  4.81s/it] 19%|█▉        | 510/2628 [21:42<2:17:59,  3.91s/it]                                                     19%|█▉        | 510/2628 [21:42<2:17:59,  3.91s/it] 19%|█▉        | 511/2628 [21:44<1:55:41,  3.28s/it] 19%|█▉        | 512/2628 [21:46<1:39:59,  2.84s/it] 20%|█▉        | 513/2628 [21:48<1:29:01,  2.53s/it] 20%|█▉        | 514/2628 [21:49<1:21:17,  2.31s/it] 20%|█▉        | 515/2628 [21:51<1:15:53,  2.15s/it] 20%|█▉        | 516/2628 [21:53<1:12:05,  2.05s/it] 20%|█▉        | 517/2628 [21:55<1:09:27,  1.97s/it] 20%|█▉        | 518/2628 [21:57<1:07:34,  1.92s/it] 20%|█▉        | 519/2628 [21:58<1:06:14,  1.88s/it] 20%|█▉        | 520/2628 [22:00<1:05:26,  1.86s/it]                                                     20%|█▉        | 520/2628 [22:00<1:05:26,  1.86s/it] 20%|█▉        | 521/2628 [22:02<1:04:44,  1.84s/it] 20%|█▉        | 522/2628 [22:04<1:04:20,  1.83s/it] 20%|█▉        | 523/2628 [22:06<1:03:57,  1.82s/it] 20%|█▉        | 524/2628 [22:07<1:03:46,  1.82s/it] 20%|█▉        | 525/2628 [22:09<1:03:31,  1.81s/it] 20%|██        | 526/2628 [22:11<1:03:21,  1.81s/it] 20%|██        | 527/2628 [22:13<1:03:14,  1.81s/it] 20%|██        | 528/2628 [22:15<1:03:09,  1.80s/it] 20%|██        | 529/2628 [22:16<1:03:02,  1.80s/it] 20%|██        | 530/2628 [22:18<1:03:00,  1.80s/it]                                                     20%|██        | 530/2628 [22:18<1:03:00,  1.80s/it] 20%|██        | 531/2628 [22:20<1:02:58,  1.80s/it] 20%|██        | 532/2628 [22:22<1:03:01,  1.80s/it] 20%|██        | 533/2628 [22:24<1:03:00,  1.80s/it] 20%|██        | 534/2628 [22:25<1:02:55,  1.80s/it] 20%|██        | 535/2628 [22:27<1:02:52,  1.80s/it] 20%|██        | 536/2628 [22:29<1:02:49,  1.80s/it] 20%|██        | 537/2628 [22:31<1:02:47,  1.80s/it] 20%|██        | 538/2628 [22:33<1:02:52,  1.81s/it] 21%|██        | 539/2628 [22:34<1:02:45,  1.80s/it] 21%|██        | 540/2628 [22:36<1:02:47,  1.80s/it]                                                     21%|██        | 540/2628 [22:36<1:02:47,  1.80s/it] 21%|██        | 541/2628 [22:38<1:02:44,  1.80s/it] 21%|██        | 542/2628 [22:40<1:02:49,  1.81s/it] 21%|██        | 543/2628 [22:42<1:02:42,  1.80s/it] 21%|██        | 544/2628 [22:43<1:02:47,  1.81s/it] 21%|██        | 545/2628 [22:45<1:02:40,  1.81s/it] 21%|██        | 546/2628 [22:47<1:02:46,  1.81s/it] 21%|██        | 547/2628 [22:49<1:02:38,  1.81s/it] 21%|██        | 548/2628 [22:51<1:02:34,  1.81s/it] 21%|██        | 549/2628 [22:53<1:02:37,  1.81s/it] 21%|██        | 550/2628 [22:54<1:02:42,  1.81s/it]                                                     21%|██        | 550/2628 [22:54<1:02:42,  1.81s/it] 21%|██        | 551/2628 [22:56<1:02:41,  1.81s/it] 21%|██        | 552/2628 [22:58<1:02:43,  1.81s/it] 21%|██        | 553/2628 [23:00<1:02:41,  1.81s/it] 21%|██        | 554/2628 [23:02<1:02:39,  1.81s/it] 21%|██        | 555/2628 [23:03<1:02:38,  1.81s/it] 21%|██        | 556/2628 [23:05<1:02:26,  1.81s/it] 21%|██        | 557/2628 [23:07<1:02:17,  1.80s/it] 21%|██        | 558/2628 [23:09<1:02:12,  1.80s/it] 21%|██▏       | 559/2628 [23:11<1:02:08,  1.80s/it] 21%|██▏       | 560/2628 [23:12<1:02:04,  1.80s/it]                                                     21%|██▏       | 560/2628 [23:12<1:02:04,  1.80s/it] 21%|██▏       | 561/2628 [23:14<1:02:03,  1.80s/it] 21%|██▏       | 562/2628 [23:16<1:01:58,  1.80s/it] 21%|██▏       | 563/2628 [23:18<1:02:06,  1.80s/it] 21%|██▏       | 564/2628 [23:20<1:02:01,  1.80s/it] 21%|██▏       | 565/2628 [23:21<1:01:57,  1.80s/it] 22%|██▏       | 566/2628 [23:23<1:01:52,  1.80s/it] 22%|██▏       | 567/2628 [23:25<1:01:55,  1.80s/it] 22%|██▏       | 568/2628 [23:27<1:01:55,  1.80s/it] 22%|██▏       | 569/2628 [23:29<1:01:51,  1.80s/it] 22%|██▏       | 570/2628 [23:30<1:01:47,  1.80s/it]                                                     22%|██▏       | 570/2628 [23:30<1:01:47,  1.80s/it] 22%|██▏       | 571/2628 [23:32<1:01:46,  1.80s/it] 22%|██▏       | 572/2628 [23:34<1:01:42,  1.80s/it] 22%|██▏       | 573/2628 [23:36<1:01:39,  1.80s/it] 22%|██▏       | 574/2628 [23:38<1:01:47,  1.81s/it] 22%|██▏       | 575/2628 [23:39<1:01:41,  1.80s/it] 22%|██▏       | 576/2628 [23:41<1:01:44,  1.81s/it] 22%|██▏       | 577/2628 [23:43<1:01:48,  1.81s/it] 22%|██▏       | 578/2628 [23:45<1:01:41,  1.81s/it] 22%|██▏       | 579/2628 [23:47<1:01:36,  1.80s/it] 22%|██▏       | 580/2628 [23:48<1:01:44,  1.81s/it]                                                     22%|██▏       | 580/2628 [23:48<1:01:44,  1.81s/it] 22%|██▏       | 581/2628 [23:50<1:01:36,  1.81s/it] 22%|██▏       | 582/2628 [23:52<1:01:29,  1.80s/it] 22%|██▏       | 583/2628 [23:54<1:01:22,  1.80s/it] 22%|██▏       | 584/2628 [23:56<1:01:19,  1.80s/it] 22%|██▏       | 585/2628 [23:57<1:01:28,  1.81s/it] 22%|██▏       | 586/2628 [23:59<1:01:26,  1.81s/it] 22%|██▏       | 587/2628 [24:01<1:01:19,  1.80s/it] 22%|██▏       | 588/2628 [24:03<1:01:16,  1.80s/it] 22%|██▏       | 589/2628 [24:05<1:01:12,  1.80s/it] 22%|██▏       | 590/2628 [24:06<1:01:09,  1.80s/it]                                                     22%|██▏       | 590/2628 [24:06<1:01:09,  1.80s/it] 22%|██▏       | 591/2628 [24:08<1:01:06,  1.80s/it] 23%|██▎       | 592/2628 [24:10<1:01:04,  1.80s/it] 23%|██▎       | 593/2628 [24:12<1:01:02,  1.80s/it] 23%|██▎       | 594/2628 [24:14<1:01:01,  1.80s/it] 23%|██▎       | 595/2628 [24:15<1:00:59,  1.80s/it] 23%|██▎       | 596/2628 [24:17<1:00:58,  1.80s/it] 23%|██▎       | 597/2628 [24:19<1:01:03,  1.80s/it] 23%|██▎       | 598/2628 [24:21<1:00:58,  1.80s/it] 23%|██▎       | 599/2628 [24:23<1:01:03,  1.81s/it] 23%|██▎       | 600/2628 [24:25<1:00:54,  1.80s/it]                                                     23%|██▎       | 600/2628 [24:25<1:00:54,  1.80s/it][INFO|trainer.py:4643] 2025-10-21 17:20:49,852 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 17:20:49,852 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 17:20:49,852 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:20:50,327 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:21:48,316 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:55<00:27, 27.98s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:22:44,345 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [01:54<00:00, 40.55s/it][A                                                    
                                             [A 23%|██▎       | 600/2628 [27:17<1:00:54,  1.80s/it]
100%|██████████| 3/3 [01:54<00:00, 40.55s/it][A
                                             [A 23%|██▎       | 601/2628 [27:19<30:13:26, 53.68s/it] 23%|██▎       | 602/2628 [27:21<21:27:05, 38.12s/it] 23%|██▎       | 603/2628 [27:23<15:18:41, 27.22s/it] 23%|██▎       | 604/2628 [27:25<11:00:59, 19.59s/it] 23%|██▎       | 605/2628 [27:26<8:00:38, 14.26s/it]  23%|██▎       | 606/2628 [27:28<5:54:38, 10.52s/it] 23%|██▎       | 607/2628 [27:30<4:26:23,  7.91s/it] 23%|██▎       | 608/2628 [27:32<3:24:31,  6.07s/it] 23%|██▎       | 609/2628 [27:34<2:41:13,  4.79s/it] 23%|██▎       | 610/2628 [27:35<2:10:55,  3.89s/it]                                                     23%|██▎       | 610/2628 [27:35<2:10:55,  3.89s/it] 23%|██▎       | 611/2628 [27:37<1:49:45,  3.27s/it] 23%|██▎       | 612/2628 [27:39<1:35:03,  2.83s/it] 23%|██▎       | 613/2628 [27:41<1:24:37,  2.52s/it] 23%|██▎       | 614/2628 [27:43<1:17:26,  2.31s/it] 23%|██▎       | 615/2628 [27:44<1:12:16,  2.15s/it] 23%|██▎       | 616/2628 [27:46<1:08:41,  2.05s/it] 23%|██▎       | 617/2628 [27:48<1:06:08,  1.97s/it] 24%|██▎       | 618/2628 [27:50<1:04:29,  1.92s/it] 24%|██▎       | 619/2628 [27:52<1:03:10,  1.89s/it] 24%|██▎       | 620/2628 [27:53<1:02:15,  1.86s/it]                                                     24%|██▎       | 620/2628 [27:53<1:02:15,  1.86s/it] 24%|██▎       | 621/2628 [27:55<1:01:36,  1.84s/it] 24%|██▎       | 622/2628 [27:57<1:01:17,  1.83s/it] 24%|██▎       | 623/2628 [27:59<1:00:55,  1.82s/it] 24%|██▎       | 624/2628 [28:01<1:00:36,  1.81s/it] 24%|██▍       | 625/2628 [28:03<1:00:38,  1.82s/it] 24%|██▍       | 626/2628 [28:04<1:00:25,  1.81s/it] 24%|██▍       | 627/2628 [28:06<1:00:13,  1.81s/it] 24%|██▍       | 628/2628 [28:08<1:00:15,  1.81s/it] 24%|██▍       | 629/2628 [28:10<1:00:17,  1.81s/it] 24%|██▍       | 630/2628 [28:12<1:00:10,  1.81s/it]                                                     24%|██▍       | 630/2628 [28:12<1:00:10,  1.81s/it] 24%|██▍       | 631/2628 [28:13<1:00:04,  1.80s/it] 24%|██▍       | 632/2628 [28:15<59:58,  1.80s/it]   24%|██▍       | 633/2628 [28:17<1:00:00,  1.80s/it] 24%|██▍       | 634/2628 [28:19<59:55,  1.80s/it]   24%|██▍       | 635/2628 [28:21<59:50,  1.80s/it] 24%|██▍       | 636/2628 [28:22<59:47,  1.80s/it] 24%|██▍       | 637/2628 [28:24<59:45,  1.80s/it] 24%|██▍       | 638/2628 [28:26<59:50,  1.80s/it] 24%|██▍       | 639/2628 [28:28<59:53,  1.81s/it] 24%|██▍       | 640/2628 [28:30<59:58,  1.81s/it]                                                   24%|██▍       | 640/2628 [28:30<59:58,  1.81s/it] 24%|██▍       | 641/2628 [28:31<59:52,  1.81s/it] 24%|██▍       | 642/2628 [28:33<59:54,  1.81s/it] 24%|██▍       | 643/2628 [28:35<59:49,  1.81s/it] 25%|██▍       | 644/2628 [28:37<59:44,  1.81s/it] 25%|██▍       | 645/2628 [28:39<59:39,  1.81s/it] 25%|██▍       | 646/2628 [28:40<59:34,  1.80s/it] 25%|██▍       | 647/2628 [28:42<59:39,  1.81s/it] 25%|██▍       | 648/2628 [28:44<59:33,  1.80s/it] 25%|██▍       | 649/2628 [28:46<59:35,  1.81s/it] 25%|██▍       | 650/2628 [28:48<59:37,  1.81s/it]                                                   25%|██▍       | 650/2628 [28:48<59:37,  1.81s/it] 25%|██▍       | 651/2628 [28:49<59:31,  1.81s/it] 25%|██▍       | 652/2628 [28:51<59:27,  1.81s/it] 25%|██▍       | 653/2628 [28:53<59:33,  1.81s/it] 25%|██▍       | 654/2628 [28:55<59:25,  1.81s/it] 25%|██▍       | 655/2628 [28:57<59:29,  1.81s/it] 25%|██▍       | 656/2628 [28:58<59:20,  1.81s/it] 25%|██▌       | 657/2628 [29:00<59:21,  1.81s/it] 25%|██▌       | 658/2628 [29:02<59:13,  1.80s/it] 25%|██▌       | 659/2628 [29:04<59:15,  1.81s/it] 25%|██▌       | 660/2628 [29:06<59:14,  1.81s/it]                                                   25%|██▌       | 660/2628 [29:06<59:14,  1.81s/it] 25%|██▌       | 661/2628 [29:07<59:08,  1.80s/it] 25%|██▌       | 662/2628 [29:09<59:06,  1.80s/it] 25%|██▌       | 663/2628 [29:11<59:07,  1.81s/it] 25%|██▌       | 664/2628 [29:13<59:03,  1.80s/it] 25%|██▌       | 665/2628 [29:15<58:58,  1.80s/it] 25%|██▌       | 666/2628 [29:17<58:53,  1.80s/it] 25%|██▌       | 667/2628 [29:18<58:49,  1.80s/it] 25%|██▌       | 668/2628 [29:20<58:50,  1.80s/it] 25%|██▌       | 669/2628 [29:22<58:48,  1.80s/it] 25%|██▌       | 670/2628 [29:24<58:46,  1.80s/it]                                                   25%|██▌       | 670/2628 [29:24<58:46,  1.80s/it] 26%|██▌       | 671/2628 [29:26<58:44,  1.80s/it] 26%|██▌       | 672/2628 [29:27<58:42,  1.80s/it] 26%|██▌       | 673/2628 [29:29<58:49,  1.81s/it] 26%|██▌       | 674/2628 [29:31<1:02:19,  1.91s/it] 26%|██▌       | 675/2628 [29:33<1:01:08,  1.88s/it] 26%|██▌       | 676/2628 [29:35<1:00:20,  1.85s/it] 26%|██▌       | 677/2628 [29:37<59:45,  1.84s/it]   26%|██▌       | 678/2628 [29:38<59:22,  1.83s/it] 26%|██▌       | 679/2628 [29:40<59:06,  1.82s/it] 26%|██▌       | 680/2628 [29:42<59:00,  1.82s/it]                                                   26%|██▌       | 680/2628 [29:42<59:00,  1.82s/it] 26%|██▌       | 681/2628 [29:44<58:57,  1.82s/it] 26%|██▌       | 682/2628 [29:46<58:48,  1.81s/it] 26%|██▌       | 683/2628 [29:48<58:47,  1.81s/it] 26%|██▌       | 684/2628 [29:49<58:39,  1.81s/it] 26%|██▌       | 685/2628 [29:51<58:38,  1.81s/it] 26%|██▌       | 686/2628 [29:53<58:30,  1.81s/it] 26%|██▌       | 687/2628 [29:55<58:25,  1.81s/it] 26%|██▌       | 688/2628 [29:57<58:22,  1.81s/it] 26%|██▌       | 689/2628 [29:58<58:28,  1.81s/it] 26%|██▋       | 690/2628 [30:00<58:29,  1.81s/it]                                                   26%|██▋       | 690/2628 [30:00<58:29,  1.81s/it] 26%|██▋       | 691/2628 [30:02<58:27,  1.81s/it] 26%|██▋       | 692/2628 [30:04<58:20,  1.81s/it] 26%|██▋       | 693/2628 [30:06<58:22,  1.81s/it] 26%|██▋       | 694/2628 [30:07<58:17,  1.81s/it] 26%|██▋       | 695/2628 [30:09<58:11,  1.81s/it] 26%|██▋       | 696/2628 [30:11<58:05,  1.80s/it] 27%|██▋       | 697/2628 [30:13<58:07,  1.81s/it] 27%|██▋       | 698/2628 [30:15<58:14,  1.81s/it] 27%|██▋       | 699/2628 [30:16<58:05,  1.81s/it] 27%|██▋       | 700/2628 [30:18<57:59,  1.80s/it]                                                   27%|██▋       | 700/2628 [30:18<57:59,  1.80s/it][INFO|trainer.py:4643] 2025-10-21 17:26:43,589 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 17:26:43,589 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 17:26:43,589 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:26:44,062 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:26:48,905 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:57<00:28, 28.98s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:27:46,942 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [01:02<00:00, 18.99s/it][A                                                  
                                             [A 27%|██▋       | 700/2628 [31:27<57:59,  1.80s/it]
100%|██████████| 3/3 [01:03<00:00, 18.99s/it][A
                                             [A 27%|██▋       | 701/2628 [31:29<11:57:44, 22.35s/it] 27%|██▋       | 702/2628 [31:30<8:39:27, 16.18s/it]  27%|██▋       | 703/2628 [31:32<6:20:48, 11.87s/it] 27%|██▋       | 704/2628 [31:34<4:43:43,  8.85s/it] 27%|██▋       | 705/2628 [31:36<3:35:59,  6.74s/it] 27%|██▋       | 706/2628 [31:38<2:48:22,  5.26s/it] 27%|██▋       | 707/2628 [31:39<2:15:04,  4.22s/it] 27%|██▋       | 708/2628 [31:41<1:51:46,  3.49s/it] 27%|██▋       | 709/2628 [31:43<1:35:39,  2.99s/it] 27%|██▋       | 710/2628 [31:45<1:24:22,  2.64s/it]                                                     27%|██▋       | 710/2628 [31:45<1:24:22,  2.64s/it] 27%|██▋       | 711/2628 [31:47<1:16:17,  2.39s/it] 27%|██▋       | 712/2628 [31:48<1:10:37,  2.21s/it] 27%|██▋       | 713/2628 [31:50<1:06:37,  2.09s/it] 27%|██▋       | 714/2628 [31:52<1:04:01,  2.01s/it] 27%|██▋       | 715/2628 [31:54<1:02:05,  1.95s/it] 27%|██▋       | 716/2628 [31:56<1:00:40,  1.90s/it] 27%|██▋       | 717/2628 [31:57<59:37,  1.87s/it]   27%|██▋       | 718/2628 [31:59<58:55,  1.85s/it] 27%|██▋       | 719/2628 [32:01<58:26,  1.84s/it] 27%|██▋       | 720/2628 [32:03<58:02,  1.83s/it]                                                   27%|██▋       | 720/2628 [32:03<58:02,  1.83s/it] 27%|██▋       | 721/2628 [32:05<57:44,  1.82s/it] 27%|██▋       | 722/2628 [32:06<57:34,  1.81s/it] 28%|██▊       | 723/2628 [32:08<57:31,  1.81s/it] 28%|██▊       | 724/2628 [32:10<57:22,  1.81s/it] 28%|██▊       | 725/2628 [32:12<57:14,  1.80s/it] 28%|██▊       | 726/2628 [32:14<57:12,  1.80s/it] 28%|██▊       | 727/2628 [32:15<57:14,  1.81s/it] 28%|██▊       | 728/2628 [32:17<57:06,  1.80s/it] 28%|██▊       | 729/2628 [32:19<57:11,  1.81s/it] 28%|██▊       | 730/2628 [32:21<57:03,  1.80s/it]                                                   28%|██▊       | 730/2628 [32:21<57:03,  1.80s/it] 28%|██▊       | 731/2628 [32:23<57:10,  1.81s/it] 28%|██▊       | 732/2628 [32:24<57:06,  1.81s/it] 28%|██▊       | 733/2628 [32:26<57:01,  1.81s/it] 28%|██▊       | 734/2628 [32:28<56:56,  1.80s/it] 28%|██▊       | 735/2628 [32:30<56:59,  1.81s/it] 28%|██▊       | 736/2628 [32:32<56:59,  1.81s/it] 28%|██▊       | 737/2628 [32:33<56:51,  1.80s/it] 28%|██▊       | 738/2628 [32:35<56:50,  1.80s/it] 28%|██▊       | 739/2628 [32:37<56:48,  1.80s/it] 28%|██▊       | 740/2628 [32:39<56:42,  1.80s/it]                                                   28%|██▊       | 740/2628 [32:39<56:42,  1.80s/it] 28%|██▊       | 741/2628 [32:41<56:40,  1.80s/it] 28%|██▊       | 742/2628 [32:43<56:37,  1.80s/it] 28%|██▊       | 743/2628 [32:45<59:20,  1.89s/it] 28%|██▊       | 744/2628 [32:46<58:29,  1.86s/it] 28%|██▊       | 745/2628 [32:48<57:58,  1.85s/it] 28%|██▊       | 746/2628 [32:50<57:35,  1.84s/it] 28%|██▊       | 747/2628 [32:52<57:12,  1.83s/it] 28%|██▊       | 748/2628 [32:54<56:56,  1.82s/it] 29%|██▊       | 749/2628 [32:55<56:55,  1.82s/it] 29%|██▊       | 750/2628 [32:57<56:44,  1.81s/it]                                                   29%|██▊       | 750/2628 [32:57<56:44,  1.81s/it] 29%|██▊       | 751/2628 [32:59<56:34,  1.81s/it] 29%|██▊       | 752/2628 [33:01<56:34,  1.81s/it] 29%|██▊       | 753/2628 [33:03<56:26,  1.81s/it] 29%|██▊       | 754/2628 [33:04<56:19,  1.80s/it] 29%|██▊       | 755/2628 [33:06<56:22,  1.81s/it] 29%|██▉       | 756/2628 [33:08<56:17,  1.80s/it] 29%|██▉       | 757/2628 [33:10<56:14,  1.80s/it] 29%|██▉       | 758/2628 [33:12<56:14,  1.80s/it] 29%|██▉       | 759/2628 [33:13<56:11,  1.80s/it] 29%|██▉       | 760/2628 [33:15<56:17,  1.81s/it]                                                   29%|██▉       | 760/2628 [33:15<56:17,  1.81s/it] 29%|██▉       | 761/2628 [33:17<56:18,  1.81s/it] 29%|██▉       | 762/2628 [33:19<56:12,  1.81s/it] 29%|██▉       | 763/2628 [33:21<56:12,  1.81s/it] 29%|██▉       | 764/2628 [33:23<56:06,  1.81s/it] 29%|██▉       | 765/2628 [33:24<56:01,  1.80s/it] 29%|██▉       | 766/2628 [33:26<55:56,  1.80s/it] 29%|██▉       | 767/2628 [33:28<55:51,  1.80s/it] 29%|██▉       | 768/2628 [33:30<55:54,  1.80s/it] 29%|██▉       | 769/2628 [33:32<56:00,  1.81s/it] 29%|██▉       | 770/2628 [33:34<58:55,  1.90s/it]                                                   29%|██▉       | 770/2628 [33:34<58:55,  1.90s/it] 29%|██▉       | 771/2628 [33:35<58:05,  1.88s/it] 29%|██▉       | 772/2628 [33:37<57:22,  1.85s/it] 29%|██▉       | 773/2628 [33:39<56:51,  1.84s/it] 29%|██▉       | 774/2628 [33:41<56:27,  1.83s/it] 29%|██▉       | 775/2628 [33:43<56:08,  1.82s/it] 30%|██▉       | 776/2628 [33:44<55:56,  1.81s/it] 30%|██▉       | 777/2628 [33:46<55:46,  1.81s/it] 30%|██▉       | 778/2628 [33:48<55:47,  1.81s/it] 30%|██▉       | 779/2628 [33:50<55:51,  1.81s/it] 30%|██▉       | 780/2628 [33:52<55:45,  1.81s/it]                                                   30%|██▉       | 780/2628 [33:52<55:45,  1.81s/it] 30%|██▉       | 781/2628 [33:54<55:41,  1.81s/it] 30%|██▉       | 782/2628 [33:55<55:36,  1.81s/it] 30%|██▉       | 783/2628 [33:57<55:30,  1.81s/it] 30%|██▉       | 784/2628 [33:59<55:26,  1.80s/it] 30%|██▉       | 785/2628 [34:01<55:20,  1.80s/it] 30%|██▉       | 786/2628 [34:03<55:36,  1.81s/it] 30%|██▉       | 787/2628 [34:04<55:28,  1.81s/it] 30%|██▉       | 788/2628 [34:06<55:23,  1.81s/it] 30%|███       | 789/2628 [34:08<55:22,  1.81s/it] 30%|███       | 790/2628 [34:10<55:24,  1.81s/it]                                                   30%|███       | 790/2628 [34:10<55:24,  1.81s/it] 30%|███       | 791/2628 [34:12<55:25,  1.81s/it] 30%|███       | 792/2628 [34:13<55:28,  1.81s/it] 30%|███       | 793/2628 [34:15<55:28,  1.81s/it] 30%|███       | 794/2628 [34:17<55:29,  1.82s/it] 30%|███       | 795/2628 [34:19<55:18,  1.81s/it] 30%|███       | 796/2628 [34:21<55:17,  1.81s/it] 30%|███       | 797/2628 [34:22<55:09,  1.81s/it] 30%|███       | 798/2628 [34:24<55:02,  1.80s/it] 30%|███       | 799/2628 [34:26<54:57,  1.80s/it] 30%|███       | 800/2628 [34:28<54:52,  1.80s/it]                                                   30%|███       | 800/2628 [34:28<54:52,  1.80s/it][INFO|trainer.py:4643] 2025-10-21 17:30:53,182 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 17:30:53,182 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 17:30:53,182 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:30:53,649 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][A[WARNING|utils.py:2443] 2025-10-21 17:31:49,538 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:03<00:01,  1.88s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:31:53,361 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:59<00:00, 24.46s/it][A                                                  
                                             [A 30%|███       | 800/2628 [36:24<54:52,  1.80s/it]
100%|██████████| 3/3 [00:59<00:00, 24.46s/it][A
                                             [A[INFO|trainer.py:4309] 2025-10-21 17:32:49,557 >> Saving model checkpoint to saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-800
[INFO|configuration_utils.py:491] 2025-10-21 17:32:49,561 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-800/config.json
[INFO|configuration_utils.py:757] 2025-10-21 17:32:49,562 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-800/generation_config.json
[INFO|modeling_utils.py:4189] 2025-10-21 17:32:54,136 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-800/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2421] 2025-10-21 17:32:54,138 >> chat template saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-800/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-21 17:32:54,139 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-21 17:32:54,139 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-800/special_tokens_map.json
[INFO|image_processing_base.py:253] 2025-10-21 17:32:59,117 >> Image processor saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-800/preprocessor_config.json
[INFO|tokenization_utils_base.py:2421] 2025-10-21 17:32:59,118 >> chat template saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-800/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-21 17:32:59,118 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-21 17:32:59,118 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-800/special_tokens_map.json
[INFO|video_processing_utils.py:600] 2025-10-21 17:32:59,205 >> Video processor saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-800/video_preprocessor_config.json
[INFO|processing_utils.py:814] 2025-10-21 17:32:59,206 >> chat template saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-800/chat_template.jinja
 30%|███       | 801/2628 [36:36<20:08:29, 39.69s/it] 31%|███       | 802/2628 [36:38<14:21:55, 28.32s/it] 31%|███       | 803/2628 [36:40<10:19:31, 20.37s/it] 31%|███       | 804/2628 [36:41<7:29:51, 14.80s/it]  31%|███       | 805/2628 [36:43<5:31:16, 10.90s/it] 31%|███       | 806/2628 [36:45<4:08:08,  8.17s/it] 31%|███       | 807/2628 [36:47<3:09:59,  6.26s/it] 31%|███       | 808/2628 [36:49<2:29:17,  4.92s/it] 31%|███       | 809/2628 [36:50<2:00:56,  3.99s/it] 31%|███       | 810/2628 [36:52<1:41:01,  3.33s/it]                                                     31%|███       | 810/2628 [36:52<1:41:01,  3.33s/it] 31%|███       | 811/2628 [36:54<1:27:00,  2.87s/it] 31%|███       | 812/2628 [36:56<1:17:13,  2.55s/it] 31%|███       | 813/2628 [36:58<1:10:28,  2.33s/it] 31%|███       | 814/2628 [36:59<1:05:36,  2.17s/it] 31%|███       | 815/2628 [37:01<1:02:12,  2.06s/it] 31%|███       | 816/2628 [37:03<59:48,  1.98s/it]   31%|███       | 817/2628 [37:05<58:08,  1.93s/it] 31%|███       | 818/2628 [37:07<56:58,  1.89s/it] 31%|███       | 819/2628 [37:08<56:09,  1.86s/it] 31%|███       | 820/2628 [37:10<55:32,  1.84s/it]                                                   31%|███       | 820/2628 [37:10<55:32,  1.84s/it] 31%|███       | 821/2628 [37:12<55:07,  1.83s/it] 31%|███▏      | 822/2628 [37:14<54:49,  1.82s/it] 31%|███▏      | 823/2628 [37:16<54:41,  1.82s/it] 31%|███▏      | 824/2628 [37:17<54:38,  1.82s/it] 31%|███▏      | 825/2628 [37:19<54:29,  1.81s/it] 31%|███▏      | 826/2628 [37:21<54:20,  1.81s/it] 31%|███▏      | 827/2628 [37:23<54:13,  1.81s/it] 32%|███▏      | 828/2628 [37:25<54:13,  1.81s/it] 32%|███▏      | 829/2628 [37:26<54:07,  1.80s/it] 32%|███▏      | 830/2628 [37:28<54:04,  1.80s/it]                                                   32%|███▏      | 830/2628 [37:28<54:04,  1.80s/it] 32%|███▏      | 831/2628 [37:30<54:04,  1.81s/it] 32%|███▏      | 832/2628 [37:32<53:59,  1.80s/it] 32%|███▏      | 833/2628 [37:34<53:59,  1.80s/it] 32%|███▏      | 834/2628 [37:35<54:03,  1.81s/it] 32%|███▏      | 835/2628 [37:37<54:07,  1.81s/it] 32%|███▏      | 836/2628 [37:39<54:03,  1.81s/it] 32%|███▏      | 837/2628 [37:41<54:00,  1.81s/it] 32%|███▏      | 838/2628 [37:43<54:00,  1.81s/it] 32%|███▏      | 839/2628 [37:45<53:56,  1.81s/it] 32%|███▏      | 840/2628 [37:46<53:57,  1.81s/it]                                                   32%|███▏      | 840/2628 [37:46<53:57,  1.81s/it] 32%|███▏      | 841/2628 [37:48<53:57,  1.81s/it] 32%|███▏      | 842/2628 [37:50<54:00,  1.81s/it] 32%|███▏      | 843/2628 [37:52<53:59,  1.81s/it] 32%|███▏      | 844/2628 [37:54<53:52,  1.81s/it] 32%|███▏      | 845/2628 [37:55<53:42,  1.81s/it] 32%|███▏      | 846/2628 [37:57<53:36,  1.80s/it] 32%|███▏      | 847/2628 [37:59<53:39,  1.81s/it] 32%|███▏      | 848/2628 [38:01<53:32,  1.80s/it] 32%|███▏      | 849/2628 [38:03<53:27,  1.80s/it] 32%|███▏      | 850/2628 [38:04<53:31,  1.81s/it]                                                   32%|███▏      | 850/2628 [38:04<53:31,  1.81s/it] 32%|███▏      | 851/2628 [38:06<53:26,  1.80s/it] 32%|███▏      | 852/2628 [38:08<53:22,  1.80s/it] 32%|███▏      | 853/2628 [38:10<53:18,  1.80s/it] 32%|███▏      | 854/2628 [38:12<53:14,  1.80s/it] 33%|███▎      | 855/2628 [38:13<53:22,  1.81s/it] 33%|███▎      | 856/2628 [38:15<53:20,  1.81s/it] 33%|███▎      | 857/2628 [38:17<53:13,  1.80s/it] 33%|███▎      | 858/2628 [38:19<53:10,  1.80s/it] 33%|███▎      | 859/2628 [38:21<53:07,  1.80s/it] 33%|███▎      | 860/2628 [38:22<53:06,  1.80s/it]                                                   33%|███▎      | 860/2628 [38:22<53:06,  1.80s/it] 33%|███▎      | 861/2628 [38:24<53:02,  1.80s/it] 33%|███▎      | 862/2628 [38:26<53:05,  1.80s/it] 33%|███▎      | 863/2628 [38:28<53:05,  1.80s/it] 33%|███▎      | 864/2628 [38:30<53:00,  1.80s/it] 33%|███▎      | 865/2628 [38:31<52:56,  1.80s/it] 33%|███▎      | 866/2628 [38:33<52:53,  1.80s/it] 33%|███▎      | 867/2628 [38:35<52:52,  1.80s/it] 33%|███▎      | 868/2628 [38:37<52:48,  1.80s/it] 33%|███▎      | 869/2628 [38:39<52:46,  1.80s/it] 33%|███▎      | 870/2628 [38:40<52:50,  1.80s/it]                                                   33%|███▎      | 870/2628 [38:40<52:50,  1.80s/it] 33%|███▎      | 871/2628 [38:42<52:55,  1.81s/it] 33%|███▎      | 872/2628 [38:44<52:47,  1.80s/it] 33%|███▎      | 873/2628 [38:46<52:51,  1.81s/it] 33%|███▎      | 874/2628 [38:48<52:43,  1.80s/it] 33%|███▎      | 875/2628 [38:49<52:39,  1.80s/it] 33%|███▎      | 876/2628 [38:51<53:21,  1.83s/it] 33%|███▎      | 877/2628 [38:54<1:02:26,  2.14s/it] 33%|███▎      | 878/2628 [38:56<59:37,  2.04s/it]   33%|███▎      | 879/2628 [38:58<57:27,  1.97s/it] 33%|███▎      | 880/2628 [39:00<56:01,  1.92s/it]                                                   33%|███▎      | 880/2628 [39:00<56:01,  1.92s/it] 34%|███▎      | 881/2628 [39:01<54:56,  1.89s/it] 34%|███▎      | 882/2628 [39:03<54:08,  1.86s/it] 34%|███▎      | 883/2628 [39:05<53:43,  1.85s/it] 34%|███▎      | 884/2628 [39:07<53:18,  1.83s/it] 34%|███▎      | 885/2628 [39:09<52:57,  1.82s/it] 34%|███▎      | 886/2628 [39:11<52:59,  1.83s/it] 34%|███▍      | 887/2628 [39:12<52:45,  1.82s/it] 34%|███▍      | 888/2628 [39:14<52:34,  1.81s/it] 34%|███▍      | 889/2628 [39:16<52:28,  1.81s/it] 34%|███▍      | 890/2628 [39:18<52:28,  1.81s/it]                                                   34%|███▍      | 890/2628 [39:18<52:28,  1.81s/it] 34%|███▍      | 891/2628 [39:20<52:19,  1.81s/it] 34%|███▍      | 892/2628 [39:21<52:12,  1.80s/it] 34%|███▍      | 893/2628 [39:23<52:07,  1.80s/it] 34%|███▍      | 894/2628 [39:25<52:08,  1.80s/it] 34%|███▍      | 895/2628 [39:27<52:03,  1.80s/it] 34%|███▍      | 896/2628 [39:29<52:02,  1.80s/it] 34%|███▍      | 897/2628 [39:30<51:57,  1.80s/it] 34%|███▍      | 898/2628 [39:32<51:55,  1.80s/it] 34%|███▍      | 899/2628 [39:34<51:51,  1.80s/it] 34%|███▍      | 900/2628 [39:36<51:48,  1.80s/it]                                                   34%|███▍      | 900/2628 [39:36<51:48,  1.80s/it][INFO|trainer.py:4643] 2025-10-21 17:36:01,056 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 17:36:01,056 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 17:36:01,056 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:36:01,534 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][A[WARNING|utils.py:2443] 2025-10-21 17:36:57,612 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:05<00:02,  2.60s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:37:02,881 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [01:02<00:00, 25.23s/it][A                                                  
                                             [A 34%|███▍      | 900/2628 [41:35<51:48,  1.80s/it]
100%|██████████| 3/3 [01:02<00:00, 25.23s/it][A
                                             [A 34%|███▍      | 901/2628 [41:36<17:58:26, 37.47s/it] 34%|███▍      | 902/2628 [41:38<12:50:05, 26.77s/it] 34%|███▍      | 903/2628 [41:40<9:14:15, 19.28s/it]  34%|███▍      | 904/2628 [41:42<6:43:17, 14.04s/it] 34%|███▍      | 905/2628 [41:44<4:57:40, 10.37s/it] 34%|███▍      | 906/2628 [41:45<3:43:45,  7.80s/it] 35%|███▍      | 907/2628 [41:47<2:52:01,  6.00s/it] 35%|███▍      | 908/2628 [41:49<2:15:49,  4.74s/it] 35%|███▍      | 909/2628 [41:51<1:50:38,  3.86s/it] 35%|███▍      | 910/2628 [41:53<1:32:51,  3.24s/it]                                                     35%|███▍      | 910/2628 [41:53<1:32:51,  3.24s/it] 35%|███▍      | 911/2628 [41:54<1:20:33,  2.82s/it] 35%|███▍      | 912/2628 [41:56<1:11:55,  2.52s/it] 35%|███▍      | 913/2628 [41:58<1:05:57,  2.31s/it] 35%|███▍      | 914/2628 [42:00<1:01:44,  2.16s/it] 35%|███▍      | 915/2628 [42:02<58:37,  2.05s/it]   35%|███▍      | 916/2628 [42:04<56:26,  1.98s/it] 35%|███▍      | 917/2628 [42:05<54:58,  1.93s/it] 35%|███▍      | 918/2628 [42:07<53:49,  1.89s/it] 35%|███▍      | 919/2628 [42:09<53:09,  1.87s/it] 35%|███▌      | 920/2628 [42:11<52:40,  1.85s/it]                                                   35%|███▌      | 920/2628 [42:11<52:40,  1.85s/it] 35%|███▌      | 921/2628 [42:13<52:19,  1.84s/it] 35%|███▌      | 922/2628 [42:14<51:54,  1.83s/it] 35%|███▌      | 923/2628 [42:16<51:45,  1.82s/it] 35%|███▌      | 924/2628 [42:18<51:41,  1.82s/it] 35%|███▌      | 925/2628 [42:20<51:30,  1.81s/it] 35%|███▌      | 926/2628 [42:22<51:20,  1.81s/it] 35%|███▌      | 927/2628 [42:23<51:11,  1.81s/it] 35%|███▌      | 928/2628 [42:25<51:08,  1.81s/it] 35%|███▌      | 929/2628 [42:27<51:13,  1.81s/it] 35%|███▌      | 930/2628 [42:29<51:04,  1.80s/it]                                                   35%|███▌      | 930/2628 [42:29<51:04,  1.80s/it] 35%|███▌      | 931/2628 [42:31<51:02,  1.80s/it] 35%|███▌      | 932/2628 [42:32<50:59,  1.80s/it] 36%|███▌      | 933/2628 [42:34<50:55,  1.80s/it] 36%|███▌      | 934/2628 [42:36<50:52,  1.80s/it] 36%|███▌      | 935/2628 [42:38<50:57,  1.81s/it] 36%|███▌      | 936/2628 [42:40<50:53,  1.80s/it] 36%|███▌      | 937/2628 [42:41<50:47,  1.80s/it] 36%|███▌      | 938/2628 [42:43<50:43,  1.80s/it] 36%|███▌      | 939/2628 [42:45<50:47,  1.80s/it] 36%|███▌      | 940/2628 [42:47<50:45,  1.80s/it]                                                   36%|███▌      | 940/2628 [42:47<50:45,  1.80s/it] 36%|███▌      | 941/2628 [42:49<50:50,  1.81s/it] 36%|███▌      | 942/2628 [42:50<50:42,  1.80s/it] 36%|███▌      | 943/2628 [42:52<50:46,  1.81s/it] 36%|███▌      | 944/2628 [42:54<50:44,  1.81s/it] 36%|███▌      | 945/2628 [42:56<50:42,  1.81s/it] 36%|███▌      | 946/2628 [42:58<50:46,  1.81s/it] 36%|███▌      | 947/2628 [43:00<50:48,  1.81s/it] 36%|███▌      | 948/2628 [43:01<50:42,  1.81s/it] 36%|███▌      | 949/2628 [43:03<50:35,  1.81s/it] 36%|███▌      | 950/2628 [43:05<50:38,  1.81s/it]                                                   36%|███▌      | 950/2628 [43:05<50:38,  1.81s/it] 36%|███▌      | 951/2628 [43:07<50:37,  1.81s/it] 36%|███▌      | 952/2628 [43:09<50:31,  1.81s/it] 36%|███▋      | 953/2628 [43:10<50:34,  1.81s/it] 36%|███▋      | 954/2628 [43:12<50:28,  1.81s/it] 36%|███▋      | 955/2628 [43:14<50:23,  1.81s/it] 36%|███▋      | 956/2628 [43:16<50:19,  1.81s/it] 36%|███▋      | 957/2628 [43:18<50:15,  1.80s/it] 36%|███▋      | 958/2628 [43:19<50:11,  1.80s/it] 36%|███▋      | 959/2628 [43:21<50:07,  1.80s/it] 37%|███▋      | 960/2628 [43:23<50:06,  1.80s/it]                                                   37%|███▋      | 960/2628 [43:23<50:06,  1.80s/it] 37%|███▋      | 961/2628 [43:25<50:04,  1.80s/it] 37%|███▋      | 962/2628 [43:27<50:04,  1.80s/it] 37%|███▋      | 963/2628 [43:28<50:01,  1.80s/it] 37%|███▋      | 964/2628 [43:30<50:08,  1.81s/it] 37%|███▋      | 965/2628 [43:32<50:02,  1.81s/it] 37%|███▋      | 966/2628 [43:34<49:59,  1.81s/it] 37%|███▋      | 967/2628 [43:36<49:56,  1.80s/it] 37%|███▋      | 968/2628 [43:37<49:54,  1.80s/it] 37%|███▋      | 969/2628 [43:39<49:51,  1.80s/it] 37%|███▋      | 970/2628 [43:41<49:50,  1.80s/it]                                                   37%|███▋      | 970/2628 [43:41<49:50,  1.80s/it] 37%|███▋      | 971/2628 [43:43<49:48,  1.80s/it] 37%|███▋      | 972/2628 [43:45<49:54,  1.81s/it] 37%|███▋      | 973/2628 [43:46<49:54,  1.81s/it] 37%|███▋      | 974/2628 [43:48<49:48,  1.81s/it] 37%|███▋      | 975/2628 [43:50<49:42,  1.80s/it] 37%|███▋      | 976/2628 [43:52<49:39,  1.80s/it] 37%|███▋      | 977/2628 [43:54<49:37,  1.80s/it] 37%|███▋      | 978/2628 [43:55<49:33,  1.80s/it] 37%|███▋      | 979/2628 [43:57<49:29,  1.80s/it] 37%|███▋      | 980/2628 [43:59<49:28,  1.80s/it]                                                   37%|███▋      | 980/2628 [43:59<49:28,  1.80s/it] 37%|███▋      | 981/2628 [44:01<49:32,  1.81s/it] 37%|███▋      | 982/2628 [44:03<49:27,  1.80s/it] 37%|███▋      | 983/2628 [44:04<49:22,  1.80s/it] 37%|███▋      | 984/2628 [44:06<49:21,  1.80s/it] 37%|███▋      | 985/2628 [44:08<49:18,  1.80s/it] 38%|███▊      | 986/2628 [44:10<49:24,  1.81s/it] 38%|███▊      | 987/2628 [44:12<49:23,  1.81s/it] 38%|███▊      | 988/2628 [44:14<49:18,  1.80s/it] 38%|███▊      | 989/2628 [44:15<49:22,  1.81s/it] 38%|███▊      | 990/2628 [44:17<49:27,  1.81s/it]                                                   38%|███▊      | 990/2628 [44:17<49:27,  1.81s/it] 38%|███▊      | 991/2628 [44:19<49:21,  1.81s/it] 38%|███▊      | 992/2628 [44:21<49:21,  1.81s/it] 38%|███▊      | 993/2628 [44:23<49:15,  1.81s/it] 38%|███▊      | 994/2628 [44:24<49:15,  1.81s/it] 38%|███▊      | 995/2628 [44:26<49:09,  1.81s/it] 38%|███▊      | 996/2628 [44:28<49:05,  1.80s/it] 38%|███▊      | 997/2628 [44:30<49:03,  1.80s/it] 38%|███▊      | 998/2628 [44:32<48:59,  1.80s/it] 38%|███▊      | 999/2628 [44:33<49:05,  1.81s/it] 38%|███▊      | 1000/2628 [44:35<49:07,  1.81s/it]                                                    38%|███▊      | 1000/2628 [44:35<49:07,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 17:41:00,553 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 17:41:00,553 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 17:41:00,553 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:41:01,042 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:41:59,431 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:58<00:29, 29.13s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:42:57,771 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [01:55<00:00, 40.72s/it][A                                                   
                                             [A 38%|███▊      | 1000/2628 [47:30<49:07,  1.81s/it]
100%|██████████| 3/3 [01:55<00:00, 40.72s/it][A
                                             [A 38%|███▊      | 1001/2628 [47:31<24:27:49, 54.13s/it] 38%|███▊      | 1002/2628 [47:33<17:21:25, 38.43s/it] 38%|███▊      | 1003/2628 [47:35<12:23:17, 27.44s/it] 38%|███▊      | 1004/2628 [47:37<8:54:37, 19.75s/it]  38%|███▊      | 1005/2628 [47:39<6:28:38, 14.37s/it] 38%|███▊      | 1006/2628 [47:40<4:46:27, 10.60s/it] 38%|███▊      | 1007/2628 [47:42<3:34:56,  7.96s/it] 38%|███▊      | 1008/2628 [47:44<2:44:56,  6.11s/it] 38%|███▊      | 1009/2628 [47:46<2:09:59,  4.82s/it] 38%|███▊      | 1010/2628 [47:48<1:45:31,  3.91s/it]                                                      38%|███▊      | 1010/2628 [47:48<1:45:31,  3.91s/it] 38%|███▊      | 1011/2628 [47:49<1:28:23,  3.28s/it] 39%|███▊      | 1012/2628 [47:51<1:16:27,  2.84s/it] 39%|███▊      | 1013/2628 [47:53<1:08:08,  2.53s/it] 39%|███▊      | 1014/2628 [47:55<1:02:17,  2.32s/it] 39%|███▊      | 1015/2628 [47:57<58:04,  2.16s/it]   39%|███▊      | 1016/2628 [47:58<55:08,  2.05s/it] 39%|███▊      | 1017/2628 [48:00<53:04,  1.98s/it] 39%|███▊      | 1018/2628 [48:02<51:36,  1.92s/it] 39%|███▉      | 1019/2628 [48:04<50:45,  1.89s/it] 39%|███▉      | 1020/2628 [48:06<49:59,  1.87s/it]                                                    39%|███▉      | 1020/2628 [48:06<49:59,  1.87s/it] 39%|███▉      | 1021/2628 [48:07<49:28,  1.85s/it] 39%|███▉      | 1022/2628 [48:09<49:12,  1.84s/it] 39%|███▉      | 1023/2628 [48:11<48:54,  1.83s/it] 39%|███▉      | 1024/2628 [48:13<48:38,  1.82s/it] 39%|███▉      | 1025/2628 [48:15<48:27,  1.81s/it] 39%|███▉      | 1026/2628 [48:17<48:17,  1.81s/it] 39%|███▉      | 1027/2628 [48:18<48:12,  1.81s/it] 39%|███▉      | 1028/2628 [48:20<48:07,  1.80s/it] 39%|███▉      | 1029/2628 [48:22<48:03,  1.80s/it] 39%|███▉      | 1030/2628 [48:24<48:03,  1.80s/it]                                                    39%|███▉      | 1030/2628 [48:24<48:03,  1.80s/it] 39%|███▉      | 1031/2628 [48:26<48:05,  1.81s/it] 39%|███▉      | 1032/2628 [48:27<48:01,  1.81s/it] 39%|███▉      | 1033/2628 [48:29<48:02,  1.81s/it] 39%|███▉      | 1034/2628 [48:31<47:57,  1.81s/it] 39%|███▉      | 1035/2628 [48:33<47:53,  1.80s/it] 39%|███▉      | 1036/2628 [48:35<47:51,  1.80s/it] 39%|███▉      | 1037/2628 [48:36<47:49,  1.80s/it] 39%|███▉      | 1038/2628 [48:38<47:54,  1.81s/it] 40%|███▉      | 1039/2628 [48:40<47:57,  1.81s/it] 40%|███▉      | 1040/2628 [48:42<47:52,  1.81s/it]                                                    40%|███▉      | 1040/2628 [48:42<47:52,  1.81s/it] 40%|███▉      | 1041/2628 [48:44<47:46,  1.81s/it] 40%|███▉      | 1042/2628 [48:45<47:43,  1.81s/it] 40%|███▉      | 1043/2628 [48:47<47:38,  1.80s/it] 40%|███▉      | 1044/2628 [48:49<47:37,  1.80s/it] 40%|███▉      | 1045/2628 [48:51<47:34,  1.80s/it] 40%|███▉      | 1046/2628 [48:53<47:37,  1.81s/it] 40%|███▉      | 1047/2628 [48:54<47:32,  1.80s/it] 40%|███▉      | 1048/2628 [48:56<47:30,  1.80s/it] 40%|███▉      | 1049/2628 [48:58<47:26,  1.80s/it] 40%|███▉      | 1050/2628 [49:00<47:22,  1.80s/it]                                                    40%|███▉      | 1050/2628 [49:00<47:22,  1.80s/it] 40%|███▉      | 1051/2628 [49:02<47:20,  1.80s/it] 40%|████      | 1052/2628 [49:03<47:25,  1.81s/it] 40%|████      | 1053/2628 [49:05<47:23,  1.81s/it] 40%|████      | 1054/2628 [49:07<47:20,  1.80s/it] 40%|████      | 1055/2628 [49:09<47:21,  1.81s/it] 40%|████      | 1056/2628 [49:11<47:25,  1.81s/it] 40%|████      | 1057/2628 [49:12<47:21,  1.81s/it] 40%|████      | 1058/2628 [49:14<47:15,  1.81s/it] 40%|████      | 1059/2628 [49:16<47:17,  1.81s/it] 40%|████      | 1060/2628 [49:18<47:18,  1.81s/it]                                                    40%|████      | 1060/2628 [49:18<47:18,  1.81s/it] 40%|████      | 1061/2628 [49:20<47:22,  1.81s/it] 40%|████      | 1062/2628 [49:22<47:14,  1.81s/it] 40%|████      | 1063/2628 [49:23<47:07,  1.81s/it] 40%|████      | 1064/2628 [49:25<47:02,  1.80s/it] 41%|████      | 1065/2628 [49:27<47:00,  1.80s/it] 41%|████      | 1066/2628 [49:29<46:55,  1.80s/it] 41%|████      | 1067/2628 [49:31<46:51,  1.80s/it] 41%|████      | 1068/2628 [49:32<46:47,  1.80s/it] 41%|████      | 1069/2628 [49:34<46:47,  1.80s/it] 41%|████      | 1070/2628 [49:36<46:44,  1.80s/it]                                                    41%|████      | 1070/2628 [49:36<46:44,  1.80s/it] 41%|████      | 1071/2628 [49:38<46:44,  1.80s/it] 41%|████      | 1072/2628 [49:40<46:41,  1.80s/it] 41%|████      | 1073/2628 [49:41<46:48,  1.81s/it] 41%|████      | 1074/2628 [49:43<46:50,  1.81s/it] 41%|████      | 1075/2628 [49:45<46:44,  1.81s/it] 41%|████      | 1076/2628 [49:47<46:43,  1.81s/it] 41%|████      | 1077/2628 [49:49<46:45,  1.81s/it] 41%|████      | 1078/2628 [49:50<46:46,  1.81s/it] 41%|████      | 1079/2628 [49:52<46:39,  1.81s/it] 41%|████      | 1080/2628 [49:54<46:35,  1.81s/it]                                                    41%|████      | 1080/2628 [49:54<46:35,  1.81s/it] 41%|████      | 1081/2628 [49:56<46:46,  1.81s/it] 41%|████      | 1082/2628 [49:58<46:39,  1.81s/it] 41%|████      | 1083/2628 [49:59<46:31,  1.81s/it] 41%|████      | 1084/2628 [50:01<46:34,  1.81s/it] 41%|████▏     | 1085/2628 [50:03<46:27,  1.81s/it] 41%|████▏     | 1086/2628 [50:05<46:22,  1.80s/it] 41%|████▏     | 1087/2628 [50:07<46:17,  1.80s/it] 41%|████▏     | 1088/2628 [50:08<46:14,  1.80s/it] 41%|████▏     | 1089/2628 [50:10<46:12,  1.80s/it] 41%|████▏     | 1090/2628 [50:12<46:08,  1.80s/it]                                                    41%|████▏     | 1090/2628 [50:12<46:08,  1.80s/it] 42%|████▏     | 1091/2628 [50:14<46:14,  1.81s/it] 42%|████▏     | 1092/2628 [50:16<46:12,  1.81s/it] 42%|████▏     | 1093/2628 [50:17<46:13,  1.81s/it] 42%|████▏     | 1094/2628 [50:19<46:13,  1.81s/it] 42%|████▏     | 1095/2628 [50:21<46:11,  1.81s/it] 42%|████▏     | 1096/2628 [50:23<46:04,  1.80s/it] 42%|████▏     | 1097/2628 [50:25<46:00,  1.80s/it] 42%|████▏     | 1098/2628 [50:27<45:57,  1.80s/it] 42%|████▏     | 1099/2628 [50:28<45:53,  1.80s/it] 42%|████▏     | 1100/2628 [50:30<46:00,  1.81s/it]                                                    42%|████▏     | 1100/2628 [50:30<46:00,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 17:46:55,457 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 17:46:55,458 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 17:46:55,458 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:46:55,949 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:47:54,089 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:05<00:02,  2.53s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:47:59,210 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [01:03<00:00, 25.69s/it][A                                                   
                                             [A 42%|████▏     | 1100/2628 [52:32<46:00,  1.81s/it]
100%|██████████| 3/3 [01:03<00:00, 25.69s/it][A
                                             [A 42%|████▏     | 1101/2628 [52:34<16:18:42, 38.46s/it] 42%|████▏     | 1102/2628 [52:36<11:38:27, 27.46s/it] 42%|████▏     | 1103/2628 [52:38<8:22:27, 19.77s/it]  42%|████▏     | 1104/2628 [52:40<6:05:18, 14.38s/it] 42%|████▏     | 1105/2628 [52:41<4:29:14, 10.61s/it] 42%|████▏     | 1106/2628 [52:43<3:22:10,  7.97s/it] 42%|████▏     | 1107/2628 [52:45<2:35:06,  6.12s/it] 42%|████▏     | 1108/2628 [52:47<2:02:17,  4.83s/it] 42%|████▏     | 1109/2628 [52:49<1:39:19,  3.92s/it] 42%|████▏     | 1110/2628 [52:50<1:23:11,  3.29s/it]                                                      42%|████▏     | 1110/2628 [52:50<1:23:11,  3.29s/it] 42%|████▏     | 1111/2628 [52:52<1:11:51,  2.84s/it] 42%|████▏     | 1112/2628 [52:54<1:03:59,  2.53s/it] 42%|████▏     | 1113/2628 [52:56<58:24,  2.31s/it]   42%|████▏     | 1114/2628 [52:58<54:35,  2.16s/it] 42%|████▏     | 1115/2628 [52:59<51:49,  2.06s/it] 42%|████▏     | 1116/2628 [53:01<49:52,  1.98s/it] 43%|████▎     | 1117/2628 [53:03<48:37,  1.93s/it] 43%|████▎     | 1118/2628 [53:05<47:44,  1.90s/it] 43%|████▎     | 1119/2628 [53:07<46:58,  1.87s/it] 43%|████▎     | 1120/2628 [53:08<46:26,  1.85s/it]                                                    43%|████▎     | 1120/2628 [53:08<46:26,  1.85s/it] 43%|████▎     | 1121/2628 [53:10<46:12,  1.84s/it] 43%|████▎     | 1122/2628 [53:12<45:58,  1.83s/it] 43%|████▎     | 1123/2628 [53:14<45:44,  1.82s/it] 43%|████▎     | 1124/2628 [53:16<45:32,  1.82s/it] 43%|████▎     | 1125/2628 [53:18<45:28,  1.82s/it] 43%|████▎     | 1126/2628 [53:19<45:21,  1.81s/it] 43%|████▎     | 1127/2628 [53:21<45:22,  1.81s/it] 43%|████▎     | 1128/2628 [53:23<45:19,  1.81s/it] 43%|████▎     | 1129/2628 [53:25<45:18,  1.81s/it] 43%|████▎     | 1130/2628 [53:27<45:11,  1.81s/it]                                                    43%|████▎     | 1130/2628 [53:27<45:11,  1.81s/it] 43%|████▎     | 1131/2628 [53:28<45:07,  1.81s/it] 43%|████▎     | 1132/2628 [53:30<45:01,  1.81s/it] 43%|████▎     | 1133/2628 [53:32<45:00,  1.81s/it] 43%|████▎     | 1134/2628 [53:34<45:04,  1.81s/it] 43%|████▎     | 1135/2628 [53:36<44:58,  1.81s/it] 43%|████▎     | 1136/2628 [53:37<44:55,  1.81s/it] 43%|████▎     | 1137/2628 [53:39<45:01,  1.81s/it] 43%|████▎     | 1138/2628 [53:41<44:56,  1.81s/it] 43%|████▎     | 1139/2628 [53:43<44:51,  1.81s/it] 43%|████▎     | 1140/2628 [53:45<44:47,  1.81s/it]                                                    43%|████▎     | 1140/2628 [53:45<44:47,  1.81s/it] 43%|████▎     | 1141/2628 [53:46<44:51,  1.81s/it] 43%|████▎     | 1142/2628 [53:48<44:48,  1.81s/it] 43%|████▎     | 1143/2628 [53:50<44:50,  1.81s/it] 44%|████▎     | 1144/2628 [53:52<44:47,  1.81s/it] 44%|████▎     | 1145/2628 [53:54<44:45,  1.81s/it] 44%|████▎     | 1146/2628 [53:56<44:46,  1.81s/it] 44%|████▎     | 1147/2628 [53:57<44:41,  1.81s/it] 44%|████▎     | 1148/2628 [53:59<44:44,  1.81s/it] 44%|████▎     | 1149/2628 [54:01<44:40,  1.81s/it] 44%|████▍     | 1150/2628 [54:03<44:33,  1.81s/it]                                                    44%|████▍     | 1150/2628 [54:03<44:33,  1.81s/it] 44%|████▍     | 1151/2628 [54:05<44:34,  1.81s/it] 44%|████▍     | 1152/2628 [54:06<44:28,  1.81s/it] 44%|████▍     | 1153/2628 [54:08<44:23,  1.81s/it] 44%|████▍     | 1154/2628 [54:10<44:19,  1.80s/it] 44%|████▍     | 1155/2628 [54:12<44:16,  1.80s/it] 44%|████▍     | 1156/2628 [54:14<44:12,  1.80s/it] 44%|████▍     | 1157/2628 [54:15<44:10,  1.80s/it] 44%|████▍     | 1158/2628 [54:17<44:13,  1.81s/it] 44%|████▍     | 1159/2628 [54:19<44:15,  1.81s/it] 44%|████▍     | 1160/2628 [54:21<44:16,  1.81s/it]                                                    44%|████▍     | 1160/2628 [54:21<44:16,  1.81s/it] 44%|████▍     | 1161/2628 [54:23<44:16,  1.81s/it] 44%|████▍     | 1162/2628 [54:24<44:19,  1.81s/it] 44%|████▍     | 1163/2628 [54:26<44:10,  1.81s/it] 44%|████▍     | 1164/2628 [54:28<44:08,  1.81s/it] 44%|████▍     | 1165/2628 [54:30<44:08,  1.81s/it] 44%|████▍     | 1166/2628 [54:32<44:09,  1.81s/it] 44%|████▍     | 1167/2628 [54:33<44:04,  1.81s/it] 44%|████▍     | 1168/2628 [54:35<43:56,  1.81s/it] 44%|████▍     | 1169/2628 [54:37<43:52,  1.80s/it] 45%|████▍     | 1170/2628 [54:39<43:48,  1.80s/it]                                                    45%|████▍     | 1170/2628 [54:39<43:48,  1.80s/it] 45%|████▍     | 1171/2628 [54:41<43:55,  1.81s/it] 45%|████▍     | 1172/2628 [54:43<43:54,  1.81s/it] 45%|████▍     | 1173/2628 [54:44<43:56,  1.81s/it] 45%|████▍     | 1174/2628 [54:46<43:57,  1.81s/it] 45%|████▍     | 1175/2628 [54:48<43:50,  1.81s/it] 45%|████▍     | 1176/2628 [54:50<43:44,  1.81s/it] 45%|████▍     | 1177/2628 [54:52<43:46,  1.81s/it] 45%|████▍     | 1178/2628 [54:53<43:48,  1.81s/it] 45%|████▍     | 1179/2628 [54:55<43:43,  1.81s/it] 45%|████▍     | 1180/2628 [54:57<43:36,  1.81s/it]                                                    45%|████▍     | 1180/2628 [54:57<43:36,  1.81s/it] 45%|████▍     | 1181/2628 [54:59<43:40,  1.81s/it] 45%|████▍     | 1182/2628 [55:01<43:37,  1.81s/it] 45%|████▌     | 1183/2628 [55:02<43:35,  1.81s/it] 45%|████▌     | 1184/2628 [55:04<43:31,  1.81s/it] 45%|████▌     | 1185/2628 [55:06<43:33,  1.81s/it] 45%|████▌     | 1186/2628 [55:08<43:33,  1.81s/it] 45%|████▌     | 1187/2628 [55:10<43:30,  1.81s/it] 45%|████▌     | 1188/2628 [55:11<43:30,  1.81s/it] 45%|████▌     | 1189/2628 [55:13<43:24,  1.81s/it] 45%|████▌     | 1190/2628 [55:15<43:17,  1.81s/it]                                                    45%|████▌     | 1190/2628 [55:15<43:17,  1.81s/it] 45%|████▌     | 1191/2628 [55:17<43:22,  1.81s/it] 45%|████▌     | 1192/2628 [55:19<43:15,  1.81s/it] 45%|████▌     | 1193/2628 [55:21<43:10,  1.81s/it] 45%|████▌     | 1194/2628 [55:22<43:06,  1.80s/it] 45%|████▌     | 1195/2628 [55:24<43:07,  1.81s/it] 46%|████▌     | 1196/2628 [55:26<43:03,  1.80s/it] 46%|████▌     | 1197/2628 [55:28<42:59,  1.80s/it] 46%|████▌     | 1198/2628 [55:30<42:56,  1.80s/it] 46%|████▌     | 1199/2628 [55:31<42:53,  1.80s/it] 46%|████▌     | 1200/2628 [55:33<42:56,  1.80s/it]                                                    46%|████▌     | 1200/2628 [55:33<42:56,  1.80s/it][INFO|trainer.py:4643] 2025-10-21 17:51:58,465 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 17:51:58,465 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 17:51:58,465 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:51:58,954 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:52:56,020 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:58<00:29, 29.25s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:53:54,574 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [01:56<00:00, 41.30s/it][A                                                   
                                             [A 46%|████▌     | 1200/2628 [58:28<42:56,  1.80s/it]
100%|██████████| 3/3 [01:56<00:00, 41.30s/it][A
                                             [A 46%|████▌     | 1201/2628 [58:29<21:28:22, 54.17s/it] 46%|████▌     | 1202/2628 [58:31<15:14:11, 38.47s/it] 46%|████▌     | 1203/2628 [58:33<10:52:24, 27.47s/it] 46%|████▌     | 1204/2628 [58:35<7:49:12, 19.77s/it]  46%|████▌     | 1205/2628 [58:37<5:41:02, 14.38s/it] 46%|████▌     | 1206/2628 [58:39<4:11:20, 10.60s/it] 46%|████▌     | 1207/2628 [58:40<3:08:43,  7.97s/it] 46%|████▌     | 1208/2628 [58:42<2:24:46,  6.12s/it] 46%|████▌     | 1209/2628 [58:44<1:54:01,  4.82s/it] 46%|████▌     | 1210/2628 [58:46<1:32:31,  3.92s/it]                                                      46%|████▌     | 1210/2628 [58:46<1:32:31,  3.92s/it] 46%|████▌     | 1211/2628 [58:48<1:17:28,  3.28s/it] 46%|████▌     | 1212/2628 [58:49<1:06:56,  2.84s/it] 46%|████▌     | 1213/2628 [58:51<59:33,  2.53s/it]   46%|████▌     | 1214/2628 [58:53<54:26,  2.31s/it] 46%|████▌     | 1215/2628 [58:55<50:47,  2.16s/it] 46%|████▋     | 1216/2628 [58:57<48:12,  2.05s/it] 46%|████▋     | 1217/2628 [58:58<46:24,  1.97s/it] 46%|████▋     | 1218/2628 [59:00<45:14,  1.93s/it] 46%|████▋     | 1219/2628 [59:02<44:18,  1.89s/it] 46%|████▋     | 1220/2628 [59:04<43:40,  1.86s/it]                                                    46%|████▋     | 1220/2628 [59:04<43:40,  1.86s/it] 46%|████▋     | 1221/2628 [59:06<43:14,  1.84s/it] 46%|████▋     | 1222/2628 [59:07<43:02,  1.84s/it] 47%|████▋     | 1223/2628 [59:09<42:54,  1.83s/it] 47%|████▋     | 1224/2628 [59:11<42:45,  1.83s/it] 47%|████▋     | 1225/2628 [59:13<42:32,  1.82s/it] 47%|████▋     | 1226/2628 [59:15<42:22,  1.81s/it] 47%|████▋     | 1227/2628 [59:16<42:13,  1.81s/it] 47%|████▋     | 1228/2628 [59:18<42:08,  1.81s/it] 47%|████▋     | 1229/2628 [59:20<42:03,  1.80s/it] 47%|████▋     | 1230/2628 [59:22<42:02,  1.80s/it]                                                    47%|████▋     | 1230/2628 [59:22<42:02,  1.80s/it] 47%|████▋     | 1231/2628 [59:24<41:59,  1.80s/it] 47%|████▋     | 1232/2628 [59:25<41:58,  1.80s/it] 47%|████▋     | 1233/2628 [59:27<42:01,  1.81s/it] 47%|████▋     | 1234/2628 [59:29<41:58,  1.81s/it] 47%|████▋     | 1235/2628 [59:31<42:00,  1.81s/it] 47%|████▋     | 1236/2628 [59:33<41:53,  1.81s/it] 47%|████▋     | 1237/2628 [59:34<41:50,  1.80s/it] 47%|████▋     | 1238/2628 [59:36<41:51,  1.81s/it] 47%|████▋     | 1239/2628 [59:38<41:53,  1.81s/it] 47%|████▋     | 1240/2628 [59:40<41:47,  1.81s/it]                                                    47%|████▋     | 1240/2628 [59:40<41:47,  1.81s/it] 47%|████▋     | 1241/2628 [59:42<41:48,  1.81s/it] 47%|████▋     | 1242/2628 [59:43<41:41,  1.81s/it] 47%|████▋     | 1243/2628 [59:45<41:41,  1.81s/it] 47%|████▋     | 1244/2628 [59:47<41:37,  1.80s/it] 47%|████▋     | 1245/2628 [59:49<41:38,  1.81s/it] 47%|████▋     | 1246/2628 [59:51<41:38,  1.81s/it] 47%|████▋     | 1247/2628 [59:53<41:33,  1.81s/it] 47%|████▋     | 1248/2628 [59:54<41:35,  1.81s/it] 48%|████▊     | 1249/2628 [59:56<41:37,  1.81s/it] 48%|████▊     | 1250/2628 [59:58<41:34,  1.81s/it]                                                    48%|████▊     | 1250/2628 [59:58<41:34,  1.81s/it] 48%|████▊     | 1251/2628 [1:00:00<41:30,  1.81s/it] 48%|████▊     | 1252/2628 [1:00:02<41:25,  1.81s/it] 48%|████▊     | 1253/2628 [1:00:03<41:19,  1.80s/it] 48%|████▊     | 1254/2628 [1:00:05<41:19,  1.80s/it] 48%|████▊     | 1255/2628 [1:00:07<41:21,  1.81s/it] 48%|████▊     | 1256/2628 [1:00:09<41:18,  1.81s/it] 48%|████▊     | 1257/2628 [1:00:11<41:23,  1.81s/it] 48%|████▊     | 1258/2628 [1:00:12<41:21,  1.81s/it] 48%|████▊     | 1259/2628 [1:00:14<41:13,  1.81s/it] 48%|████▊     | 1260/2628 [1:00:16<41:09,  1.81s/it]                                                      48%|████▊     | 1260/2628 [1:00:16<41:09,  1.81s/it] 48%|████▊     | 1261/2628 [1:00:18<41:10,  1.81s/it] 48%|████▊     | 1262/2628 [1:00:20<41:05,  1.80s/it] 48%|████▊     | 1263/2628 [1:00:21<41:01,  1.80s/it] 48%|████▊     | 1264/2628 [1:00:23<40:59,  1.80s/it] 48%|████▊     | 1265/2628 [1:00:25<40:58,  1.80s/it] 48%|████▊     | 1266/2628 [1:00:27<40:56,  1.80s/it] 48%|████▊     | 1267/2628 [1:00:29<40:52,  1.80s/it] 48%|████▊     | 1268/2628 [1:00:30<40:50,  1.80s/it] 48%|████▊     | 1269/2628 [1:00:32<40:48,  1.80s/it] 48%|████▊     | 1270/2628 [1:00:34<40:51,  1.81s/it]                                                      48%|████▊     | 1270/2628 [1:00:34<40:51,  1.81s/it] 48%|████▊     | 1271/2628 [1:00:36<40:50,  1.81s/it] 48%|████▊     | 1272/2628 [1:00:38<40:47,  1.80s/it] 48%|████▊     | 1273/2628 [1:00:39<40:52,  1.81s/it] 48%|████▊     | 1274/2628 [1:00:41<40:52,  1.81s/it] 49%|████▊     | 1275/2628 [1:00:43<40:45,  1.81s/it] 49%|████▊     | 1276/2628 [1:00:45<40:46,  1.81s/it] 49%|████▊     | 1277/2628 [1:00:47<40:51,  1.81s/it] 49%|████▊     | 1278/2628 [1:00:49<40:42,  1.81s/it] 49%|████▊     | 1279/2628 [1:00:50<40:42,  1.81s/it] 49%|████▊     | 1280/2628 [1:00:52<40:43,  1.81s/it]                                                      49%|████▊     | 1280/2628 [1:00:52<40:43,  1.81s/it] 49%|████▊     | 1281/2628 [1:00:54<40:41,  1.81s/it] 49%|████▉     | 1282/2628 [1:00:56<40:32,  1.81s/it] 49%|████▉     | 1283/2628 [1:00:58<40:33,  1.81s/it] 49%|████▉     | 1284/2628 [1:00:59<40:29,  1.81s/it] 49%|████▉     | 1285/2628 [1:01:01<40:27,  1.81s/it] 49%|████▉     | 1286/2628 [1:01:03<40:23,  1.81s/it] 49%|████▉     | 1287/2628 [1:01:05<40:19,  1.80s/it] 49%|████▉     | 1288/2628 [1:01:07<40:15,  1.80s/it] 49%|████▉     | 1289/2628 [1:01:08<40:13,  1.80s/it] 49%|████▉     | 1290/2628 [1:01:10<40:11,  1.80s/it]                                                      49%|████▉     | 1290/2628 [1:01:10<40:11,  1.80s/it] 49%|████▉     | 1291/2628 [1:01:12<40:14,  1.81s/it] 49%|████▉     | 1292/2628 [1:01:14<40:10,  1.80s/it] 49%|████▉     | 1293/2628 [1:01:16<40:13,  1.81s/it] 49%|████▉     | 1294/2628 [1:01:17<40:07,  1.80s/it] 49%|████▉     | 1295/2628 [1:01:19<40:05,  1.80s/it] 49%|████▉     | 1296/2628 [1:01:21<40:01,  1.80s/it] 49%|████▉     | 1297/2628 [1:01:23<40:00,  1.80s/it] 49%|████▉     | 1298/2628 [1:01:25<39:57,  1.80s/it] 49%|████▉     | 1299/2628 [1:01:26<40:03,  1.81s/it] 49%|████▉     | 1300/2628 [1:01:28<39:59,  1.81s/it]                                                      49%|████▉     | 1300/2628 [1:01:28<39:59,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 17:57:53,611 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 17:57:53,611 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 17:57:53,611 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:57:54,082 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:57:59,178 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:05<00:02,  2.63s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 17:58:04,511 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [01:02<00:00, 25.22s/it][A                                                     
                                             [A 49%|████▉     | 1300/2628 [1:02:36<39:59,  1.81s/it]
100%|██████████| 3/3 [01:02<00:00, 25.22s/it][A
                                             [A 50%|████▉     | 1301/2628 [1:02:38<8:10:25, 22.17s/it] 50%|████▉     | 1302/2628 [1:02:40<5:54:57, 16.06s/it] 50%|████▉     | 1303/2628 [1:02:42<4:20:10, 11.78s/it] 50%|████▉     | 1304/2628 [1:02:43<3:13:58,  8.79s/it] 50%|████▉     | 1305/2628 [1:02:45<2:27:43,  6.70s/it] 50%|████▉     | 1306/2628 [1:02:47<1:55:14,  5.23s/it] 50%|████▉     | 1307/2628 [1:02:49<1:32:29,  4.20s/it] 50%|████▉     | 1308/2628 [1:02:51<1:16:34,  3.48s/it] 50%|████▉     | 1309/2628 [1:02:52<1:05:26,  2.98s/it] 50%|████▉     | 1310/2628 [1:02:54<57:37,  2.62s/it]                                                        50%|████▉     | 1310/2628 [1:02:54<57:37,  2.62s/it] 50%|████▉     | 1311/2628 [1:02:56<52:09,  2.38s/it] 50%|████▉     | 1312/2628 [1:02:58<48:27,  2.21s/it] 50%|████▉     | 1313/2628 [1:03:00<45:45,  2.09s/it] 50%|█████     | 1314/2628 [1:03:01<43:49,  2.00s/it] 50%|█████     | 1315/2628 [1:03:03<42:25,  1.94s/it] 50%|█████     | 1316/2628 [1:03:05<41:37,  1.90s/it] 50%|█████     | 1317/2628 [1:03:07<40:54,  1.87s/it] 50%|█████     | 1318/2628 [1:03:09<40:24,  1.85s/it] 50%|█████     | 1319/2628 [1:03:10<40:01,  1.83s/it] 50%|█████     | 1320/2628 [1:03:12<39:50,  1.83s/it]                                                      50%|█████     | 1320/2628 [1:03:12<39:50,  1.83s/it] 50%|█████     | 1321/2628 [1:03:14<39:45,  1.83s/it] 50%|█████     | 1322/2628 [1:03:16<39:34,  1.82s/it] 50%|█████     | 1323/2628 [1:03:18<39:31,  1.82s/it] 50%|█████     | 1324/2628 [1:03:19<39:26,  1.82s/it] 50%|█████     | 1325/2628 [1:03:21<39:19,  1.81s/it] 50%|█████     | 1326/2628 [1:03:23<39:18,  1.81s/it] 50%|█████     | 1327/2628 [1:03:25<39:17,  1.81s/it] 51%|█████     | 1328/2628 [1:03:27<39:17,  1.81s/it] 51%|█████     | 1329/2628 [1:03:29<39:12,  1.81s/it] 51%|█████     | 1330/2628 [1:03:30<39:10,  1.81s/it]                                                      51%|█████     | 1330/2628 [1:03:30<39:10,  1.81s/it] 51%|█████     | 1331/2628 [1:03:32<39:10,  1.81s/it] 51%|█████     | 1332/2628 [1:03:34<39:03,  1.81s/it] 51%|█████     | 1333/2628 [1:03:36<38:58,  1.81s/it] 51%|█████     | 1334/2628 [1:03:38<38:54,  1.80s/it] 51%|█████     | 1335/2628 [1:03:39<38:55,  1.81s/it] 51%|█████     | 1336/2628 [1:03:41<38:51,  1.80s/it] 51%|█████     | 1337/2628 [1:03:43<38:47,  1.80s/it] 51%|█████     | 1338/2628 [1:03:45<38:45,  1.80s/it] 51%|█████     | 1339/2628 [1:03:47<38:45,  1.80s/it] 51%|█████     | 1340/2628 [1:03:48<38:43,  1.80s/it]                                                      51%|█████     | 1340/2628 [1:03:48<38:43,  1.80s/it] 51%|█████     | 1341/2628 [1:03:50<38:48,  1.81s/it] 51%|█████     | 1342/2628 [1:03:52<38:49,  1.81s/it] 51%|█████     | 1343/2628 [1:03:54<38:45,  1.81s/it] 51%|█████     | 1344/2628 [1:03:56<38:43,  1.81s/it] 51%|█████     | 1345/2628 [1:03:57<38:40,  1.81s/it] 51%|█████     | 1346/2628 [1:03:59<38:36,  1.81s/it] 51%|█████▏    | 1347/2628 [1:04:01<38:37,  1.81s/it] 51%|█████▏    | 1348/2628 [1:04:03<38:38,  1.81s/it] 51%|█████▏    | 1349/2628 [1:04:05<40:51,  1.92s/it] 51%|█████▏    | 1350/2628 [1:04:07<40:08,  1.88s/it]                                                      51%|█████▏    | 1350/2628 [1:04:07<40:08,  1.88s/it] 51%|█████▏    | 1351/2628 [1:04:09<39:34,  1.86s/it] 51%|█████▏    | 1352/2628 [1:04:10<39:10,  1.84s/it] 51%|█████▏    | 1353/2628 [1:04:12<38:59,  1.84s/it] 52%|█████▏    | 1354/2628 [1:04:14<38:44,  1.82s/it] 52%|█████▏    | 1355/2628 [1:04:16<38:35,  1.82s/it] 52%|█████▏    | 1356/2628 [1:04:18<38:27,  1.81s/it] 52%|█████▏    | 1357/2628 [1:04:19<38:20,  1.81s/it] 52%|█████▏    | 1358/2628 [1:04:21<38:13,  1.81s/it] 52%|█████▏    | 1359/2628 [1:04:23<38:10,  1.80s/it] 52%|█████▏    | 1360/2628 [1:04:25<38:06,  1.80s/it]                                                      52%|█████▏    | 1360/2628 [1:04:25<38:06,  1.80s/it] 52%|█████▏    | 1361/2628 [1:04:27<38:03,  1.80s/it] 52%|█████▏    | 1362/2628 [1:04:28<37:59,  1.80s/it] 52%|█████▏    | 1363/2628 [1:04:30<37:56,  1.80s/it] 52%|█████▏    | 1364/2628 [1:04:32<37:54,  1.80s/it] 52%|█████▏    | 1365/2628 [1:04:34<37:59,  1.81s/it] 52%|█████▏    | 1366/2628 [1:04:36<37:58,  1.81s/it] 52%|█████▏    | 1367/2628 [1:04:38<37:59,  1.81s/it] 52%|█████▏    | 1368/2628 [1:04:39<37:54,  1.80s/it] 52%|█████▏    | 1369/2628 [1:04:41<37:50,  1.80s/it] 52%|█████▏    | 1370/2628 [1:04:43<37:46,  1.80s/it]                                                      52%|█████▏    | 1370/2628 [1:04:43<37:46,  1.80s/it] 52%|█████▏    | 1371/2628 [1:04:45<37:43,  1.80s/it] 52%|█████▏    | 1372/2628 [1:04:47<37:48,  1.81s/it] 52%|█████▏    | 1373/2628 [1:04:48<37:44,  1.80s/it] 52%|█████▏    | 1374/2628 [1:04:50<37:48,  1.81s/it] 52%|█████▏    | 1375/2628 [1:04:52<37:48,  1.81s/it] 52%|█████▏    | 1376/2628 [1:04:54<37:45,  1.81s/it] 52%|█████▏    | 1377/2628 [1:04:56<37:40,  1.81s/it] 52%|█████▏    | 1378/2628 [1:04:57<37:42,  1.81s/it] 52%|█████▏    | 1379/2628 [1:04:59<37:37,  1.81s/it] 53%|█████▎    | 1380/2628 [1:05:01<37:34,  1.81s/it]                                                      53%|█████▎    | 1380/2628 [1:05:01<37:34,  1.81s/it] 53%|█████▎    | 1381/2628 [1:05:03<37:31,  1.81s/it] 53%|█████▎    | 1382/2628 [1:05:05<37:27,  1.80s/it] 53%|█████▎    | 1383/2628 [1:05:06<37:29,  1.81s/it] 53%|█████▎    | 1384/2628 [1:05:08<37:33,  1.81s/it] 53%|█████▎    | 1385/2628 [1:05:10<37:33,  1.81s/it] 53%|█████▎    | 1386/2628 [1:05:12<37:26,  1.81s/it] 53%|█████▎    | 1387/2628 [1:05:14<37:20,  1.81s/it] 53%|█████▎    | 1388/2628 [1:05:15<37:18,  1.80s/it] 53%|█████▎    | 1389/2628 [1:05:17<37:15,  1.80s/it] 53%|█████▎    | 1390/2628 [1:05:19<37:11,  1.80s/it]                                                      53%|█████▎    | 1390/2628 [1:05:19<37:11,  1.80s/it] 53%|█████▎    | 1391/2628 [1:05:21<37:09,  1.80s/it] 53%|█████▎    | 1392/2628 [1:05:23<37:08,  1.80s/it] 53%|█████▎    | 1393/2628 [1:05:24<37:05,  1.80s/it] 53%|█████▎    | 1394/2628 [1:05:26<37:03,  1.80s/it] 53%|█████▎    | 1395/2628 [1:05:28<37:01,  1.80s/it] 53%|█████▎    | 1396/2628 [1:05:30<37:00,  1.80s/it] 53%|█████▎    | 1397/2628 [1:05:32<36:57,  1.80s/it] 53%|█████▎    | 1398/2628 [1:05:33<37:00,  1.81s/it] 53%|█████▎    | 1399/2628 [1:05:35<37:04,  1.81s/it] 53%|█████▎    | 1400/2628 [1:05:37<37:05,  1.81s/it]                                                      53%|█████▎    | 1400/2628 [1:05:37<37:05,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 18:02:02,451 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 18:02:02,451 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 18:02:02,451 >>   Batch size = 8
[WARNING|utils.py:2443] 2025-10-21 18:02:02,926 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:02:59,165 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:03<00:01,  1.68s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:03:02,610 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:06<00:00,  2.41s/it][A                                                     
                                             [A 53%|█████▎    | 1400/2628 [1:06:41<37:05,  1.81s/it]
100%|██████████| 3/3 [00:06<00:00,  2.41s/it][A
                                             [A 53%|█████▎    | 1401/2628 [1:06:43<7:07:40, 20.91s/it] 53%|█████▎    | 1402/2628 [1:06:44<5:10:12, 15.18s/it] 53%|█████▎    | 1403/2628 [1:06:46<3:47:59, 11.17s/it] 53%|█████▎    | 1404/2628 [1:06:48<2:50:31,  8.36s/it] 53%|█████▎    | 1405/2628 [1:06:50<2:10:23,  6.40s/it] 54%|█████▎    | 1406/2628 [1:06:52<1:42:11,  5.02s/it] 54%|█████▎    | 1407/2628 [1:06:53<1:22:27,  4.05s/it] 54%|█████▎    | 1408/2628 [1:06:55<1:08:40,  3.38s/it] 54%|█████▎    | 1409/2628 [1:06:57<58:59,  2.90s/it]   54%|█████▎    | 1410/2628 [1:06:59<52:12,  2.57s/it]                                                      54%|█████▎    | 1410/2628 [1:06:59<52:12,  2.57s/it] 54%|█████▎    | 1411/2628 [1:07:01<47:28,  2.34s/it] 54%|█████▎    | 1412/2628 [1:07:02<44:09,  2.18s/it] 54%|█████▍    | 1413/2628 [1:07:04<41:50,  2.07s/it] 54%|█████▍    | 1414/2628 [1:07:06<40:15,  1.99s/it] 54%|█████▍    | 1415/2628 [1:07:08<39:10,  1.94s/it] 54%|█████▍    | 1416/2628 [1:07:10<38:18,  1.90s/it] 54%|█████▍    | 1417/2628 [1:07:11<37:44,  1.87s/it] 54%|█████▍    | 1418/2628 [1:07:13<37:22,  1.85s/it] 54%|█████▍    | 1419/2628 [1:07:15<37:06,  1.84s/it] 54%|█████▍    | 1420/2628 [1:07:17<36:53,  1.83s/it]                                                      54%|█████▍    | 1420/2628 [1:07:17<36:53,  1.83s/it] 54%|█████▍    | 1421/2628 [1:07:19<36:45,  1.83s/it] 54%|█████▍    | 1422/2628 [1:07:21<36:33,  1.82s/it] 54%|█████▍    | 1423/2628 [1:07:22<36:25,  1.81s/it] 54%|█████▍    | 1424/2628 [1:07:24<36:19,  1.81s/it] 54%|█████▍    | 1425/2628 [1:07:26<36:21,  1.81s/it] 54%|█████▍    | 1426/2628 [1:07:28<36:14,  1.81s/it] 54%|█████▍    | 1427/2628 [1:07:30<36:16,  1.81s/it] 54%|█████▍    | 1428/2628 [1:07:31<36:10,  1.81s/it] 54%|█████▍    | 1429/2628 [1:07:33<36:08,  1.81s/it] 54%|█████▍    | 1430/2628 [1:07:35<36:04,  1.81s/it]                                                      54%|█████▍    | 1430/2628 [1:07:35<36:04,  1.81s/it] 54%|█████▍    | 1431/2628 [1:07:37<36:00,  1.81s/it] 54%|█████▍    | 1432/2628 [1:07:39<35:56,  1.80s/it] 55%|█████▍    | 1433/2628 [1:07:40<35:59,  1.81s/it] 55%|█████▍    | 1434/2628 [1:07:42<35:55,  1.81s/it] 55%|█████▍    | 1435/2628 [1:07:44<35:58,  1.81s/it] 55%|█████▍    | 1436/2628 [1:07:46<35:53,  1.81s/it] 55%|█████▍    | 1437/2628 [1:07:48<35:51,  1.81s/it] 55%|█████▍    | 1438/2628 [1:07:49<35:46,  1.80s/it] 55%|█████▍    | 1439/2628 [1:07:51<35:48,  1.81s/it] 55%|█████▍    | 1440/2628 [1:07:53<35:47,  1.81s/it]                                                      55%|█████▍    | 1440/2628 [1:07:53<35:47,  1.81s/it] 55%|█████▍    | 1441/2628 [1:07:55<35:45,  1.81s/it] 55%|█████▍    | 1442/2628 [1:07:57<35:40,  1.81s/it] 55%|█████▍    | 1443/2628 [1:07:58<35:37,  1.80s/it] 55%|█████▍    | 1444/2628 [1:08:00<35:34,  1.80s/it] 55%|█████▍    | 1445/2628 [1:08:02<35:33,  1.80s/it] 55%|█████▌    | 1446/2628 [1:08:04<35:30,  1.80s/it] 55%|█████▌    | 1447/2628 [1:08:06<35:27,  1.80s/it] 55%|█████▌    | 1448/2628 [1:08:07<35:24,  1.80s/it] 55%|█████▌    | 1449/2628 [1:08:09<35:26,  1.80s/it] 55%|█████▌    | 1450/2628 [1:08:11<35:23,  1.80s/it]                                                      55%|█████▌    | 1450/2628 [1:08:11<35:23,  1.80s/it] 55%|█████▌    | 1451/2628 [1:08:13<35:20,  1.80s/it] 55%|█████▌    | 1452/2628 [1:08:15<35:25,  1.81s/it] 55%|█████▌    | 1453/2628 [1:08:16<35:24,  1.81s/it] 55%|█████▌    | 1454/2628 [1:08:18<35:20,  1.81s/it] 55%|█████▌    | 1455/2628 [1:08:20<35:15,  1.80s/it] 55%|█████▌    | 1456/2628 [1:08:22<35:17,  1.81s/it] 55%|█████▌    | 1457/2628 [1:08:24<35:17,  1.81s/it] 55%|█████▌    | 1458/2628 [1:08:26<35:12,  1.81s/it] 56%|█████▌    | 1459/2628 [1:08:27<35:13,  1.81s/it] 56%|█████▌    | 1460/2628 [1:08:29<35:09,  1.81s/it]                                                      56%|█████▌    | 1460/2628 [1:08:29<35:09,  1.81s/it] 56%|█████▌    | 1461/2628 [1:08:31<35:08,  1.81s/it] 56%|█████▌    | 1462/2628 [1:08:33<35:03,  1.80s/it] 56%|█████▌    | 1463/2628 [1:08:35<34:59,  1.80s/it] 56%|█████▌    | 1464/2628 [1:08:36<34:59,  1.80s/it] 56%|█████▌    | 1465/2628 [1:08:38<35:01,  1.81s/it] 56%|█████▌    | 1466/2628 [1:08:40<34:57,  1.81s/it] 56%|█████▌    | 1467/2628 [1:08:42<34:53,  1.80s/it] 56%|█████▌    | 1468/2628 [1:08:44<34:51,  1.80s/it] 56%|█████▌    | 1469/2628 [1:08:45<34:52,  1.81s/it] 56%|█████▌    | 1470/2628 [1:08:47<34:48,  1.80s/it]                                                      56%|█████▌    | 1470/2628 [1:08:47<34:48,  1.80s/it] 56%|█████▌    | 1471/2628 [1:08:49<34:51,  1.81s/it] 56%|█████▌    | 1472/2628 [1:08:51<34:48,  1.81s/it] 56%|█████▌    | 1473/2628 [1:08:53<34:48,  1.81s/it] 56%|█████▌    | 1474/2628 [1:08:54<34:48,  1.81s/it] 56%|█████▌    | 1475/2628 [1:08:56<34:43,  1.81s/it] 56%|█████▌    | 1476/2628 [1:08:58<34:40,  1.81s/it] 56%|█████▌    | 1477/2628 [1:09:00<34:46,  1.81s/it] 56%|█████▌    | 1478/2628 [1:09:02<34:38,  1.81s/it] 56%|█████▋    | 1479/2628 [1:09:03<34:40,  1.81s/it] 56%|█████▋    | 1480/2628 [1:09:05<34:39,  1.81s/it]                                                      56%|█████▋    | 1480/2628 [1:09:05<34:39,  1.81s/it] 56%|█████▋    | 1481/2628 [1:09:07<34:39,  1.81s/it] 56%|█████▋    | 1482/2628 [1:09:09<34:34,  1.81s/it] 56%|█████▋    | 1483/2628 [1:09:11<34:29,  1.81s/it] 56%|█████▋    | 1484/2628 [1:09:12<34:24,  1.81s/it] 57%|█████▋    | 1485/2628 [1:09:14<34:25,  1.81s/it] 57%|█████▋    | 1486/2628 [1:09:16<34:19,  1.80s/it] 57%|█████▋    | 1487/2628 [1:09:18<34:21,  1.81s/it] 57%|█████▋    | 1488/2628 [1:09:20<34:23,  1.81s/it] 57%|█████▋    | 1489/2628 [1:09:22<34:25,  1.81s/it] 57%|█████▋    | 1490/2628 [1:09:23<34:19,  1.81s/it]                                                      57%|█████▋    | 1490/2628 [1:09:23<34:19,  1.81s/it] 57%|█████▋    | 1491/2628 [1:09:25<34:20,  1.81s/it] 57%|█████▋    | 1492/2628 [1:09:27<34:15,  1.81s/it] 57%|█████▋    | 1493/2628 [1:09:29<34:16,  1.81s/it] 57%|█████▋    | 1494/2628 [1:09:31<34:11,  1.81s/it] 57%|█████▋    | 1495/2628 [1:09:32<34:07,  1.81s/it] 57%|█████▋    | 1496/2628 [1:09:34<34:03,  1.81s/it] 57%|█████▋    | 1497/2628 [1:09:36<34:07,  1.81s/it] 57%|█████▋    | 1498/2628 [1:09:38<34:03,  1.81s/it] 57%|█████▋    | 1499/2628 [1:09:40<33:59,  1.81s/it] 57%|█████▋    | 1500/2628 [1:09:41<33:56,  1.81s/it]                                                      57%|█████▋    | 1500/2628 [1:09:41<33:56,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 18:06:06,766 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 18:06:06,766 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 18:06:06,766 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:06:07,242 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:07:04,200 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:56<00:28, 28.11s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:08:00,487 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [01:01<00:00, 18.63s/it][A                                                     
                                             [A 57%|█████▋    | 1500/2628 [1:11:41<33:56,  1.81s/it]
100%|██████████| 3/3 [01:01<00:00, 18.63s/it][A
                                             [A 57%|█████▋    | 1501/2628 [1:11:42<11:45:45, 37.57s/it] 57%|█████▋    | 1502/2628 [1:11:44<8:23:43, 26.84s/it]  57%|█████▋    | 1503/2628 [1:11:46<6:02:24, 19.33s/it] 57%|█████▋    | 1504/2628 [1:11:48<4:23:38, 14.07s/it] 57%|█████▋    | 1505/2628 [1:11:50<3:14:31, 10.39s/it] 57%|█████▋    | 1506/2628 [1:11:51<2:26:08,  7.82s/it] 57%|█████▋    | 1507/2628 [1:11:53<1:52:17,  6.01s/it] 57%|█████▋    | 1508/2628 [1:11:55<1:28:36,  4.75s/it] 57%|█████▋    | 1509/2628 [1:11:57<1:12:08,  3.87s/it] 57%|█████▋    | 1510/2628 [1:11:59<1:00:31,  3.25s/it]                                                        57%|█████▋    | 1510/2628 [1:11:59<1:00:31,  3.25s/it] 57%|█████▋    | 1511/2628 [1:12:00<52:23,  2.81s/it]   58%|█████▊    | 1512/2628 [1:12:02<46:45,  2.51s/it] 58%|█████▊    | 1513/2628 [1:12:04<42:46,  2.30s/it] 58%|█████▊    | 1514/2628 [1:12:06<40:01,  2.16s/it] 58%|█████▊    | 1515/2628 [1:12:08<38:00,  2.05s/it] 58%|█████▊    | 1516/2628 [1:12:10<36:35,  1.97s/it] 58%|█████▊    | 1517/2628 [1:12:11<35:46,  1.93s/it] 58%|█████▊    | 1518/2628 [1:12:13<35:01,  1.89s/it] 58%|█████▊    | 1519/2628 [1:12:15<34:30,  1.87s/it] 58%|█████▊    | 1520/2628 [1:12:17<34:06,  1.85s/it]                                                      58%|█████▊    | 1520/2628 [1:12:17<34:06,  1.85s/it] 58%|█████▊    | 1521/2628 [1:12:19<33:59,  1.84s/it] 58%|█████▊    | 1522/2628 [1:12:20<33:43,  1.83s/it] 58%|█████▊    | 1523/2628 [1:12:22<33:32,  1.82s/it] 58%|█████▊    | 1524/2628 [1:12:24<33:24,  1.82s/it] 58%|█████▊    | 1525/2628 [1:12:26<33:21,  1.81s/it] 58%|█████▊    | 1526/2628 [1:12:28<33:15,  1.81s/it] 58%|█████▊    | 1527/2628 [1:12:29<33:15,  1.81s/it] 58%|█████▊    | 1528/2628 [1:12:31<33:14,  1.81s/it] 58%|█████▊    | 1529/2628 [1:12:33<33:12,  1.81s/it] 58%|█████▊    | 1530/2628 [1:12:35<33:06,  1.81s/it]                                                      58%|█████▊    | 1530/2628 [1:12:35<33:06,  1.81s/it] 58%|█████▊    | 1531/2628 [1:12:37<33:09,  1.81s/it] 58%|█████▊    | 1532/2628 [1:12:38<33:03,  1.81s/it] 58%|█████▊    | 1533/2628 [1:12:41<34:47,  1.91s/it] 58%|█████▊    | 1534/2628 [1:12:42<34:09,  1.87s/it] 58%|█████▊    | 1535/2628 [1:12:44<33:44,  1.85s/it] 58%|█████▊    | 1536/2628 [1:12:46<33:26,  1.84s/it] 58%|█████▊    | 1537/2628 [1:12:48<33:15,  1.83s/it] 59%|█████▊    | 1538/2628 [1:12:50<33:10,  1.83s/it] 59%|█████▊    | 1539/2628 [1:12:51<33:04,  1.82s/it] 59%|█████▊    | 1540/2628 [1:12:53<32:56,  1.82s/it]                                                      59%|█████▊    | 1540/2628 [1:12:53<32:56,  1.82s/it] 59%|█████▊    | 1541/2628 [1:12:55<32:50,  1.81s/it] 59%|█████▊    | 1542/2628 [1:12:57<32:44,  1.81s/it] 59%|█████▊    | 1543/2628 [1:12:59<32:40,  1.81s/it] 59%|█████▉    | 1544/2628 [1:13:00<32:37,  1.81s/it] 59%|█████▉    | 1545/2628 [1:13:02<32:33,  1.80s/it] 59%|█████▉    | 1546/2628 [1:13:04<32:31,  1.80s/it] 59%|█████▉    | 1547/2628 [1:13:06<32:28,  1.80s/it] 59%|█████▉    | 1548/2628 [1:13:08<32:30,  1.81s/it] 59%|█████▉    | 1549/2628 [1:13:10<32:35,  1.81s/it] 59%|█████▉    | 1550/2628 [1:13:11<32:29,  1.81s/it]                                                      59%|█████▉    | 1550/2628 [1:13:11<32:29,  1.81s/it] 59%|█████▉    | 1551/2628 [1:13:13<32:31,  1.81s/it] 59%|█████▉    | 1552/2628 [1:13:15<32:33,  1.82s/it] 59%|█████▉    | 1553/2628 [1:13:17<32:36,  1.82s/it] 59%|█████▉    | 1554/2628 [1:13:19<32:33,  1.82s/it] 59%|█████▉    | 1555/2628 [1:13:20<32:30,  1.82s/it] 59%|█████▉    | 1556/2628 [1:13:22<32:25,  1.81s/it] 59%|█████▉    | 1557/2628 [1:13:24<32:22,  1.81s/it] 59%|█████▉    | 1558/2628 [1:13:26<32:17,  1.81s/it] 59%|█████▉    | 1559/2628 [1:13:28<32:18,  1.81s/it] 59%|█████▉    | 1560/2628 [1:13:29<32:18,  1.81s/it]                                                      59%|█████▉    | 1560/2628 [1:13:29<32:18,  1.81s/it] 59%|█████▉    | 1561/2628 [1:13:31<32:16,  1.82s/it] 59%|█████▉    | 1562/2628 [1:13:33<32:10,  1.81s/it] 59%|█████▉    | 1563/2628 [1:13:35<32:11,  1.81s/it] 60%|█████▉    | 1564/2628 [1:13:37<32:06,  1.81s/it] 60%|█████▉    | 1565/2628 [1:13:39<32:03,  1.81s/it] 60%|█████▉    | 1566/2628 [1:13:40<31:59,  1.81s/it] 60%|█████▉    | 1567/2628 [1:13:42<31:56,  1.81s/it] 60%|█████▉    | 1568/2628 [1:13:44<31:53,  1.81s/it] 60%|█████▉    | 1569/2628 [1:13:46<31:53,  1.81s/it] 60%|█████▉    | 1570/2628 [1:13:48<31:50,  1.81s/it]                                                      60%|█████▉    | 1570/2628 [1:13:48<31:50,  1.81s/it] 60%|█████▉    | 1571/2628 [1:13:49<31:47,  1.80s/it] 60%|█████▉    | 1572/2628 [1:13:51<31:45,  1.80s/it] 60%|█████▉    | 1573/2628 [1:13:53<31:45,  1.81s/it] 60%|█████▉    | 1574/2628 [1:13:55<31:41,  1.80s/it] 60%|█████▉    | 1575/2628 [1:13:57<31:43,  1.81s/it] 60%|█████▉    | 1576/2628 [1:13:59<33:22,  1.90s/it] 60%|██████    | 1577/2628 [1:14:01<32:50,  1.88s/it] 60%|██████    | 1578/2628 [1:14:02<32:26,  1.85s/it] 60%|██████    | 1579/2628 [1:14:04<32:11,  1.84s/it] 60%|██████    | 1580/2628 [1:14:06<31:58,  1.83s/it]                                                      60%|██████    | 1580/2628 [1:14:06<31:58,  1.83s/it] 60%|██████    | 1581/2628 [1:14:08<31:49,  1.82s/it] 60%|██████    | 1582/2628 [1:14:10<31:40,  1.82s/it] 60%|██████    | 1583/2628 [1:14:11<31:34,  1.81s/it] 60%|██████    | 1584/2628 [1:14:13<31:30,  1.81s/it] 60%|██████    | 1585/2628 [1:14:15<31:27,  1.81s/it] 60%|██████    | 1586/2628 [1:14:17<31:23,  1.81s/it] 60%|██████    | 1587/2628 [1:14:19<31:19,  1.81s/it] 60%|██████    | 1588/2628 [1:14:20<31:16,  1.80s/it] 60%|██████    | 1589/2628 [1:14:22<31:14,  1.80s/it] 61%|██████    | 1590/2628 [1:14:24<31:11,  1.80s/it]                                                      61%|██████    | 1590/2628 [1:14:24<31:11,  1.80s/it] 61%|██████    | 1591/2628 [1:14:26<31:14,  1.81s/it] 61%|██████    | 1592/2628 [1:14:28<31:13,  1.81s/it] 61%|██████    | 1593/2628 [1:14:29<31:11,  1.81s/it] 61%|██████    | 1594/2628 [1:14:31<31:14,  1.81s/it] 61%|██████    | 1595/2628 [1:14:33<31:08,  1.81s/it] 61%|██████    | 1596/2628 [1:14:35<31:04,  1.81s/it] 61%|██████    | 1597/2628 [1:14:37<31:03,  1.81s/it] 61%|██████    | 1598/2628 [1:14:38<30:59,  1.81s/it] 61%|██████    | 1599/2628 [1:14:40<30:56,  1.80s/it] 61%|██████    | 1600/2628 [1:14:42<30:53,  1.80s/it]                                                      61%|██████    | 1600/2628 [1:14:42<30:53,  1.80s/it][INFO|trainer.py:4643] 2025-10-21 18:11:07,392 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 18:11:07,392 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 18:11:07,392 >>   Batch size = 8
[WARNING|utils.py:2443] 2025-10-21 18:11:07,872 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:11:10,679 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:02<00:01,  1.19s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:11:13,144 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:05<00:00,  1.95s/it][A                                                     
                                             [A 61%|██████    | 1600/2628 [1:14:51<30:53,  1.80s/it]
100%|██████████| 3/3 [00:05<00:00,  1.95s/it][A
                                             [A[INFO|trainer.py:4309] 2025-10-21 18:11:16,222 >> Saving model checkpoint to saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-1600
[INFO|configuration_utils.py:491] 2025-10-21 18:11:16,226 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-1600/config.json
[INFO|configuration_utils.py:757] 2025-10-21 18:11:16,227 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-1600/generation_config.json
[INFO|modeling_utils.py:4189] 2025-10-21 18:11:20,150 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-1600/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2421] 2025-10-21 18:11:20,151 >> chat template saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-1600/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-21 18:11:20,152 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-1600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-21 18:11:20,153 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-1600/special_tokens_map.json
[INFO|image_processing_base.py:253] 2025-10-21 18:11:25,087 >> Image processor saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-1600/preprocessor_config.json
[INFO|tokenization_utils_base.py:2421] 2025-10-21 18:11:25,089 >> chat template saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-1600/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-21 18:11:25,090 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-1600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-21 18:11:25,090 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-1600/special_tokens_map.json
[INFO|video_processing_utils.py:600] 2025-10-21 18:11:25,178 >> Video processor saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-1600/video_preprocessor_config.json
[INFO|processing_utils.py:814] 2025-10-21 18:11:25,178 >> chat template saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-1600/chat_template.jinja
 61%|██████    | 1601/2628 [1:15:02<2:03:26,  7.21s/it] 61%|██████    | 1602/2628 [1:15:04<1:35:32,  5.59s/it] 61%|██████    | 1603/2628 [1:15:05<1:16:05,  4.45s/it] 61%|██████    | 1604/2628 [1:15:07<1:02:31,  3.66s/it] 61%|██████    | 1605/2628 [1:15:09<53:01,  3.11s/it]   61%|██████    | 1606/2628 [1:15:11<46:16,  2.72s/it] 61%|██████    | 1607/2628 [1:15:13<41:33,  2.44s/it] 61%|██████    | 1608/2628 [1:15:15<38:22,  2.26s/it] 61%|██████    | 1609/2628 [1:15:16<36:01,  2.12s/it] 61%|██████▏   | 1610/2628 [1:15:18<34:22,  2.03s/it]                                                      61%|██████▏   | 1610/2628 [1:15:18<34:22,  2.03s/it] 61%|██████▏   | 1611/2628 [1:15:20<33:11,  1.96s/it] 61%|██████▏   | 1612/2628 [1:15:22<32:25,  1.92s/it] 61%|██████▏   | 1613/2628 [1:15:24<31:52,  1.88s/it] 61%|██████▏   | 1614/2628 [1:15:25<31:25,  1.86s/it] 61%|██████▏   | 1615/2628 [1:15:27<31:10,  1.85s/it] 61%|██████▏   | 1616/2628 [1:15:29<31:00,  1.84s/it] 62%|██████▏   | 1617/2628 [1:15:31<30:50,  1.83s/it] 62%|██████▏   | 1618/2628 [1:15:33<30:43,  1.83s/it] 62%|██████▏   | 1619/2628 [1:15:34<30:35,  1.82s/it] 62%|██████▏   | 1620/2628 [1:15:36<30:28,  1.81s/it]                                                      62%|██████▏   | 1620/2628 [1:15:36<30:28,  1.81s/it] 62%|██████▏   | 1621/2628 [1:15:38<30:23,  1.81s/it] 62%|██████▏   | 1622/2628 [1:15:40<30:18,  1.81s/it] 62%|██████▏   | 1623/2628 [1:15:42<30:15,  1.81s/it] 62%|██████▏   | 1624/2628 [1:15:43<30:17,  1.81s/it] 62%|██████▏   | 1625/2628 [1:15:45<30:15,  1.81s/it] 62%|██████▏   | 1626/2628 [1:15:47<30:15,  1.81s/it] 62%|██████▏   | 1627/2628 [1:15:49<30:14,  1.81s/it] 62%|██████▏   | 1628/2628 [1:15:51<30:09,  1.81s/it] 62%|██████▏   | 1629/2628 [1:15:53<30:10,  1.81s/it] 62%|██████▏   | 1630/2628 [1:15:54<30:09,  1.81s/it]                                                      62%|██████▏   | 1630/2628 [1:15:54<30:09,  1.81s/it] 62%|██████▏   | 1631/2628 [1:15:56<30:05,  1.81s/it] 62%|██████▏   | 1632/2628 [1:15:58<30:01,  1.81s/it] 62%|██████▏   | 1633/2628 [1:16:00<30:00,  1.81s/it] 62%|██████▏   | 1634/2628 [1:16:02<30:03,  1.81s/it] 62%|██████▏   | 1635/2628 [1:16:03<29:57,  1.81s/it] 62%|██████▏   | 1636/2628 [1:16:05<29:53,  1.81s/it] 62%|██████▏   | 1637/2628 [1:16:07<29:52,  1.81s/it] 62%|██████▏   | 1638/2628 [1:16:09<29:51,  1.81s/it] 62%|██████▏   | 1639/2628 [1:16:11<29:49,  1.81s/it] 62%|██████▏   | 1640/2628 [1:16:12<29:46,  1.81s/it]                                                      62%|██████▏   | 1640/2628 [1:16:12<29:46,  1.81s/it] 62%|██████▏   | 1641/2628 [1:16:14<29:47,  1.81s/it] 62%|██████▏   | 1642/2628 [1:16:16<29:47,  1.81s/it] 63%|██████▎   | 1643/2628 [1:16:18<29:41,  1.81s/it] 63%|██████▎   | 1644/2628 [1:16:20<29:40,  1.81s/it] 63%|██████▎   | 1645/2628 [1:16:22<29:39,  1.81s/it] 63%|██████▎   | 1646/2628 [1:16:23<29:35,  1.81s/it] 63%|██████▎   | 1647/2628 [1:16:25<29:35,  1.81s/it] 63%|██████▎   | 1648/2628 [1:16:27<29:37,  1.81s/it] 63%|██████▎   | 1649/2628 [1:16:29<29:35,  1.81s/it] 63%|██████▎   | 1650/2628 [1:16:31<29:30,  1.81s/it]                                                      63%|██████▎   | 1650/2628 [1:16:31<29:30,  1.81s/it] 63%|██████▎   | 1651/2628 [1:16:32<29:31,  1.81s/it] 63%|██████▎   | 1652/2628 [1:16:34<29:28,  1.81s/it] 63%|██████▎   | 1653/2628 [1:16:36<29:26,  1.81s/it] 63%|██████▎   | 1654/2628 [1:16:38<29:21,  1.81s/it] 63%|██████▎   | 1655/2628 [1:16:40<29:17,  1.81s/it] 63%|██████▎   | 1656/2628 [1:16:41<29:15,  1.81s/it] 63%|██████▎   | 1657/2628 [1:16:43<29:14,  1.81s/it] 63%|██████▎   | 1658/2628 [1:16:45<29:09,  1.80s/it] 63%|██████▎   | 1659/2628 [1:16:47<29:12,  1.81s/it] 63%|██████▎   | 1660/2628 [1:16:49<29:09,  1.81s/it]                                                      63%|██████▎   | 1660/2628 [1:16:49<29:09,  1.81s/it] 63%|██████▎   | 1661/2628 [1:16:50<29:08,  1.81s/it] 63%|██████▎   | 1662/2628 [1:16:52<29:05,  1.81s/it] 63%|██████▎   | 1663/2628 [1:16:54<29:01,  1.80s/it] 63%|██████▎   | 1664/2628 [1:16:56<28:59,  1.80s/it] 63%|██████▎   | 1665/2628 [1:16:58<29:00,  1.81s/it] 63%|██████▎   | 1666/2628 [1:16:59<28:56,  1.81s/it] 63%|██████▎   | 1667/2628 [1:17:01<28:57,  1.81s/it] 63%|██████▎   | 1668/2628 [1:17:03<28:55,  1.81s/it] 64%|██████▎   | 1669/2628 [1:17:05<28:54,  1.81s/it] 64%|██████▎   | 1670/2628 [1:17:07<28:55,  1.81s/it]                                                      64%|██████▎   | 1670/2628 [1:17:07<28:55,  1.81s/it] 64%|██████▎   | 1671/2628 [1:17:09<28:50,  1.81s/it] 64%|██████▎   | 1672/2628 [1:17:10<28:47,  1.81s/it] 64%|██████▎   | 1673/2628 [1:17:12<28:52,  1.81s/it] 64%|██████▎   | 1674/2628 [1:17:14<28:51,  1.81s/it] 64%|██████▎   | 1675/2628 [1:17:16<28:48,  1.81s/it] 64%|██████▍   | 1676/2628 [1:17:18<28:43,  1.81s/it] 64%|██████▍   | 1677/2628 [1:17:19<28:45,  1.81s/it] 64%|██████▍   | 1678/2628 [1:17:21<28:40,  1.81s/it] 64%|██████▍   | 1679/2628 [1:17:23<28:36,  1.81s/it] 64%|██████▍   | 1680/2628 [1:17:25<28:31,  1.81s/it]                                                      64%|██████▍   | 1680/2628 [1:17:25<28:31,  1.81s/it] 64%|██████▍   | 1681/2628 [1:17:27<28:29,  1.81s/it] 64%|██████▍   | 1682/2628 [1:17:28<28:26,  1.80s/it] 64%|██████▍   | 1683/2628 [1:17:30<28:23,  1.80s/it] 64%|██████▍   | 1684/2628 [1:17:32<28:21,  1.80s/it] 64%|██████▍   | 1685/2628 [1:17:34<28:22,  1.81s/it] 64%|██████▍   | 1686/2628 [1:17:36<28:19,  1.80s/it] 64%|██████▍   | 1687/2628 [1:17:37<28:16,  1.80s/it] 64%|██████▍   | 1688/2628 [1:17:39<28:19,  1.81s/it] 64%|██████▍   | 1689/2628 [1:17:41<28:18,  1.81s/it] 64%|██████▍   | 1690/2628 [1:17:43<28:15,  1.81s/it]                                                      64%|██████▍   | 1690/2628 [1:17:43<28:15,  1.81s/it] 64%|██████▍   | 1691/2628 [1:17:45<28:13,  1.81s/it] 64%|██████▍   | 1692/2628 [1:17:46<28:09,  1.81s/it] 64%|██████▍   | 1693/2628 [1:17:48<28:08,  1.81s/it] 64%|██████▍   | 1694/2628 [1:17:50<28:04,  1.80s/it] 64%|██████▍   | 1695/2628 [1:17:52<28:02,  1.80s/it] 65%|██████▍   | 1696/2628 [1:17:54<28:00,  1.80s/it] 65%|██████▍   | 1697/2628 [1:17:56<28:02,  1.81s/it] 65%|██████▍   | 1698/2628 [1:17:57<27:59,  1.81s/it] 65%|██████▍   | 1699/2628 [1:17:59<27:56,  1.80s/it] 65%|██████▍   | 1700/2628 [1:18:01<27:59,  1.81s/it]                                                      65%|██████▍   | 1700/2628 [1:18:01<27:59,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 18:14:26,264 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 18:14:26,264 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 18:14:26,264 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:14:26,752 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:14:32,275 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:06<00:03,  3.27s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:14:38,891 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:12<00:00,  4.20s/it][A                                                     
                                             [A 65%|██████▍   | 1700/2628 [1:18:19<27:59,  1.81s/it]
100%|██████████| 3/3 [00:12<00:00,  4.20s/it][A
                                             [A 65%|██████▍   | 1701/2628 [1:18:21<1:52:25,  7.28s/it] 65%|██████▍   | 1702/2628 [1:18:23<1:26:56,  5.63s/it] 65%|██████▍   | 1703/2628 [1:18:25<1:09:07,  4.48s/it] 65%|██████▍   | 1704/2628 [1:18:26<56:39,  3.68s/it]   65%|██████▍   | 1705/2628 [1:18:28<47:59,  3.12s/it] 65%|██████▍   | 1706/2628 [1:18:30<41:55,  2.73s/it] 65%|██████▍   | 1707/2628 [1:18:32<37:37,  2.45s/it] 65%|██████▍   | 1708/2628 [1:18:34<34:35,  2.26s/it] 65%|██████▌   | 1709/2628 [1:18:35<32:30,  2.12s/it] 65%|██████▌   | 1710/2628 [1:18:37<31:03,  2.03s/it]                                                      65%|██████▌   | 1710/2628 [1:18:37<31:03,  2.03s/it] 65%|██████▌   | 1711/2628 [1:18:39<29:58,  1.96s/it] 65%|██████▌   | 1712/2628 [1:18:41<29:15,  1.92s/it] 65%|██████▌   | 1713/2628 [1:18:43<28:42,  1.88s/it] 65%|██████▌   | 1714/2628 [1:18:44<28:19,  1.86s/it] 65%|██████▌   | 1715/2628 [1:18:46<28:02,  1.84s/it] 65%|██████▌   | 1716/2628 [1:18:48<27:50,  1.83s/it] 65%|██████▌   | 1717/2628 [1:18:50<27:41,  1.82s/it] 65%|██████▌   | 1718/2628 [1:18:52<27:32,  1.82s/it] 65%|██████▌   | 1719/2628 [1:18:53<27:27,  1.81s/it] 65%|██████▌   | 1720/2628 [1:18:55<27:24,  1.81s/it]                                                      65%|██████▌   | 1720/2628 [1:18:55<27:24,  1.81s/it] 65%|██████▌   | 1721/2628 [1:18:57<27:22,  1.81s/it] 66%|██████▌   | 1722/2628 [1:18:59<27:23,  1.81s/it] 66%|██████▌   | 1723/2628 [1:19:01<27:23,  1.82s/it] 66%|██████▌   | 1724/2628 [1:19:03<27:21,  1.82s/it] 66%|██████▌   | 1725/2628 [1:19:04<27:14,  1.81s/it] 66%|██████▌   | 1726/2628 [1:19:06<27:16,  1.81s/it] 66%|██████▌   | 1727/2628 [1:19:08<27:11,  1.81s/it] 66%|██████▌   | 1728/2628 [1:19:10<27:08,  1.81s/it] 66%|██████▌   | 1729/2628 [1:19:12<27:02,  1.81s/it] 66%|██████▌   | 1730/2628 [1:19:13<27:00,  1.80s/it]                                                      66%|██████▌   | 1730/2628 [1:19:13<27:00,  1.80s/it] 66%|██████▌   | 1731/2628 [1:19:15<27:02,  1.81s/it] 66%|██████▌   | 1732/2628 [1:19:17<27:00,  1.81s/it] 66%|██████▌   | 1733/2628 [1:19:19<26:57,  1.81s/it] 66%|██████▌   | 1734/2628 [1:19:21<26:57,  1.81s/it] 66%|██████▌   | 1735/2628 [1:19:22<26:57,  1.81s/it] 66%|██████▌   | 1736/2628 [1:19:24<26:59,  1.82s/it] 66%|██████▌   | 1737/2628 [1:19:26<26:56,  1.81s/it] 66%|██████▌   | 1738/2628 [1:19:28<26:51,  1.81s/it] 66%|██████▌   | 1739/2628 [1:19:30<26:51,  1.81s/it] 66%|██████▌   | 1740/2628 [1:19:31<26:51,  1.81s/it]                                                      66%|██████▌   | 1740/2628 [1:19:32<26:51,  1.81s/it] 66%|██████▌   | 1741/2628 [1:19:33<26:52,  1.82s/it] 66%|██████▋   | 1742/2628 [1:19:35<26:50,  1.82s/it] 66%|██████▋   | 1743/2628 [1:19:37<26:45,  1.81s/it] 66%|██████▋   | 1744/2628 [1:19:39<26:39,  1.81s/it] 66%|██████▋   | 1745/2628 [1:19:41<26:34,  1.81s/it] 66%|██████▋   | 1746/2628 [1:19:42<26:34,  1.81s/it] 66%|██████▋   | 1747/2628 [1:19:44<26:34,  1.81s/it] 67%|██████▋   | 1748/2628 [1:19:46<26:29,  1.81s/it] 67%|██████▋   | 1749/2628 [1:19:48<26:26,  1.80s/it] 67%|██████▋   | 1750/2628 [1:19:50<26:22,  1.80s/it]                                                      67%|██████▋   | 1750/2628 [1:19:50<26:22,  1.80s/it] 67%|██████▋   | 1751/2628 [1:19:51<26:20,  1.80s/it] 67%|██████▋   | 1752/2628 [1:19:53<26:42,  1.83s/it] 67%|██████▋   | 1753/2628 [1:19:56<31:15,  2.14s/it] 67%|██████▋   | 1754/2628 [1:19:58<29:47,  2.05s/it] 67%|██████▋   | 1755/2628 [1:20:00<28:42,  1.97s/it] 67%|██████▋   | 1756/2628 [1:20:02<27:58,  1.93s/it] 67%|██████▋   | 1757/2628 [1:20:03<27:25,  1.89s/it] 67%|██████▋   | 1758/2628 [1:20:05<27:07,  1.87s/it] 67%|██████▋   | 1759/2628 [1:20:07<26:47,  1.85s/it] 67%|██████▋   | 1760/2628 [1:20:09<26:36,  1.84s/it]                                                      67%|██████▋   | 1760/2628 [1:20:09<26:36,  1.84s/it] 67%|██████▋   | 1761/2628 [1:20:11<26:30,  1.83s/it] 67%|██████▋   | 1762/2628 [1:20:12<26:28,  1.83s/it] 67%|██████▋   | 1763/2628 [1:20:14<26:17,  1.82s/it] 67%|██████▋   | 1764/2628 [1:20:16<26:11,  1.82s/it] 67%|██████▋   | 1765/2628 [1:20:18<26:06,  1.82s/it] 67%|██████▋   | 1766/2628 [1:20:20<26:04,  1.82s/it] 67%|██████▋   | 1767/2628 [1:20:22<25:59,  1.81s/it] 67%|██████▋   | 1768/2628 [1:20:23<25:55,  1.81s/it] 67%|██████▋   | 1769/2628 [1:20:25<25:52,  1.81s/it] 67%|██████▋   | 1770/2628 [1:20:27<25:49,  1.81s/it]                                                      67%|██████▋   | 1770/2628 [1:20:27<25:49,  1.81s/it] 67%|██████▋   | 1771/2628 [1:20:29<25:50,  1.81s/it] 67%|██████▋   | 1772/2628 [1:20:31<25:48,  1.81s/it] 67%|██████▋   | 1773/2628 [1:20:32<25:45,  1.81s/it] 68%|██████▊   | 1774/2628 [1:20:34<25:42,  1.81s/it] 68%|██████▊   | 1775/2628 [1:20:36<25:39,  1.80s/it] 68%|██████▊   | 1776/2628 [1:20:38<25:40,  1.81s/it] 68%|██████▊   | 1777/2628 [1:20:40<25:38,  1.81s/it] 68%|██████▊   | 1778/2628 [1:20:41<25:37,  1.81s/it] 68%|██████▊   | 1779/2628 [1:20:43<25:34,  1.81s/it] 68%|██████▊   | 1780/2628 [1:20:45<25:38,  1.81s/it]                                                      68%|██████▊   | 1780/2628 [1:20:45<25:38,  1.81s/it] 68%|██████▊   | 1781/2628 [1:20:47<25:33,  1.81s/it] 68%|██████▊   | 1782/2628 [1:20:49<25:33,  1.81s/it] 68%|██████▊   | 1783/2628 [1:20:50<25:33,  1.81s/it] 68%|██████▊   | 1784/2628 [1:20:52<25:31,  1.81s/it] 68%|██████▊   | 1785/2628 [1:20:54<25:28,  1.81s/it] 68%|██████▊   | 1786/2628 [1:20:56<25:24,  1.81s/it] 68%|██████▊   | 1787/2628 [1:20:58<25:21,  1.81s/it] 68%|██████▊   | 1788/2628 [1:20:59<25:18,  1.81s/it] 68%|██████▊   | 1789/2628 [1:21:01<25:19,  1.81s/it] 68%|██████▊   | 1790/2628 [1:21:03<25:18,  1.81s/it]                                                      68%|██████▊   | 1790/2628 [1:21:03<25:18,  1.81s/it] 68%|██████▊   | 1791/2628 [1:21:05<25:15,  1.81s/it] 68%|██████▊   | 1792/2628 [1:21:07<25:12,  1.81s/it] 68%|██████▊   | 1793/2628 [1:21:09<25:08,  1.81s/it] 68%|██████▊   | 1794/2628 [1:21:10<25:09,  1.81s/it] 68%|██████▊   | 1795/2628 [1:21:12<25:11,  1.81s/it] 68%|██████▊   | 1796/2628 [1:21:14<25:08,  1.81s/it] 68%|██████▊   | 1797/2628 [1:21:16<25:03,  1.81s/it] 68%|██████▊   | 1798/2628 [1:21:18<25:04,  1.81s/it] 68%|██████▊   | 1799/2628 [1:21:19<25:00,  1.81s/it] 68%|██████▊   | 1800/2628 [1:21:21<25:00,  1.81s/it]                                                      68%|██████▊   | 1800/2628 [1:21:21<25:00,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 18:17:46,576 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 18:17:46,576 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 18:17:46,576 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:17:47,070 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:17:50,669 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:05<00:02,  2.68s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:17:56,103 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:10<00:00,  3.74s/it][A                                                     
                                             [A 68%|██████▊   | 1800/2628 [1:21:36<25:00,  1.81s/it]
100%|██████████| 3/3 [00:10<00:00,  3.74s/it][A
                                             [A 69%|██████▊   | 1801/2628 [1:21:38<1:26:25,  6.27s/it] 69%|██████▊   | 1802/2628 [1:21:40<1:07:51,  4.93s/it] 69%|██████▊   | 1803/2628 [1:21:42<54:56,  4.00s/it]   69%|██████▊   | 1804/2628 [1:21:43<45:50,  3.34s/it] 69%|██████▊   | 1805/2628 [1:21:45<39:27,  2.88s/it] 69%|██████▊   | 1806/2628 [1:21:47<35:00,  2.56s/it] 69%|██████▉   | 1807/2628 [1:21:49<31:52,  2.33s/it] 69%|██████▉   | 1808/2628 [1:21:51<29:40,  2.17s/it] 69%|██████▉   | 1809/2628 [1:21:52<28:11,  2.06s/it] 69%|██████▉   | 1810/2628 [1:21:54<27:07,  1.99s/it]                                                      69%|██████▉   | 1810/2628 [1:21:54<27:07,  1.99s/it] 69%|██████▉   | 1811/2628 [1:21:56<26:19,  1.93s/it] 69%|██████▉   | 1812/2628 [1:21:58<25:45,  1.89s/it] 69%|██████▉   | 1813/2628 [1:22:00<25:21,  1.87s/it] 69%|██████▉   | 1814/2628 [1:22:01<25:07,  1.85s/it] 69%|██████▉   | 1815/2628 [1:22:03<24:57,  1.84s/it] 69%|██████▉   | 1816/2628 [1:22:05<24:45,  1.83s/it] 69%|██████▉   | 1817/2628 [1:22:07<24:37,  1.82s/it] 69%|██████▉   | 1818/2628 [1:22:09<24:31,  1.82s/it] 69%|██████▉   | 1819/2628 [1:22:10<24:27,  1.81s/it] 69%|██████▉   | 1820/2628 [1:22:12<24:24,  1.81s/it]                                                      69%|██████▉   | 1820/2628 [1:22:12<24:24,  1.81s/it] 69%|██████▉   | 1821/2628 [1:22:14<24:20,  1.81s/it] 69%|██████▉   | 1822/2628 [1:22:16<24:21,  1.81s/it] 69%|██████▉   | 1823/2628 [1:22:18<24:20,  1.81s/it] 69%|██████▉   | 1824/2628 [1:22:19<24:17,  1.81s/it] 69%|██████▉   | 1825/2628 [1:22:21<24:12,  1.81s/it] 69%|██████▉   | 1826/2628 [1:22:23<24:09,  1.81s/it] 70%|██████▉   | 1827/2628 [1:22:25<24:06,  1.81s/it] 70%|██████▉   | 1828/2628 [1:22:27<24:04,  1.81s/it] 70%|██████▉   | 1829/2628 [1:22:29<24:07,  1.81s/it] 70%|██████▉   | 1830/2628 [1:22:30<24:07,  1.81s/it]                                                      70%|██████▉   | 1830/2628 [1:22:30<24:07,  1.81s/it] 70%|██████▉   | 1831/2628 [1:22:32<24:02,  1.81s/it] 70%|██████▉   | 1832/2628 [1:22:34<23:59,  1.81s/it] 70%|██████▉   | 1833/2628 [1:22:36<23:59,  1.81s/it] 70%|██████▉   | 1834/2628 [1:22:38<23:56,  1.81s/it] 70%|██████▉   | 1835/2628 [1:22:39<23:58,  1.81s/it] 70%|██████▉   | 1836/2628 [1:22:41<24:00,  1.82s/it] 70%|██████▉   | 1837/2628 [1:22:43<23:57,  1.82s/it] 70%|██████▉   | 1838/2628 [1:22:45<23:57,  1.82s/it] 70%|██████▉   | 1839/2628 [1:22:47<23:56,  1.82s/it] 70%|███████   | 1840/2628 [1:22:49<23:52,  1.82s/it]                                                      70%|███████   | 1840/2628 [1:22:49<23:52,  1.82s/it] 70%|███████   | 1841/2628 [1:22:50<23:51,  1.82s/it] 70%|███████   | 1842/2628 [1:22:52<23:45,  1.81s/it] 70%|███████   | 1843/2628 [1:22:54<23:43,  1.81s/it] 70%|███████   | 1844/2628 [1:22:56<23:38,  1.81s/it] 70%|███████   | 1845/2628 [1:22:58<23:36,  1.81s/it] 70%|███████   | 1846/2628 [1:22:59<23:33,  1.81s/it] 70%|███████   | 1847/2628 [1:23:01<23:30,  1.81s/it] 70%|███████   | 1848/2628 [1:23:03<23:30,  1.81s/it] 70%|███████   | 1849/2628 [1:23:05<23:30,  1.81s/it] 70%|███████   | 1850/2628 [1:23:07<23:27,  1.81s/it]                                                      70%|███████   | 1850/2628 [1:23:07<23:27,  1.81s/it] 70%|███████   | 1851/2628 [1:23:08<23:24,  1.81s/it] 70%|███████   | 1852/2628 [1:23:10<23:24,  1.81s/it] 71%|███████   | 1853/2628 [1:23:12<23:23,  1.81s/it] 71%|███████   | 1854/2628 [1:23:14<23:23,  1.81s/it] 71%|███████   | 1855/2628 [1:23:16<23:18,  1.81s/it] 71%|███████   | 1856/2628 [1:23:17<23:17,  1.81s/it] 71%|███████   | 1857/2628 [1:23:19<23:17,  1.81s/it] 71%|███████   | 1858/2628 [1:23:21<23:16,  1.81s/it] 71%|███████   | 1859/2628 [1:23:23<23:18,  1.82s/it] 71%|███████   | 1860/2628 [1:23:25<23:12,  1.81s/it]                                                      71%|███████   | 1860/2628 [1:23:25<23:12,  1.81s/it] 71%|███████   | 1861/2628 [1:23:27<23:09,  1.81s/it] 71%|███████   | 1862/2628 [1:23:28<23:04,  1.81s/it] 71%|███████   | 1863/2628 [1:23:30<23:04,  1.81s/it] 71%|███████   | 1864/2628 [1:23:32<23:04,  1.81s/it] 71%|███████   | 1865/2628 [1:23:34<23:01,  1.81s/it] 71%|███████   | 1866/2628 [1:23:36<22:59,  1.81s/it] 71%|███████   | 1867/2628 [1:23:37<22:56,  1.81s/it] 71%|███████   | 1868/2628 [1:23:39<22:53,  1.81s/it] 71%|███████   | 1869/2628 [1:23:41<22:52,  1.81s/it] 71%|███████   | 1870/2628 [1:23:43<22:48,  1.81s/it]                                                      71%|███████   | 1870/2628 [1:23:43<22:48,  1.81s/it] 71%|███████   | 1871/2628 [1:23:45<22:47,  1.81s/it] 71%|███████   | 1872/2628 [1:23:46<22:43,  1.80s/it] 71%|███████▏  | 1873/2628 [1:23:48<22:43,  1.81s/it] 71%|███████▏  | 1874/2628 [1:23:50<22:41,  1.81s/it] 71%|███████▏  | 1875/2628 [1:23:52<22:38,  1.80s/it] 71%|███████▏  | 1876/2628 [1:23:54<22:38,  1.81s/it] 71%|███████▏  | 1877/2628 [1:23:55<22:40,  1.81s/it] 71%|███████▏  | 1878/2628 [1:23:57<22:39,  1.81s/it] 71%|███████▏  | 1879/2628 [1:23:59<22:38,  1.81s/it] 72%|███████▏  | 1880/2628 [1:24:01<22:35,  1.81s/it]                                                      72%|███████▏  | 1880/2628 [1:24:01<22:35,  1.81s/it] 72%|███████▏  | 1881/2628 [1:24:03<22:32,  1.81s/it] 72%|███████▏  | 1882/2628 [1:24:05<22:32,  1.81s/it] 72%|███████▏  | 1883/2628 [1:24:06<22:31,  1.81s/it] 72%|███████▏  | 1884/2628 [1:24:08<22:31,  1.82s/it] 72%|███████▏  | 1885/2628 [1:24:10<22:30,  1.82s/it] 72%|███████▏  | 1886/2628 [1:24:12<22:28,  1.82s/it] 72%|███████▏  | 1887/2628 [1:24:14<22:22,  1.81s/it] 72%|███████▏  | 1888/2628 [1:24:15<22:18,  1.81s/it] 72%|███████▏  | 1889/2628 [1:24:17<22:15,  1.81s/it] 72%|███████▏  | 1890/2628 [1:24:19<22:14,  1.81s/it]                                                      72%|███████▏  | 1890/2628 [1:24:19<22:14,  1.81s/it] 72%|███████▏  | 1891/2628 [1:24:21<22:13,  1.81s/it] 72%|███████▏  | 1892/2628 [1:24:23<22:12,  1.81s/it] 72%|███████▏  | 1893/2628 [1:24:24<22:08,  1.81s/it] 72%|███████▏  | 1894/2628 [1:24:26<22:05,  1.81s/it] 72%|███████▏  | 1895/2628 [1:24:28<22:04,  1.81s/it] 72%|███████▏  | 1896/2628 [1:24:30<22:01,  1.81s/it] 72%|███████▏  | 1897/2628 [1:24:32<21:59,  1.81s/it] 72%|███████▏  | 1898/2628 [1:24:33<21:57,  1.80s/it] 72%|███████▏  | 1899/2628 [1:24:35<21:56,  1.81s/it] 72%|███████▏  | 1900/2628 [1:24:37<21:54,  1.81s/it]                                                      72%|███████▏  | 1900/2628 [1:24:37<21:54,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 18:21:02,403 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 18:21:02,403 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 18:21:02,403 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:21:02,880 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:21:05,896 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:03<00:01,  1.95s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:21:09,856 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:07<00:00,  2.57s/it][A                                                     
                                             [A 72%|███████▏  | 1900/2628 [1:24:48<21:54,  1.81s/it]
100%|██████████| 3/3 [00:07<00:00,  2.57s/it][A
                                             [A 72%|███████▏  | 1901/2628 [1:24:50<1:01:54,  5.11s/it] 72%|███████▏  | 1902/2628 [1:24:52<49:51,  4.12s/it]   72%|███████▏  | 1903/2628 [1:24:54<41:23,  3.42s/it] 72%|███████▏  | 1904/2628 [1:24:55<35:26,  2.94s/it] 72%|███████▏  | 1905/2628 [1:24:57<31:21,  2.60s/it] 73%|███████▎  | 1906/2628 [1:24:59<28:26,  2.36s/it] 73%|███████▎  | 1907/2628 [1:25:01<26:24,  2.20s/it] 73%|███████▎  | 1908/2628 [1:25:03<24:59,  2.08s/it] 73%|███████▎  | 1909/2628 [1:25:04<23:57,  2.00s/it] 73%|███████▎  | 1910/2628 [1:25:06<23:12,  1.94s/it]                                                      73%|███████▎  | 1910/2628 [1:25:06<23:12,  1.94s/it] 73%|███████▎  | 1911/2628 [1:25:08<22:46,  1.91s/it] 73%|███████▎  | 1912/2628 [1:25:10<22:22,  1.88s/it] 73%|███████▎  | 1913/2628 [1:25:12<22:07,  1.86s/it] 73%|███████▎  | 1914/2628 [1:25:13<21:56,  1.84s/it] 73%|███████▎  | 1915/2628 [1:25:15<21:46,  1.83s/it] 73%|███████▎  | 1916/2628 [1:25:17<21:37,  1.82s/it] 73%|███████▎  | 1917/2628 [1:25:19<21:33,  1.82s/it] 73%|███████▎  | 1918/2628 [1:25:21<21:27,  1.81s/it] 73%|███████▎  | 1919/2628 [1:25:22<21:23,  1.81s/it] 73%|███████▎  | 1920/2628 [1:25:24<21:21,  1.81s/it]                                                      73%|███████▎  | 1920/2628 [1:25:24<21:21,  1.81s/it] 73%|███████▎  | 1921/2628 [1:25:26<21:18,  1.81s/it] 73%|███████▎  | 1922/2628 [1:25:28<21:15,  1.81s/it] 73%|███████▎  | 1923/2628 [1:25:30<21:12,  1.81s/it] 73%|███████▎  | 1924/2628 [1:25:31<21:14,  1.81s/it] 73%|███████▎  | 1925/2628 [1:25:33<21:11,  1.81s/it] 73%|███████▎  | 1926/2628 [1:25:35<21:07,  1.81s/it] 73%|███████▎  | 1927/2628 [1:25:37<21:08,  1.81s/it] 73%|███████▎  | 1928/2628 [1:25:39<21:04,  1.81s/it] 73%|███████▎  | 1929/2628 [1:25:41<21:03,  1.81s/it] 73%|███████▎  | 1930/2628 [1:25:42<21:00,  1.81s/it]                                                      73%|███████▎  | 1930/2628 [1:25:42<21:00,  1.81s/it] 73%|███████▎  | 1931/2628 [1:25:44<20:59,  1.81s/it] 74%|███████▎  | 1932/2628 [1:25:46<20:56,  1.80s/it] 74%|███████▎  | 1933/2628 [1:25:48<20:53,  1.80s/it] 74%|███████▎  | 1934/2628 [1:25:50<20:52,  1.81s/it] 74%|███████▎  | 1935/2628 [1:25:51<20:50,  1.80s/it] 74%|███████▎  | 1936/2628 [1:25:53<20:50,  1.81s/it] 74%|███████▎  | 1937/2628 [1:25:55<20:47,  1.81s/it] 74%|███████▎  | 1938/2628 [1:25:57<20:47,  1.81s/it] 74%|███████▍  | 1939/2628 [1:25:59<20:45,  1.81s/it] 74%|███████▍  | 1940/2628 [1:26:00<20:41,  1.80s/it]                                                      74%|███████▍  | 1940/2628 [1:26:00<20:41,  1.80s/it] 74%|███████▍  | 1941/2628 [1:26:02<20:40,  1.81s/it] 74%|███████▍  | 1942/2628 [1:26:04<20:37,  1.80s/it] 74%|███████▍  | 1943/2628 [1:26:06<20:35,  1.80s/it] 74%|███████▍  | 1944/2628 [1:26:08<20:34,  1.81s/it] 74%|███████▍  | 1945/2628 [1:26:09<20:34,  1.81s/it] 74%|███████▍  | 1946/2628 [1:26:11<20:31,  1.81s/it] 74%|███████▍  | 1947/2628 [1:26:13<20:29,  1.80s/it] 74%|███████▍  | 1948/2628 [1:26:15<20:26,  1.80s/it] 74%|███████▍  | 1949/2628 [1:26:17<20:25,  1.81s/it] 74%|███████▍  | 1950/2628 [1:26:18<20:26,  1.81s/it]                                                      74%|███████▍  | 1950/2628 [1:26:18<20:26,  1.81s/it] 74%|███████▍  | 1951/2628 [1:26:20<20:26,  1.81s/it] 74%|███████▍  | 1952/2628 [1:26:22<20:22,  1.81s/it] 74%|███████▍  | 1953/2628 [1:26:24<20:20,  1.81s/it] 74%|███████▍  | 1954/2628 [1:26:26<20:20,  1.81s/it] 74%|███████▍  | 1955/2628 [1:26:27<20:21,  1.81s/it] 74%|███████▍  | 1956/2628 [1:26:29<20:18,  1.81s/it] 74%|███████▍  | 1957/2628 [1:26:31<20:18,  1.82s/it] 75%|███████▍  | 1958/2628 [1:26:33<20:13,  1.81s/it] 75%|███████▍  | 1959/2628 [1:26:35<20:11,  1.81s/it] 75%|███████▍  | 1960/2628 [1:26:37<20:08,  1.81s/it]                                                      75%|███████▍  | 1960/2628 [1:26:37<20:08,  1.81s/it] 75%|███████▍  | 1961/2628 [1:26:38<20:06,  1.81s/it] 75%|███████▍  | 1962/2628 [1:26:40<20:02,  1.81s/it] 75%|███████▍  | 1963/2628 [1:26:42<20:03,  1.81s/it] 75%|███████▍  | 1964/2628 [1:26:44<20:00,  1.81s/it] 75%|███████▍  | 1965/2628 [1:26:46<20:00,  1.81s/it] 75%|███████▍  | 1966/2628 [1:26:47<19:57,  1.81s/it] 75%|███████▍  | 1967/2628 [1:26:49<19:55,  1.81s/it] 75%|███████▍  | 1968/2628 [1:26:51<19:53,  1.81s/it] 75%|███████▍  | 1969/2628 [1:26:53<19:51,  1.81s/it] 75%|███████▍  | 1970/2628 [1:26:55<19:48,  1.81s/it]                                                      75%|███████▍  | 1970/2628 [1:26:55<19:48,  1.81s/it] 75%|███████▌  | 1971/2628 [1:26:56<19:47,  1.81s/it] 75%|███████▌  | 1972/2628 [1:26:58<19:46,  1.81s/it] 75%|███████▌  | 1973/2628 [1:27:00<19:44,  1.81s/it] 75%|███████▌  | 1974/2628 [1:27:02<19:44,  1.81s/it] 75%|███████▌  | 1975/2628 [1:27:04<19:44,  1.81s/it] 75%|███████▌  | 1976/2628 [1:27:05<19:39,  1.81s/it] 75%|███████▌  | 1977/2628 [1:27:07<19:39,  1.81s/it] 75%|███████▌  | 1978/2628 [1:27:09<19:36,  1.81s/it] 75%|███████▌  | 1979/2628 [1:27:11<19:33,  1.81s/it] 75%|███████▌  | 1980/2628 [1:27:13<19:34,  1.81s/it]                                                      75%|███████▌  | 1980/2628 [1:27:13<19:34,  1.81s/it] 75%|███████▌  | 1981/2628 [1:27:15<19:31,  1.81s/it] 75%|███████▌  | 1982/2628 [1:27:16<19:28,  1.81s/it] 75%|███████▌  | 1983/2628 [1:27:18<19:25,  1.81s/it] 75%|███████▌  | 1984/2628 [1:27:20<19:23,  1.81s/it] 76%|███████▌  | 1985/2628 [1:27:22<19:20,  1.81s/it] 76%|███████▌  | 1986/2628 [1:27:24<19:20,  1.81s/it] 76%|███████▌  | 1987/2628 [1:27:25<19:18,  1.81s/it] 76%|███████▌  | 1988/2628 [1:27:27<19:19,  1.81s/it] 76%|███████▌  | 1989/2628 [1:27:29<19:18,  1.81s/it] 76%|███████▌  | 1990/2628 [1:27:31<19:15,  1.81s/it]                                                      76%|███████▌  | 1990/2628 [1:27:31<19:15,  1.81s/it] 76%|███████▌  | 1991/2628 [1:27:33<19:12,  1.81s/it] 76%|███████▌  | 1992/2628 [1:27:34<19:10,  1.81s/it] 76%|███████▌  | 1993/2628 [1:27:36<19:07,  1.81s/it] 76%|███████▌  | 1994/2628 [1:27:38<19:08,  1.81s/it] 76%|███████▌  | 1995/2628 [1:27:40<19:08,  1.81s/it] 76%|███████▌  | 1996/2628 [1:27:42<19:04,  1.81s/it] 76%|███████▌  | 1997/2628 [1:27:43<19:03,  1.81s/it] 76%|███████▌  | 1998/2628 [1:27:45<18:59,  1.81s/it] 76%|███████▌  | 1999/2628 [1:27:47<18:59,  1.81s/it] 76%|███████▌  | 2000/2628 [1:27:49<18:59,  1.82s/it]                                                      76%|███████▌  | 2000/2628 [1:27:49<18:59,  1.82s/it][INFO|trainer.py:4643] 2025-10-21 18:24:14,274 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 18:24:14,274 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 18:24:14,274 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:24:14,759 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:24:18,088 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:03<00:01,  1.78s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:24:21,720 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:08<00:00,  3.27s/it][A                                                     
                                             [A 76%|███████▌  | 2000/2628 [1:28:02<18:59,  1.82s/it]
100%|██████████| 3/3 [00:09<00:00,  3.27s/it][A
                                             [A 76%|███████▌  | 2001/2628 [1:28:04<59:23,  5.68s/it] 76%|███████▌  | 2002/2628 [1:28:05<47:11,  4.52s/it] 76%|███████▌  | 2003/2628 [1:28:07<38:41,  3.71s/it] 76%|███████▋  | 2004/2628 [1:28:09<32:42,  3.15s/it] 76%|███████▋  | 2005/2628 [1:28:11<28:29,  2.74s/it] 76%|███████▋  | 2006/2628 [1:28:13<25:31,  2.46s/it] 76%|███████▋  | 2007/2628 [1:28:15<23:30,  2.27s/it] 76%|███████▋  | 2008/2628 [1:28:16<22:01,  2.13s/it] 76%|███████▋  | 2009/2628 [1:28:18<20:58,  2.03s/it] 76%|███████▋  | 2010/2628 [1:28:20<20:13,  1.96s/it]                                                      76%|███████▋  | 2010/2628 [1:28:20<20:13,  1.96s/it] 77%|███████▋  | 2011/2628 [1:28:22<19:43,  1.92s/it] 77%|███████▋  | 2012/2628 [1:28:24<19:19,  1.88s/it] 77%|███████▋  | 2013/2628 [1:28:25<19:03,  1.86s/it] 77%|███████▋  | 2014/2628 [1:28:27<18:52,  1.84s/it] 77%|███████▋  | 2015/2628 [1:28:29<18:43,  1.83s/it] 77%|███████▋  | 2016/2628 [1:28:31<18:37,  1.83s/it] 77%|███████▋  | 2017/2628 [1:28:33<18:31,  1.82s/it] 77%|███████▋  | 2018/2628 [1:28:34<18:27,  1.82s/it] 77%|███████▋  | 2019/2628 [1:28:36<18:25,  1.82s/it] 77%|███████▋  | 2020/2628 [1:28:38<18:22,  1.81s/it]                                                      77%|███████▋  | 2020/2628 [1:28:38<18:22,  1.81s/it] 77%|███████▋  | 2021/2628 [1:28:40<18:19,  1.81s/it] 77%|███████▋  | 2022/2628 [1:28:42<18:16,  1.81s/it] 77%|███████▋  | 2023/2628 [1:28:43<18:13,  1.81s/it] 77%|███████▋  | 2024/2628 [1:28:45<18:11,  1.81s/it] 77%|███████▋  | 2025/2628 [1:28:47<18:10,  1.81s/it] 77%|███████▋  | 2026/2628 [1:28:49<18:07,  1.81s/it] 77%|███████▋  | 2027/2628 [1:28:51<18:05,  1.81s/it] 77%|███████▋  | 2028/2628 [1:28:52<18:03,  1.81s/it] 77%|███████▋  | 2029/2628 [1:28:54<18:03,  1.81s/it] 77%|███████▋  | 2030/2628 [1:28:56<18:02,  1.81s/it]                                                      77%|███████▋  | 2030/2628 [1:28:56<18:02,  1.81s/it] 77%|███████▋  | 2031/2628 [1:28:58<18:03,  1.81s/it] 77%|███████▋  | 2032/2628 [1:29:00<17:59,  1.81s/it] 77%|███████▋  | 2033/2628 [1:29:02<17:58,  1.81s/it] 77%|███████▋  | 2034/2628 [1:29:03<17:54,  1.81s/it] 77%|███████▋  | 2035/2628 [1:29:05<17:52,  1.81s/it] 77%|███████▋  | 2036/2628 [1:29:07<17:49,  1.81s/it] 78%|███████▊  | 2037/2628 [1:29:09<17:48,  1.81s/it] 78%|███████▊  | 2038/2628 [1:29:11<17:45,  1.81s/it] 78%|███████▊  | 2039/2628 [1:29:12<17:43,  1.81s/it] 78%|███████▊  | 2040/2628 [1:29:14<17:43,  1.81s/it]                                                      78%|███████▊  | 2040/2628 [1:29:14<17:43,  1.81s/it] 78%|███████▊  | 2041/2628 [1:29:16<17:40,  1.81s/it] 78%|███████▊  | 2042/2628 [1:29:18<17:40,  1.81s/it] 78%|███████▊  | 2043/2628 [1:29:20<17:40,  1.81s/it] 78%|███████▊  | 2044/2628 [1:29:21<17:36,  1.81s/it] 78%|███████▊  | 2045/2628 [1:29:23<17:33,  1.81s/it] 78%|███████▊  | 2046/2628 [1:29:25<17:31,  1.81s/it] 78%|███████▊  | 2047/2628 [1:29:27<17:28,  1.81s/it] 78%|███████▊  | 2048/2628 [1:29:29<17:26,  1.80s/it] 78%|███████▊  | 2049/2628 [1:29:30<17:27,  1.81s/it] 78%|███████▊  | 2050/2628 [1:29:32<17:24,  1.81s/it]                                                      78%|███████▊  | 2050/2628 [1:29:32<17:24,  1.81s/it] 78%|███████▊  | 2051/2628 [1:29:34<17:23,  1.81s/it] 78%|███████▊  | 2052/2628 [1:29:36<17:19,  1.81s/it] 78%|███████▊  | 2053/2628 [1:29:38<17:17,  1.81s/it] 78%|███████▊  | 2054/2628 [1:29:39<17:15,  1.80s/it] 78%|███████▊  | 2055/2628 [1:29:41<17:15,  1.81s/it] 78%|███████▊  | 2056/2628 [1:29:43<17:12,  1.81s/it] 78%|███████▊  | 2057/2628 [1:29:45<17:10,  1.81s/it] 78%|███████▊  | 2058/2628 [1:29:47<17:08,  1.80s/it] 78%|███████▊  | 2059/2628 [1:29:49<17:07,  1.81s/it] 78%|███████▊  | 2060/2628 [1:29:50<17:05,  1.81s/it]                                                      78%|███████▊  | 2060/2628 [1:29:50<17:05,  1.81s/it] 78%|███████▊  | 2061/2628 [1:29:52<17:03,  1.80s/it] 78%|███████▊  | 2062/2628 [1:29:54<17:02,  1.81s/it] 79%|███████▊  | 2063/2628 [1:29:56<16:59,  1.81s/it] 79%|███████▊  | 2064/2628 [1:29:58<16:58,  1.81s/it] 79%|███████▊  | 2065/2628 [1:29:59<16:58,  1.81s/it] 79%|███████▊  | 2066/2628 [1:30:01<16:54,  1.81s/it] 79%|███████▊  | 2067/2628 [1:30:03<16:54,  1.81s/it] 79%|███████▊  | 2068/2628 [1:30:05<16:53,  1.81s/it] 79%|███████▊  | 2069/2628 [1:30:07<16:52,  1.81s/it] 79%|███████▉  | 2070/2628 [1:30:08<16:52,  1.81s/it]                                                      79%|███████▉  | 2070/2628 [1:30:08<16:52,  1.81s/it] 79%|███████▉  | 2071/2628 [1:30:10<16:51,  1.82s/it] 79%|███████▉  | 2072/2628 [1:30:12<16:48,  1.81s/it] 79%|███████▉  | 2073/2628 [1:30:14<16:45,  1.81s/it] 79%|███████▉  | 2074/2628 [1:30:16<16:42,  1.81s/it] 79%|███████▉  | 2075/2628 [1:30:17<16:39,  1.81s/it] 79%|███████▉  | 2076/2628 [1:30:19<16:38,  1.81s/it] 79%|███████▉  | 2077/2628 [1:30:21<16:35,  1.81s/it] 79%|███████▉  | 2078/2628 [1:30:23<16:37,  1.81s/it] 79%|███████▉  | 2079/2628 [1:30:25<16:35,  1.81s/it] 79%|███████▉  | 2080/2628 [1:30:27<16:33,  1.81s/it]                                                      79%|███████▉  | 2080/2628 [1:30:27<16:33,  1.81s/it] 79%|███████▉  | 2081/2628 [1:30:28<16:33,  1.82s/it] 79%|███████▉  | 2082/2628 [1:30:30<16:30,  1.81s/it] 79%|███████▉  | 2083/2628 [1:30:32<16:26,  1.81s/it] 79%|███████▉  | 2084/2628 [1:30:34<16:24,  1.81s/it] 79%|███████▉  | 2085/2628 [1:30:36<16:21,  1.81s/it] 79%|███████▉  | 2086/2628 [1:30:37<16:19,  1.81s/it] 79%|███████▉  | 2087/2628 [1:30:39<16:19,  1.81s/it] 79%|███████▉  | 2088/2628 [1:30:41<16:17,  1.81s/it] 79%|███████▉  | 2089/2628 [1:30:43<16:13,  1.81s/it] 80%|███████▉  | 2090/2628 [1:30:45<16:14,  1.81s/it]                                                      80%|███████▉  | 2090/2628 [1:30:45<16:14,  1.81s/it] 80%|███████▉  | 2091/2628 [1:30:46<16:14,  1.81s/it] 80%|███████▉  | 2092/2628 [1:30:48<16:11,  1.81s/it] 80%|███████▉  | 2093/2628 [1:30:50<16:07,  1.81s/it] 80%|███████▉  | 2094/2628 [1:30:52<16:07,  1.81s/it] 80%|███████▉  | 2095/2628 [1:30:54<16:06,  1.81s/it] 80%|███████▉  | 2096/2628 [1:30:56<16:03,  1.81s/it] 80%|███████▉  | 2097/2628 [1:30:57<16:03,  1.81s/it] 80%|███████▉  | 2098/2628 [1:30:59<16:02,  1.82s/it] 80%|███████▉  | 2099/2628 [1:31:01<15:59,  1.81s/it] 80%|███████▉  | 2100/2628 [1:31:03<15:59,  1.82s/it]                                                      80%|███████▉  | 2100/2628 [1:31:03<15:59,  1.82s/it][INFO|trainer.py:4643] 2025-10-21 18:27:28,118 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 18:27:28,118 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 18:27:28,118 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:27:28,608 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:27:33,732 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:03<00:01,  1.78s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:27:37,347 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:08<00:00,  3.19s/it][A                                                     
                                             [A 80%|███████▉  | 2100/2628 [1:31:17<15:59,  1.82s/it]
100%|██████████| 3/3 [00:08<00:00,  3.19s/it][A
                                             [A 80%|███████▉  | 2101/2628 [1:31:19<54:09,  6.17s/it] 80%|███████▉  | 2102/2628 [1:31:21<42:35,  4.86s/it] 80%|████████  | 2103/2628 [1:31:23<34:31,  3.95s/it] 80%|████████  | 2104/2628 [1:31:25<28:51,  3.30s/it] 80%|████████  | 2105/2628 [1:31:26<24:52,  2.85s/it] 80%|████████  | 2106/2628 [1:31:28<22:05,  2.54s/it] 80%|████████  | 2107/2628 [1:31:30<20:08,  2.32s/it] 80%|████████  | 2108/2628 [1:31:32<18:46,  2.17s/it] 80%|████████  | 2109/2628 [1:31:34<17:47,  2.06s/it] 80%|████████  | 2110/2628 [1:31:36<17:54,  2.07s/it]                                                      80%|████████  | 2110/2628 [1:31:36<17:54,  2.07s/it] 80%|████████  | 2111/2628 [1:31:37<17:13,  2.00s/it] 80%|████████  | 2112/2628 [1:31:39<16:41,  1.94s/it] 80%|████████  | 2113/2628 [1:31:41<16:17,  1.90s/it] 80%|████████  | 2114/2628 [1:31:43<16:02,  1.87s/it] 80%|████████  | 2115/2628 [1:31:45<15:52,  1.86s/it] 81%|████████  | 2116/2628 [1:31:47<15:44,  1.84s/it] 81%|████████  | 2117/2628 [1:31:48<15:37,  1.84s/it] 81%|████████  | 2118/2628 [1:31:50<15:31,  1.83s/it] 81%|████████  | 2119/2628 [1:31:52<15:25,  1.82s/it] 81%|████████  | 2120/2628 [1:31:54<15:24,  1.82s/it]                                                      81%|████████  | 2120/2628 [1:31:54<15:24,  1.82s/it] 81%|████████  | 2121/2628 [1:31:56<15:23,  1.82s/it] 81%|████████  | 2122/2628 [1:31:57<15:19,  1.82s/it] 81%|████████  | 2123/2628 [1:31:59<15:18,  1.82s/it] 81%|████████  | 2124/2628 [1:32:01<15:16,  1.82s/it] 81%|████████  | 2125/2628 [1:32:03<15:14,  1.82s/it] 81%|████████  | 2126/2628 [1:32:05<15:11,  1.82s/it] 81%|████████  | 2127/2628 [1:32:06<15:07,  1.81s/it] 81%|████████  | 2128/2628 [1:32:08<15:05,  1.81s/it] 81%|████████  | 2129/2628 [1:32:10<15:03,  1.81s/it] 81%|████████  | 2130/2628 [1:32:12<15:01,  1.81s/it]                                                      81%|████████  | 2130/2628 [1:32:12<15:01,  1.81s/it] 81%|████████  | 2131/2628 [1:32:14<14:58,  1.81s/it] 81%|████████  | 2132/2628 [1:32:16<14:57,  1.81s/it] 81%|████████  | 2133/2628 [1:32:17<14:54,  1.81s/it] 81%|████████  | 2134/2628 [1:32:19<14:52,  1.81s/it] 81%|████████  | 2135/2628 [1:32:21<14:52,  1.81s/it] 81%|████████▏ | 2136/2628 [1:32:23<14:51,  1.81s/it] 81%|████████▏ | 2137/2628 [1:32:25<14:50,  1.81s/it] 81%|████████▏ | 2138/2628 [1:32:26<14:47,  1.81s/it] 81%|████████▏ | 2139/2628 [1:32:28<14:44,  1.81s/it] 81%|████████▏ | 2140/2628 [1:32:30<14:43,  1.81s/it]                                                      81%|████████▏ | 2140/2628 [1:32:30<14:43,  1.81s/it] 81%|████████▏ | 2141/2628 [1:32:32<14:42,  1.81s/it] 82%|████████▏ | 2142/2628 [1:32:34<14:39,  1.81s/it] 82%|████████▏ | 2143/2628 [1:32:35<14:38,  1.81s/it] 82%|████████▏ | 2144/2628 [1:32:37<14:37,  1.81s/it] 82%|████████▏ | 2145/2628 [1:32:39<14:33,  1.81s/it] 82%|████████▏ | 2146/2628 [1:32:41<14:31,  1.81s/it] 82%|████████▏ | 2147/2628 [1:32:43<14:31,  1.81s/it] 82%|████████▏ | 2148/2628 [1:32:45<14:29,  1.81s/it] 82%|████████▏ | 2149/2628 [1:32:46<14:28,  1.81s/it] 82%|████████▏ | 2150/2628 [1:32:48<14:25,  1.81s/it]                                                      82%|████████▏ | 2150/2628 [1:32:48<14:25,  1.81s/it] 82%|████████▏ | 2151/2628 [1:32:50<14:23,  1.81s/it] 82%|████████▏ | 2152/2628 [1:32:52<14:22,  1.81s/it] 82%|████████▏ | 2153/2628 [1:32:54<14:20,  1.81s/it] 82%|████████▏ | 2154/2628 [1:32:55<14:19,  1.81s/it] 82%|████████▏ | 2155/2628 [1:32:57<14:17,  1.81s/it] 82%|████████▏ | 2156/2628 [1:32:59<14:15,  1.81s/it] 82%|████████▏ | 2157/2628 [1:33:01<14:12,  1.81s/it] 82%|████████▏ | 2158/2628 [1:33:03<14:11,  1.81s/it] 82%|████████▏ | 2159/2628 [1:33:04<14:09,  1.81s/it] 82%|████████▏ | 2160/2628 [1:33:06<14:07,  1.81s/it]                                                      82%|████████▏ | 2160/2628 [1:33:06<14:07,  1.81s/it] 82%|████████▏ | 2161/2628 [1:33:08<14:04,  1.81s/it] 82%|████████▏ | 2162/2628 [1:33:10<14:01,  1.81s/it] 82%|████████▏ | 2163/2628 [1:33:12<13:59,  1.81s/it] 82%|████████▏ | 2164/2628 [1:33:13<13:57,  1.81s/it] 82%|████████▏ | 2165/2628 [1:33:15<13:56,  1.81s/it] 82%|████████▏ | 2166/2628 [1:33:17<13:54,  1.81s/it] 82%|████████▏ | 2167/2628 [1:33:19<13:52,  1.81s/it] 82%|████████▏ | 2168/2628 [1:33:21<13:51,  1.81s/it] 83%|████████▎ | 2169/2628 [1:33:22<13:49,  1.81s/it] 83%|████████▎ | 2170/2628 [1:33:24<13:47,  1.81s/it]                                                      83%|████████▎ | 2170/2628 [1:33:24<13:47,  1.81s/it] 83%|████████▎ | 2171/2628 [1:33:26<13:45,  1.81s/it] 83%|████████▎ | 2172/2628 [1:33:28<13:43,  1.81s/it] 83%|████████▎ | 2173/2628 [1:33:30<13:41,  1.81s/it] 83%|████████▎ | 2174/2628 [1:33:32<13:39,  1.80s/it] 83%|████████▎ | 2175/2628 [1:33:33<13:39,  1.81s/it] 83%|████████▎ | 2176/2628 [1:33:35<13:37,  1.81s/it] 83%|████████▎ | 2177/2628 [1:33:37<13:37,  1.81s/it] 83%|████████▎ | 2178/2628 [1:33:39<13:35,  1.81s/it] 83%|████████▎ | 2179/2628 [1:33:41<13:32,  1.81s/it] 83%|████████▎ | 2180/2628 [1:33:42<13:30,  1.81s/it]                                                      83%|████████▎ | 2180/2628 [1:33:42<13:30,  1.81s/it] 83%|████████▎ | 2181/2628 [1:33:44<13:28,  1.81s/it] 83%|████████▎ | 2182/2628 [1:33:46<13:26,  1.81s/it] 83%|████████▎ | 2183/2628 [1:33:48<13:24,  1.81s/it] 83%|████████▎ | 2184/2628 [1:33:50<13:22,  1.81s/it] 83%|████████▎ | 2185/2628 [1:33:51<13:20,  1.81s/it] 83%|████████▎ | 2186/2628 [1:33:53<13:18,  1.81s/it] 83%|████████▎ | 2187/2628 [1:33:55<13:16,  1.81s/it] 83%|████████▎ | 2188/2628 [1:33:57<13:15,  1.81s/it] 83%|████████▎ | 2189/2628 [1:33:59<13:14,  1.81s/it] 83%|████████▎ | 2190/2628 [1:34:00<13:12,  1.81s/it]                                                      83%|████████▎ | 2190/2628 [1:34:00<13:12,  1.81s/it] 83%|████████▎ | 2191/2628 [1:34:02<13:10,  1.81s/it] 83%|████████▎ | 2192/2628 [1:34:04<13:10,  1.81s/it] 83%|████████▎ | 2193/2628 [1:34:06<13:09,  1.81s/it] 83%|████████▎ | 2194/2628 [1:34:08<13:05,  1.81s/it] 84%|████████▎ | 2195/2628 [1:34:10<13:03,  1.81s/it] 84%|████████▎ | 2196/2628 [1:34:11<13:04,  1.82s/it] 84%|████████▎ | 2197/2628 [1:34:13<13:02,  1.81s/it] 84%|████████▎ | 2198/2628 [1:34:15<12:59,  1.81s/it] 84%|████████▎ | 2199/2628 [1:34:17<12:56,  1.81s/it] 84%|████████▎ | 2200/2628 [1:34:19<12:54,  1.81s/it]                                                      84%|████████▎ | 2200/2628 [1:34:19<12:54,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 18:30:43,924 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 18:30:43,924 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 18:30:43,924 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:30:44,404 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:30:47,895 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:03<00:01,  1.56s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:30:51,081 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:07<00:00,  2.59s/it][A                                                     
                                             [A 84%|████████▎ | 2200/2628 [1:34:30<12:54,  1.81s/it]
100%|██████████| 3/3 [00:07<00:00,  2.59s/it][A
                                             [A 84%|████████▍ | 2201/2628 [1:34:32<36:59,  5.20s/it] 84%|████████▍ | 2202/2628 [1:34:33<29:41,  4.18s/it] 84%|████████▍ | 2203/2628 [1:34:35<24:35,  3.47s/it] 84%|████████▍ | 2204/2628 [1:34:37<21:00,  2.97s/it] 84%|████████▍ | 2205/2628 [1:34:39<18:29,  2.62s/it] 84%|████████▍ | 2206/2628 [1:34:41<16:43,  2.38s/it] 84%|████████▍ | 2207/2628 [1:34:43<15:31,  2.21s/it] 84%|████████▍ | 2208/2628 [1:34:44<14:36,  2.09s/it] 84%|████████▍ | 2209/2628 [1:34:46<13:59,  2.00s/it] 84%|████████▍ | 2210/2628 [1:34:48<13:33,  1.95s/it]                                                      84%|████████▍ | 2210/2628 [1:34:48<13:33,  1.95s/it] 84%|████████▍ | 2211/2628 [1:34:50<13:15,  1.91s/it] 84%|████████▍ | 2212/2628 [1:34:52<13:00,  1.88s/it] 84%|████████▍ | 2213/2628 [1:34:53<12:52,  1.86s/it] 84%|████████▍ | 2214/2628 [1:34:55<12:43,  1.84s/it] 84%|████████▍ | 2215/2628 [1:34:57<12:38,  1.84s/it] 84%|████████▍ | 2216/2628 [1:34:59<12:32,  1.83s/it] 84%|████████▍ | 2217/2628 [1:35:01<12:30,  1.83s/it] 84%|████████▍ | 2218/2628 [1:35:02<12:27,  1.82s/it] 84%|████████▍ | 2219/2628 [1:35:04<12:24,  1.82s/it] 84%|████████▍ | 2220/2628 [1:35:06<12:20,  1.82s/it]                                                      84%|████████▍ | 2220/2628 [1:35:06<12:20,  1.82s/it] 85%|████████▍ | 2221/2628 [1:35:08<12:19,  1.82s/it] 85%|████████▍ | 2222/2628 [1:35:10<12:18,  1.82s/it] 85%|████████▍ | 2223/2628 [1:35:12<12:16,  1.82s/it] 85%|████████▍ | 2224/2628 [1:35:13<12:13,  1.81s/it] 85%|████████▍ | 2225/2628 [1:35:15<12:09,  1.81s/it] 85%|████████▍ | 2226/2628 [1:35:17<12:07,  1.81s/it] 85%|████████▍ | 2227/2628 [1:35:19<12:04,  1.81s/it] 85%|████████▍ | 2228/2628 [1:35:21<12:03,  1.81s/it] 85%|████████▍ | 2229/2628 [1:35:22<12:00,  1.81s/it] 85%|████████▍ | 2230/2628 [1:35:24<11:58,  1.81s/it]                                                      85%|████████▍ | 2230/2628 [1:35:24<11:58,  1.81s/it] 85%|████████▍ | 2231/2628 [1:35:26<11:59,  1.81s/it] 85%|████████▍ | 2232/2628 [1:35:28<11:58,  1.81s/it] 85%|████████▍ | 2233/2628 [1:35:30<11:55,  1.81s/it] 85%|████████▌ | 2234/2628 [1:35:31<11:52,  1.81s/it] 85%|████████▌ | 2235/2628 [1:35:33<11:52,  1.81s/it] 85%|████████▌ | 2236/2628 [1:35:35<11:52,  1.82s/it] 85%|████████▌ | 2237/2628 [1:35:37<11:50,  1.82s/it] 85%|████████▌ | 2238/2628 [1:35:39<11:47,  1.81s/it] 85%|████████▌ | 2239/2628 [1:35:41<11:45,  1.81s/it] 85%|████████▌ | 2240/2628 [1:35:42<11:43,  1.81s/it]                                                      85%|████████▌ | 2240/2628 [1:35:42<11:43,  1.81s/it] 85%|████████▌ | 2241/2628 [1:35:44<11:40,  1.81s/it] 85%|████████▌ | 2242/2628 [1:35:46<11:38,  1.81s/it] 85%|████████▌ | 2243/2628 [1:35:48<11:37,  1.81s/it] 85%|████████▌ | 2244/2628 [1:35:50<11:34,  1.81s/it] 85%|████████▌ | 2245/2628 [1:35:51<11:33,  1.81s/it] 85%|████████▌ | 2246/2628 [1:35:53<11:31,  1.81s/it] 86%|████████▌ | 2247/2628 [1:35:55<11:28,  1.81s/it] 86%|████████▌ | 2248/2628 [1:35:57<11:26,  1.81s/it] 86%|████████▌ | 2249/2628 [1:35:59<11:23,  1.80s/it] 86%|████████▌ | 2250/2628 [1:36:00<11:21,  1.80s/it]                                                      86%|████████▌ | 2250/2628 [1:36:00<11:21,  1.80s/it] 86%|████████▌ | 2251/2628 [1:36:02<11:20,  1.80s/it] 86%|████████▌ | 2252/2628 [1:36:04<11:18,  1.80s/it] 86%|████████▌ | 2253/2628 [1:36:06<11:16,  1.80s/it] 86%|████████▌ | 2254/2628 [1:36:08<11:14,  1.80s/it] 86%|████████▌ | 2255/2628 [1:36:09<11:15,  1.81s/it] 86%|████████▌ | 2256/2628 [1:36:11<11:14,  1.81s/it] 86%|████████▌ | 2257/2628 [1:36:13<11:48,  1.91s/it] 86%|████████▌ | 2258/2628 [1:36:15<11:35,  1.88s/it] 86%|████████▌ | 2259/2628 [1:36:17<11:27,  1.86s/it] 86%|████████▌ | 2260/2628 [1:36:19<11:19,  1.85s/it]                                                      86%|████████▌ | 2260/2628 [1:36:19<11:19,  1.85s/it] 86%|████████▌ | 2261/2628 [1:36:21<11:15,  1.84s/it] 86%|████████▌ | 2262/2628 [1:36:22<11:10,  1.83s/it] 86%|████████▌ | 2263/2628 [1:36:24<11:07,  1.83s/it] 86%|████████▌ | 2264/2628 [1:36:26<11:02,  1.82s/it] 86%|████████▌ | 2265/2628 [1:36:28<10:58,  1.81s/it] 86%|████████▌ | 2266/2628 [1:36:30<10:55,  1.81s/it] 86%|████████▋ | 2267/2628 [1:36:32<10:54,  1.81s/it] 86%|████████▋ | 2268/2628 [1:36:33<10:52,  1.81s/it] 86%|████████▋ | 2269/2628 [1:36:35<10:49,  1.81s/it] 86%|████████▋ | 2270/2628 [1:36:37<10:49,  1.81s/it]                                                      86%|████████▋ | 2270/2628 [1:36:37<10:49,  1.81s/it] 86%|████████▋ | 2271/2628 [1:36:39<10:46,  1.81s/it] 86%|████████▋ | 2272/2628 [1:36:41<10:44,  1.81s/it] 86%|████████▋ | 2273/2628 [1:36:42<10:43,  1.81s/it] 87%|████████▋ | 2274/2628 [1:36:44<10:40,  1.81s/it] 87%|████████▋ | 2275/2628 [1:36:46<10:38,  1.81s/it] 87%|████████▋ | 2276/2628 [1:36:48<10:36,  1.81s/it] 87%|████████▋ | 2277/2628 [1:36:50<10:36,  1.81s/it] 87%|████████▋ | 2278/2628 [1:36:51<10:33,  1.81s/it] 87%|████████▋ | 2279/2628 [1:36:53<10:30,  1.81s/it] 87%|████████▋ | 2280/2628 [1:36:55<10:28,  1.81s/it]                                                      87%|████████▋ | 2280/2628 [1:36:55<10:28,  1.81s/it] 87%|████████▋ | 2281/2628 [1:36:57<10:27,  1.81s/it] 87%|████████▋ | 2282/2628 [1:36:59<10:24,  1.81s/it] 87%|████████▋ | 2283/2628 [1:37:00<10:24,  1.81s/it] 87%|████████▋ | 2284/2628 [1:37:02<10:22,  1.81s/it] 87%|████████▋ | 2285/2628 [1:37:04<10:22,  1.82s/it] 87%|████████▋ | 2286/2628 [1:37:06<10:20,  1.82s/it] 87%|████████▋ | 2287/2628 [1:37:08<10:18,  1.81s/it] 87%|████████▋ | 2288/2628 [1:37:10<10:15,  1.81s/it] 87%|████████▋ | 2289/2628 [1:37:11<10:14,  1.81s/it] 87%|████████▋ | 2290/2628 [1:37:13<10:13,  1.81s/it]                                                      87%|████████▋ | 2290/2628 [1:37:13<10:13,  1.81s/it] 87%|████████▋ | 2291/2628 [1:37:15<10:12,  1.82s/it] 87%|████████▋ | 2292/2628 [1:37:17<10:10,  1.82s/it] 87%|████████▋ | 2293/2628 [1:37:19<10:08,  1.82s/it] 87%|████████▋ | 2294/2628 [1:37:20<10:06,  1.81s/it] 87%|████████▋ | 2295/2628 [1:37:22<10:03,  1.81s/it] 87%|████████▋ | 2296/2628 [1:37:24<10:01,  1.81s/it] 87%|████████▋ | 2297/2628 [1:37:26<09:58,  1.81s/it] 87%|████████▋ | 2298/2628 [1:37:28<09:56,  1.81s/it] 87%|████████▋ | 2299/2628 [1:37:29<09:54,  1.81s/it] 88%|████████▊ | 2300/2628 [1:37:31<09:53,  1.81s/it]                                                      88%|████████▊ | 2300/2628 [1:37:31<09:53,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 18:33:56,625 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 18:33:56,625 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 18:33:56,625 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:33:57,107 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][A[WARNING|utils.py:2443] 2025-10-21 18:34:53,216 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:03<00:01,  1.60s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:34:56,498 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:06<00:00,  2.44s/it][A                                                     
                                             [A 88%|████████▊ | 2300/2628 [1:38:35<09:53,  1.81s/it]
100%|██████████| 3/3 [00:06<00:00,  2.44s/it][A
                                             [A 88%|████████▊ | 2301/2628 [1:38:37<1:53:51, 20.89s/it] 88%|████████▊ | 2302/2628 [1:38:39<1:22:24, 15.17s/it] 88%|████████▊ | 2303/2628 [1:38:40<1:00:25, 11.16s/it] 88%|████████▊ | 2304/2628 [1:38:42<45:05,  8.35s/it]   88%|████████▊ | 2305/2628 [1:38:44<34:22,  6.39s/it] 88%|████████▊ | 2306/2628 [1:38:46<26:53,  5.01s/it] 88%|████████▊ | 2307/2628 [1:38:48<21:40,  4.05s/it] 88%|████████▊ | 2308/2628 [1:38:49<18:00,  3.38s/it] 88%|████████▊ | 2309/2628 [1:38:51<15:26,  2.90s/it] 88%|████████▊ | 2310/2628 [1:38:53<13:38,  2.57s/it]                                                      88%|████████▊ | 2310/2628 [1:38:53<13:38,  2.57s/it] 88%|████████▊ | 2311/2628 [1:38:55<12:22,  2.34s/it] 88%|████████▊ | 2312/2628 [1:38:57<11:29,  2.18s/it] 88%|████████▊ | 2313/2628 [1:38:58<10:52,  2.07s/it] 88%|████████▊ | 2314/2628 [1:39:00<10:25,  1.99s/it] 88%|████████▊ | 2315/2628 [1:39:02<10:05,  1.93s/it] 88%|████████▊ | 2316/2628 [1:39:04<09:51,  1.90s/it] 88%|████████▊ | 2317/2628 [1:39:06<09:41,  1.87s/it] 88%|████████▊ | 2318/2628 [1:39:07<09:33,  1.85s/it] 88%|████████▊ | 2319/2628 [1:39:09<09:27,  1.84s/it] 88%|████████▊ | 2320/2628 [1:39:11<09:23,  1.83s/it]                                                      88%|████████▊ | 2320/2628 [1:39:11<09:23,  1.83s/it] 88%|████████▊ | 2321/2628 [1:39:13<09:19,  1.82s/it] 88%|████████▊ | 2322/2628 [1:39:15<09:17,  1.82s/it] 88%|████████▊ | 2323/2628 [1:39:16<09:15,  1.82s/it] 88%|████████▊ | 2324/2628 [1:39:18<09:13,  1.82s/it] 88%|████████▊ | 2325/2628 [1:39:20<09:10,  1.82s/it] 89%|████████▊ | 2326/2628 [1:39:22<09:07,  1.81s/it] 89%|████████▊ | 2327/2628 [1:39:24<09:04,  1.81s/it] 89%|████████▊ | 2328/2628 [1:39:25<09:02,  1.81s/it] 89%|████████▊ | 2329/2628 [1:39:27<09:00,  1.81s/it] 89%|████████▊ | 2330/2628 [1:39:29<08:58,  1.81s/it]                                                      89%|████████▊ | 2330/2628 [1:39:29<08:58,  1.81s/it] 89%|████████▊ | 2331/2628 [1:39:31<08:56,  1.81s/it] 89%|████████▊ | 2332/2628 [1:39:33<08:55,  1.81s/it] 89%|████████▉ | 2333/2628 [1:39:35<08:53,  1.81s/it] 89%|████████▉ | 2334/2628 [1:39:36<08:51,  1.81s/it] 89%|████████▉ | 2335/2628 [1:39:38<08:49,  1.81s/it] 89%|████████▉ | 2336/2628 [1:39:40<08:47,  1.81s/it] 89%|████████▉ | 2337/2628 [1:39:42<08:45,  1.81s/it] 89%|████████▉ | 2338/2628 [1:39:44<08:45,  1.81s/it] 89%|████████▉ | 2339/2628 [1:39:45<08:43,  1.81s/it] 89%|████████▉ | 2340/2628 [1:39:47<08:42,  1.81s/it]                                                      89%|████████▉ | 2340/2628 [1:39:47<08:42,  1.81s/it] 89%|████████▉ | 2341/2628 [1:39:49<08:40,  1.81s/it] 89%|████████▉ | 2342/2628 [1:39:51<08:37,  1.81s/it] 89%|████████▉ | 2343/2628 [1:39:53<08:35,  1.81s/it] 89%|████████▉ | 2344/2628 [1:39:54<08:33,  1.81s/it] 89%|████████▉ | 2345/2628 [1:39:56<08:31,  1.81s/it] 89%|████████▉ | 2346/2628 [1:39:58<08:29,  1.81s/it] 89%|████████▉ | 2347/2628 [1:40:00<08:28,  1.81s/it] 89%|████████▉ | 2348/2628 [1:40:02<08:26,  1.81s/it] 89%|████████▉ | 2349/2628 [1:40:03<08:24,  1.81s/it] 89%|████████▉ | 2350/2628 [1:40:05<08:22,  1.81s/it]                                                      89%|████████▉ | 2350/2628 [1:40:05<08:22,  1.81s/it] 89%|████████▉ | 2351/2628 [1:40:07<08:20,  1.81s/it] 89%|████████▉ | 2352/2628 [1:40:09<08:47,  1.91s/it] 90%|████████▉ | 2353/2628 [1:40:11<08:38,  1.89s/it] 90%|████████▉ | 2354/2628 [1:40:13<08:30,  1.86s/it] 90%|████████▉ | 2355/2628 [1:40:15<08:23,  1.84s/it] 90%|████████▉ | 2356/2628 [1:40:16<08:19,  1.84s/it] 90%|████████▉ | 2357/2628 [1:40:18<08:15,  1.83s/it] 90%|████████▉ | 2358/2628 [1:40:20<08:12,  1.82s/it] 90%|████████▉ | 2359/2628 [1:40:22<08:10,  1.82s/it] 90%|████████▉ | 2360/2628 [1:40:24<08:07,  1.82s/it]                                                      90%|████████▉ | 2360/2628 [1:40:24<08:07,  1.82s/it] 90%|████████▉ | 2361/2628 [1:40:26<08:30,  1.91s/it] 90%|████████▉ | 2362/2628 [1:40:28<08:19,  1.88s/it] 90%|████████▉ | 2363/2628 [1:40:29<08:12,  1.86s/it] 90%|████████▉ | 2364/2628 [1:40:31<08:06,  1.84s/it] 90%|████████▉ | 2365/2628 [1:40:33<08:01,  1.83s/it] 90%|█████████ | 2366/2628 [1:40:35<07:57,  1.82s/it] 90%|█████████ | 2367/2628 [1:40:37<07:54,  1.82s/it] 90%|█████████ | 2368/2628 [1:40:39<07:51,  1.82s/it] 90%|█████████ | 2369/2628 [1:40:40<07:49,  1.81s/it] 90%|█████████ | 2370/2628 [1:40:42<07:47,  1.81s/it]                                                      90%|█████████ | 2370/2628 [1:40:42<07:47,  1.81s/it] 90%|█████████ | 2371/2628 [1:40:44<07:45,  1.81s/it] 90%|█████████ | 2372/2628 [1:40:46<07:43,  1.81s/it] 90%|█████████ | 2373/2628 [1:40:48<07:41,  1.81s/it] 90%|█████████ | 2374/2628 [1:40:49<07:39,  1.81s/it] 90%|█████████ | 2375/2628 [1:40:51<07:38,  1.81s/it] 90%|█████████ | 2376/2628 [1:40:53<07:35,  1.81s/it] 90%|█████████ | 2377/2628 [1:40:55<07:35,  1.82s/it] 90%|█████████ | 2378/2628 [1:40:57<07:32,  1.81s/it] 91%|█████████ | 2379/2628 [1:40:58<07:31,  1.81s/it] 91%|█████████ | 2380/2628 [1:41:00<07:28,  1.81s/it]                                                      91%|█████████ | 2380/2628 [1:41:00<07:28,  1.81s/it] 91%|█████████ | 2381/2628 [1:41:02<07:27,  1.81s/it] 91%|█████████ | 2382/2628 [1:41:04<07:24,  1.81s/it] 91%|█████████ | 2383/2628 [1:41:06<07:23,  1.81s/it] 91%|█████████ | 2384/2628 [1:41:07<07:21,  1.81s/it] 91%|█████████ | 2385/2628 [1:41:09<07:19,  1.81s/it] 91%|█████████ | 2386/2628 [1:41:11<07:18,  1.81s/it] 91%|█████████ | 2387/2628 [1:41:13<07:17,  1.82s/it] 91%|█████████ | 2388/2628 [1:41:15<07:15,  1.81s/it] 91%|█████████ | 2389/2628 [1:41:17<07:12,  1.81s/it] 91%|█████████ | 2390/2628 [1:41:18<07:10,  1.81s/it]                                                      91%|█████████ | 2390/2628 [1:41:18<07:10,  1.81s/it] 91%|█████████ | 2391/2628 [1:41:20<07:08,  1.81s/it] 91%|█████████ | 2392/2628 [1:41:22<07:06,  1.81s/it] 91%|█████████ | 2393/2628 [1:41:24<07:05,  1.81s/it] 91%|█████████ | 2394/2628 [1:41:26<07:03,  1.81s/it] 91%|█████████ | 2395/2628 [1:41:27<07:02,  1.81s/it] 91%|█████████ | 2396/2628 [1:41:29<06:59,  1.81s/it] 91%|█████████ | 2397/2628 [1:41:31<06:58,  1.81s/it] 91%|█████████ | 2398/2628 [1:41:33<06:56,  1.81s/it] 91%|█████████▏| 2399/2628 [1:41:35<06:53,  1.81s/it] 91%|█████████▏| 2400/2628 [1:41:36<06:52,  1.81s/it]                                                      91%|█████████▏| 2400/2628 [1:41:36<06:52,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 18:38:01,765 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 18:38:01,765 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 18:38:01,765 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:38:02,244 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:38:07,767 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:03<00:01,  1.83s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:38:11,509 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:07<00:00,  2.74s/it][A                                                     
                                             [A 91%|█████████▏| 2400/2628 [1:41:50<06:52,  1.81s/it]
100%|██████████| 3/3 [00:07<00:00,  2.74s/it][A
                                             [A[INFO|trainer.py:4309] 2025-10-21 18:38:15,607 >> Saving model checkpoint to saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2400
[INFO|configuration_utils.py:491] 2025-10-21 18:38:15,613 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2400/config.json
[INFO|configuration_utils.py:757] 2025-10-21 18:38:15,614 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2400/generation_config.json
[INFO|modeling_utils.py:4189] 2025-10-21 18:38:19,499 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2400/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2421] 2025-10-21 18:38:19,501 >> chat template saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2400/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-21 18:38:19,501 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-21 18:38:19,502 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2400/special_tokens_map.json
[INFO|image_processing_base.py:253] 2025-10-21 18:38:24,413 >> Image processor saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2400/preprocessor_config.json
[INFO|tokenization_utils_base.py:2421] 2025-10-21 18:38:24,414 >> chat template saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2400/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-21 18:38:24,415 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-21 18:38:24,415 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2400/special_tokens_map.json
[INFO|video_processing_utils.py:600] 2025-10-21 18:38:24,501 >> Video processor saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2400/video_preprocessor_config.json
[INFO|processing_utils.py:814] 2025-10-21 18:38:24,502 >> chat template saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2400/chat_template.jinja
 91%|█████████▏| 2401/2628 [1:42:01<32:54,  8.70s/it] 91%|█████████▏| 2402/2628 [1:42:03<24:59,  6.63s/it] 91%|█████████▏| 2403/2628 [1:42:05<19:27,  5.19s/it] 91%|█████████▏| 2404/2628 [1:42:07<15:34,  4.17s/it] 92%|█████████▏| 2405/2628 [1:42:08<12:51,  3.46s/it] 92%|█████████▏| 2406/2628 [1:42:10<10:58,  2.96s/it] 92%|█████████▏| 2407/2628 [1:42:12<09:38,  2.62s/it] 92%|█████████▏| 2408/2628 [1:42:14<08:42,  2.38s/it] 92%|█████████▏| 2409/2628 [1:42:16<08:02,  2.20s/it] 92%|█████████▏| 2410/2628 [1:42:17<07:34,  2.08s/it]                                                      92%|█████████▏| 2410/2628 [1:42:17<07:34,  2.08s/it] 92%|█████████▏| 2411/2628 [1:42:19<07:13,  2.00s/it] 92%|█████████▏| 2412/2628 [1:42:21<06:59,  1.94s/it] 92%|█████████▏| 2413/2628 [1:42:23<06:48,  1.90s/it] 92%|█████████▏| 2414/2628 [1:42:25<06:40,  1.87s/it] 92%|█████████▏| 2415/2628 [1:42:26<06:34,  1.85s/it] 92%|█████████▏| 2416/2628 [1:42:28<06:29,  1.84s/it] 92%|█████████▏| 2417/2628 [1:42:30<06:25,  1.83s/it] 92%|█████████▏| 2418/2628 [1:42:32<06:22,  1.82s/it] 92%|█████████▏| 2419/2628 [1:42:34<06:20,  1.82s/it] 92%|█████████▏| 2420/2628 [1:42:36<06:17,  1.81s/it]                                                      92%|█████████▏| 2420/2628 [1:42:36<06:17,  1.81s/it] 92%|█████████▏| 2421/2628 [1:42:37<06:16,  1.82s/it] 92%|█████████▏| 2422/2628 [1:42:39<06:14,  1.82s/it] 92%|█████████▏| 2423/2628 [1:42:41<06:12,  1.82s/it] 92%|█████████▏| 2424/2628 [1:42:43<06:09,  1.81s/it] 92%|█████████▏| 2425/2628 [1:42:45<06:08,  1.81s/it] 92%|█████████▏| 2426/2628 [1:42:46<06:05,  1.81s/it] 92%|█████████▏| 2427/2628 [1:42:48<06:04,  1.81s/it] 92%|█████████▏| 2428/2628 [1:42:50<06:02,  1.81s/it] 92%|█████████▏| 2429/2628 [1:42:52<05:59,  1.81s/it] 92%|█████████▏| 2430/2628 [1:42:54<05:57,  1.81s/it]                                                      92%|█████████▏| 2430/2628 [1:42:54<05:57,  1.81s/it] 93%|█████████▎| 2431/2628 [1:42:55<05:56,  1.81s/it] 93%|█████████▎| 2432/2628 [1:42:57<05:54,  1.81s/it] 93%|█████████▎| 2433/2628 [1:42:59<05:52,  1.81s/it] 93%|█████████▎| 2434/2628 [1:43:01<05:50,  1.81s/it] 93%|█████████▎| 2435/2628 [1:43:03<05:48,  1.80s/it] 93%|█████████▎| 2436/2628 [1:43:04<05:46,  1.81s/it] 93%|█████████▎| 2437/2628 [1:43:06<05:45,  1.81s/it] 93%|█████████▎| 2438/2628 [1:43:08<05:42,  1.81s/it] 93%|█████████▎| 2439/2628 [1:43:10<05:42,  1.81s/it] 93%|█████████▎| 2440/2628 [1:43:12<05:40,  1.81s/it]                                                      93%|█████████▎| 2440/2628 [1:43:12<05:40,  1.81s/it] 93%|█████████▎| 2441/2628 [1:43:14<05:37,  1.81s/it] 93%|█████████▎| 2442/2628 [1:43:15<05:35,  1.81s/it] 93%|█████████▎| 2443/2628 [1:43:17<05:33,  1.80s/it] 93%|█████████▎| 2444/2628 [1:43:19<05:32,  1.81s/it] 93%|█████████▎| 2445/2628 [1:43:21<05:30,  1.81s/it] 93%|█████████▎| 2446/2628 [1:43:23<05:29,  1.81s/it] 93%|█████████▎| 2447/2628 [1:43:24<05:27,  1.81s/it] 93%|█████████▎| 2448/2628 [1:43:26<05:25,  1.81s/it] 93%|█████████▎| 2449/2628 [1:43:28<05:23,  1.81s/it] 93%|█████████▎| 2450/2628 [1:43:30<05:22,  1.81s/it]                                                      93%|█████████▎| 2450/2628 [1:43:30<05:22,  1.81s/it] 93%|█████████▎| 2451/2628 [1:43:32<05:20,  1.81s/it] 93%|█████████▎| 2452/2628 [1:43:33<05:18,  1.81s/it] 93%|█████████▎| 2453/2628 [1:43:35<05:16,  1.81s/it] 93%|█████████▎| 2454/2628 [1:43:37<05:14,  1.81s/it] 93%|█████████▎| 2455/2628 [1:43:39<05:12,  1.80s/it] 93%|█████████▎| 2456/2628 [1:43:41<05:10,  1.80s/it] 93%|█████████▎| 2457/2628 [1:43:42<05:08,  1.80s/it] 94%|█████████▎| 2458/2628 [1:43:44<05:06,  1.80s/it] 94%|█████████▎| 2459/2628 [1:43:46<05:04,  1.80s/it] 94%|█████████▎| 2460/2628 [1:43:48<05:02,  1.80s/it]                                                      94%|█████████▎| 2460/2628 [1:43:48<05:02,  1.80s/it] 94%|█████████▎| 2461/2628 [1:43:50<05:01,  1.81s/it] 94%|█████████▎| 2462/2628 [1:43:51<05:00,  1.81s/it] 94%|█████████▎| 2463/2628 [1:43:53<04:58,  1.81s/it] 94%|█████████▍| 2464/2628 [1:43:55<04:56,  1.80s/it] 94%|█████████▍| 2465/2628 [1:43:57<04:54,  1.80s/it] 94%|█████████▍| 2466/2628 [1:43:59<04:52,  1.80s/it] 94%|█████████▍| 2467/2628 [1:44:00<04:50,  1.80s/it] 94%|█████████▍| 2468/2628 [1:44:02<04:49,  1.81s/it] 94%|█████████▍| 2469/2628 [1:44:04<04:47,  1.81s/it] 94%|█████████▍| 2470/2628 [1:44:06<04:45,  1.81s/it]                                                      94%|█████████▍| 2470/2628 [1:44:06<04:45,  1.81s/it] 94%|█████████▍| 2471/2628 [1:44:08<04:43,  1.81s/it] 94%|█████████▍| 2472/2628 [1:44:09<04:41,  1.80s/it] 94%|█████████▍| 2473/2628 [1:44:11<04:39,  1.80s/it] 94%|█████████▍| 2474/2628 [1:44:13<04:37,  1.81s/it] 94%|█████████▍| 2475/2628 [1:44:15<04:36,  1.81s/it] 94%|█████████▍| 2476/2628 [1:44:17<04:34,  1.81s/it] 94%|█████████▍| 2477/2628 [1:44:19<04:32,  1.81s/it] 94%|█████████▍| 2478/2628 [1:44:20<04:31,  1.81s/it] 94%|█████████▍| 2479/2628 [1:44:22<04:29,  1.81s/it] 94%|█████████▍| 2480/2628 [1:44:24<04:27,  1.81s/it]                                                      94%|█████████▍| 2480/2628 [1:44:24<04:27,  1.81s/it] 94%|█████████▍| 2481/2628 [1:44:26<04:25,  1.81s/it] 94%|█████████▍| 2482/2628 [1:44:28<04:23,  1.80s/it] 94%|█████████▍| 2483/2628 [1:44:29<04:21,  1.80s/it] 95%|█████████▍| 2484/2628 [1:44:31<04:20,  1.81s/it] 95%|█████████▍| 2485/2628 [1:44:33<04:18,  1.81s/it] 95%|█████████▍| 2486/2628 [1:44:35<04:17,  1.81s/it] 95%|█████████▍| 2487/2628 [1:44:37<04:15,  1.81s/it] 95%|█████████▍| 2488/2628 [1:44:38<04:14,  1.82s/it] 95%|█████████▍| 2489/2628 [1:44:40<04:11,  1.81s/it] 95%|█████████▍| 2490/2628 [1:44:42<04:10,  1.81s/it]                                                      95%|█████████▍| 2490/2628 [1:44:42<04:10,  1.81s/it] 95%|█████████▍| 2491/2628 [1:44:44<04:08,  1.81s/it] 95%|█████████▍| 2492/2628 [1:44:46<04:07,  1.82s/it] 95%|█████████▍| 2493/2628 [1:44:47<04:04,  1.81s/it] 95%|█████████▍| 2494/2628 [1:44:49<04:02,  1.81s/it] 95%|█████████▍| 2495/2628 [1:44:51<04:00,  1.81s/it] 95%|█████████▍| 2496/2628 [1:44:53<03:58,  1.81s/it] 95%|█████████▌| 2497/2628 [1:44:55<03:56,  1.81s/it] 95%|█████████▌| 2498/2628 [1:44:57<03:55,  1.81s/it] 95%|█████████▌| 2499/2628 [1:44:58<03:53,  1.81s/it] 95%|█████████▌| 2500/2628 [1:45:00<03:51,  1.81s/it]                                                      95%|█████████▌| 2500/2628 [1:45:00<03:51,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 18:41:25,489 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 18:41:25,489 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 18:41:25,489 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:41:25,987 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:41:29,103 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:03<00:01,  1.61s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:41:32,395 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:06<00:00,  2.30s/it][A                                                     
                                             [A 95%|█████████▌| 2500/2628 [1:45:10<03:51,  1.81s/it]
100%|██████████| 3/3 [00:06<00:00,  2.30s/it][A
                                             [A 95%|█████████▌| 2501/2628 [1:45:12<10:20,  4.89s/it] 95%|█████████▌| 2502/2628 [1:45:14<08:19,  3.96s/it] 95%|█████████▌| 2503/2628 [1:45:16<06:54,  3.32s/it] 95%|█████████▌| 2504/2628 [1:45:18<05:55,  2.87s/it] 95%|█████████▌| 2505/2628 [1:45:19<05:13,  2.55s/it] 95%|█████████▌| 2506/2628 [1:45:21<04:43,  2.33s/it] 95%|█████████▌| 2507/2628 [1:45:23<04:22,  2.17s/it] 95%|█████████▌| 2508/2628 [1:45:25<04:07,  2.06s/it] 95%|█████████▌| 2509/2628 [1:45:27<03:56,  1.99s/it] 96%|█████████▌| 2510/2628 [1:45:29<03:48,  1.93s/it]                                                      96%|█████████▌| 2510/2628 [1:45:29<03:48,  1.93s/it] 96%|█████████▌| 2511/2628 [1:45:30<03:42,  1.90s/it] 96%|█████████▌| 2512/2628 [1:45:32<03:37,  1.88s/it] 96%|█████████▌| 2513/2628 [1:45:34<03:33,  1.85s/it] 96%|█████████▌| 2514/2628 [1:45:36<03:29,  1.84s/it] 96%|█████████▌| 2515/2628 [1:45:38<03:26,  1.83s/it] 96%|█████████▌| 2516/2628 [1:45:39<03:24,  1.82s/it] 96%|█████████▌| 2517/2628 [1:45:41<03:21,  1.82s/it] 96%|█████████▌| 2518/2628 [1:45:43<03:19,  1.81s/it] 96%|█████████▌| 2519/2628 [1:45:45<03:17,  1.81s/it] 96%|█████████▌| 2520/2628 [1:45:47<03:15,  1.81s/it]                                                      96%|█████████▌| 2520/2628 [1:45:47<03:15,  1.81s/it] 96%|█████████▌| 2521/2628 [1:45:48<03:13,  1.81s/it] 96%|█████████▌| 2522/2628 [1:45:50<03:12,  1.81s/it] 96%|█████████▌| 2523/2628 [1:45:52<03:09,  1.81s/it] 96%|█████████▌| 2524/2628 [1:45:54<03:08,  1.81s/it] 96%|█████████▌| 2525/2628 [1:45:56<03:06,  1.81s/it] 96%|█████████▌| 2526/2628 [1:45:57<03:04,  1.81s/it] 96%|█████████▌| 2527/2628 [1:45:59<03:02,  1.81s/it] 96%|█████████▌| 2528/2628 [1:46:01<03:00,  1.81s/it] 96%|█████████▌| 2529/2628 [1:46:03<02:58,  1.81s/it] 96%|█████████▋| 2530/2628 [1:46:05<02:56,  1.81s/it]                                                      96%|█████████▋| 2530/2628 [1:46:05<02:56,  1.81s/it] 96%|█████████▋| 2531/2628 [1:46:07<02:55,  1.81s/it] 96%|█████████▋| 2532/2628 [1:46:08<02:53,  1.81s/it] 96%|█████████▋| 2533/2628 [1:46:10<02:52,  1.81s/it] 96%|█████████▋| 2534/2628 [1:46:12<02:50,  1.81s/it] 96%|█████████▋| 2535/2628 [1:46:14<02:48,  1.81s/it] 96%|█████████▋| 2536/2628 [1:46:16<02:46,  1.81s/it] 97%|█████████▋| 2537/2628 [1:46:17<02:44,  1.81s/it] 97%|█████████▋| 2538/2628 [1:46:19<02:42,  1.81s/it] 97%|█████████▋| 2539/2628 [1:46:21<02:41,  1.81s/it] 97%|█████████▋| 2540/2628 [1:46:23<02:39,  1.81s/it]                                                      97%|█████████▋| 2540/2628 [1:46:23<02:39,  1.81s/it] 97%|█████████▋| 2541/2628 [1:46:25<02:37,  1.81s/it] 97%|█████████▋| 2542/2628 [1:46:26<02:35,  1.81s/it] 97%|█████████▋| 2543/2628 [1:46:28<02:33,  1.81s/it] 97%|█████████▋| 2544/2628 [1:46:30<02:31,  1.81s/it] 97%|█████████▋| 2545/2628 [1:46:32<02:30,  1.81s/it] 97%|█████████▋| 2546/2628 [1:46:34<02:28,  1.81s/it] 97%|█████████▋| 2547/2628 [1:46:35<02:26,  1.81s/it] 97%|█████████▋| 2548/2628 [1:46:37<02:24,  1.81s/it] 97%|█████████▋| 2549/2628 [1:46:39<02:22,  1.81s/it] 97%|█████████▋| 2550/2628 [1:46:41<02:20,  1.81s/it]                                                      97%|█████████▋| 2550/2628 [1:46:41<02:20,  1.81s/it] 97%|█████████▋| 2551/2628 [1:46:43<02:19,  1.81s/it] 97%|█████████▋| 2552/2628 [1:46:45<02:17,  1.81s/it] 97%|█████████▋| 2553/2628 [1:46:46<02:16,  1.81s/it] 97%|█████████▋| 2554/2628 [1:46:48<02:14,  1.81s/it] 97%|█████████▋| 2555/2628 [1:46:50<02:12,  1.81s/it] 97%|█████████▋| 2556/2628 [1:46:52<02:10,  1.82s/it] 97%|█████████▋| 2557/2628 [1:46:54<02:08,  1.81s/it] 97%|█████████▋| 2558/2628 [1:46:55<02:06,  1.81s/it] 97%|█████████▋| 2559/2628 [1:46:57<02:04,  1.81s/it] 97%|█████████▋| 2560/2628 [1:46:59<02:03,  1.81s/it]                                                      97%|█████████▋| 2560/2628 [1:46:59<02:03,  1.81s/it] 97%|█████████▋| 2561/2628 [1:47:01<02:01,  1.81s/it] 97%|█████████▋| 2562/2628 [1:47:03<01:59,  1.81s/it] 98%|█████████▊| 2563/2628 [1:47:04<01:57,  1.81s/it] 98%|█████████▊| 2564/2628 [1:47:06<01:55,  1.81s/it] 98%|█████████▊| 2565/2628 [1:47:08<01:53,  1.81s/it] 98%|█████████▊| 2566/2628 [1:47:10<01:51,  1.81s/it] 98%|█████████▊| 2567/2628 [1:47:12<01:50,  1.81s/it] 98%|█████████▊| 2568/2628 [1:47:13<01:48,  1.81s/it] 98%|█████████▊| 2569/2628 [1:47:15<01:46,  1.81s/it] 98%|█████████▊| 2570/2628 [1:47:17<01:44,  1.81s/it]                                                      98%|█████████▊| 2570/2628 [1:47:17<01:44,  1.81s/it] 98%|█████████▊| 2571/2628 [1:47:19<01:43,  1.81s/it] 98%|█████████▊| 2572/2628 [1:47:21<01:41,  1.81s/it] 98%|█████████▊| 2573/2628 [1:47:23<01:39,  1.81s/it] 98%|█████████▊| 2574/2628 [1:47:24<01:37,  1.81s/it] 98%|█████████▊| 2575/2628 [1:47:26<01:35,  1.81s/it] 98%|█████████▊| 2576/2628 [1:47:28<01:34,  1.81s/it] 98%|█████████▊| 2577/2628 [1:47:30<01:32,  1.81s/it] 98%|█████████▊| 2578/2628 [1:47:32<01:30,  1.81s/it] 98%|█████████▊| 2579/2628 [1:47:33<01:28,  1.81s/it] 98%|█████████▊| 2580/2628 [1:47:35<01:27,  1.82s/it]                                                      98%|█████████▊| 2580/2628 [1:47:35<01:27,  1.82s/it] 98%|█████████▊| 2581/2628 [1:47:37<01:25,  1.81s/it] 98%|█████████▊| 2582/2628 [1:47:39<01:23,  1.81s/it] 98%|█████████▊| 2583/2628 [1:47:41<01:21,  1.81s/it] 98%|█████████▊| 2584/2628 [1:47:42<01:19,  1.81s/it] 98%|█████████▊| 2585/2628 [1:47:44<01:17,  1.81s/it] 98%|█████████▊| 2586/2628 [1:47:46<01:15,  1.81s/it] 98%|█████████▊| 2587/2628 [1:47:48<01:14,  1.81s/it] 98%|█████████▊| 2588/2628 [1:47:50<01:12,  1.80s/it] 99%|█████████▊| 2589/2628 [1:47:51<01:10,  1.81s/it] 99%|█████████▊| 2590/2628 [1:47:53<01:08,  1.81s/it]                                                      99%|█████████▊| 2590/2628 [1:47:53<01:08,  1.81s/it] 99%|█████████▊| 2591/2628 [1:47:55<01:06,  1.81s/it] 99%|█████████▊| 2592/2628 [1:47:57<01:04,  1.81s/it] 99%|█████████▊| 2593/2628 [1:47:59<01:03,  1.81s/it] 99%|█████████▊| 2594/2628 [1:48:00<01:01,  1.81s/it] 99%|█████████▊| 2595/2628 [1:48:02<00:59,  1.81s/it] 99%|█████████▉| 2596/2628 [1:48:04<00:57,  1.81s/it] 99%|█████████▉| 2597/2628 [1:48:06<00:56,  1.81s/it] 99%|█████████▉| 2598/2628 [1:48:08<00:54,  1.81s/it] 99%|█████████▉| 2599/2628 [1:48:10<00:52,  1.81s/it] 99%|█████████▉| 2600/2628 [1:48:11<00:50,  1.81s/it]                                                      99%|█████████▉| 2600/2628 [1:48:11<00:50,  1.81s/it][INFO|trainer.py:4643] 2025-10-21 18:44:36,705 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 18:44:36,705 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 18:44:36,705 >>   Batch size = 8
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:44:37,202 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

  0%|          | 0/3 [00:00<?, ?it/s][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:44:40,395 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

 67%|██████▋   | 2/3 [00:03<00:01,  1.64s/it][AA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[WARNING|utils.py:2443] 2025-10-21 18:44:43,737 >> A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.

100%|██████████| 3/3 [00:07<00:00,  2.69s/it][A                                                     
                                             [A 99%|█████████▉| 2600/2628 [1:48:23<00:50,  1.81s/it]
100%|██████████| 3/3 [00:07<00:00,  2.69s/it][A
                                             [A 99%|█████████▉| 2601/2628 [1:48:24<02:20,  5.19s/it] 99%|█████████▉| 2602/2628 [1:48:26<01:48,  4.18s/it] 99%|█████████▉| 2603/2628 [1:48:28<01:26,  3.47s/it] 99%|█████████▉| 2604/2628 [1:48:30<01:11,  2.97s/it] 99%|█████████▉| 2605/2628 [1:48:32<01:00,  2.62s/it] 99%|█████████▉| 2606/2628 [1:48:34<00:52,  2.38s/it] 99%|█████████▉| 2607/2628 [1:48:35<00:46,  2.21s/it] 99%|█████████▉| 2608/2628 [1:48:37<00:41,  2.09s/it] 99%|█████████▉| 2609/2628 [1:48:39<00:38,  2.01s/it] 99%|█████████▉| 2610/2628 [1:48:41<00:35,  1.95s/it]                                                      99%|█████████▉| 2610/2628 [1:48:41<00:35,  1.95s/it] 99%|█████████▉| 2611/2628 [1:48:43<00:32,  1.91s/it] 99%|█████████▉| 2612/2628 [1:48:44<00:30,  1.88s/it] 99%|█████████▉| 2613/2628 [1:48:46<00:27,  1.86s/it] 99%|█████████▉| 2614/2628 [1:48:48<00:25,  1.84s/it]100%|█████████▉| 2615/2628 [1:48:50<00:23,  1.83s/it]100%|█████████▉| 2616/2628 [1:48:52<00:21,  1.83s/it]100%|█████████▉| 2617/2628 [1:48:53<00:20,  1.82s/it]100%|█████████▉| 2618/2628 [1:48:55<00:18,  1.82s/it]100%|█████████▉| 2619/2628 [1:48:57<00:16,  1.82s/it]100%|█████████▉| 2620/2628 [1:48:59<00:14,  1.81s/it]                                                     100%|█████████▉| 2620/2628 [1:48:59<00:14,  1.81s/it]100%|█████████▉| 2621/2628 [1:49:01<00:12,  1.81s/it]100%|█████████▉| 2622/2628 [1:49:02<00:10,  1.81s/it]100%|█████████▉| 2623/2628 [1:49:04<00:09,  1.81s/it]100%|█████████▉| 2624/2628 [1:49:06<00:07,  1.81s/it]100%|█████████▉| 2625/2628 [1:49:08<00:05,  1.81s/it]100%|█████████▉| 2626/2628 [1:49:10<00:03,  1.80s/it]100%|█████████▉| 2627/2628 [1:49:12<00:01,  1.80s/it]100%|██████████| 2628/2628 [1:49:13<00:00,  1.84s/it][INFO|trainer.py:4309] 2025-10-21 18:45:38,763 >> Saving model checkpoint to saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2628
[INFO|configuration_utils.py:491] 2025-10-21 18:45:38,767 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2628/config.json
[INFO|configuration_utils.py:757] 2025-10-21 18:45:38,768 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2628/generation_config.json
[INFO|modeling_utils.py:4189] 2025-10-21 18:45:42,658 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2628/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2421] 2025-10-21 18:45:42,660 >> chat template saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2628/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-21 18:45:42,660 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2628/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-21 18:45:42,661 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2628/special_tokens_map.json
[INFO|image_processing_base.py:253] 2025-10-21 18:45:47,614 >> Image processor saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2628/preprocessor_config.json
[INFO|tokenization_utils_base.py:2421] 2025-10-21 18:45:47,616 >> chat template saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2628/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-21 18:45:47,617 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2628/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-21 18:45:47,617 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2628/special_tokens_map.json
[INFO|video_processing_utils.py:600] 2025-10-21 18:45:47,709 >> Video processor saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2628/video_preprocessor_config.json
[INFO|processing_utils.py:814] 2025-10-21 18:45:47,709 >> chat template saved in saves/qwen3_5vl-4b/full/sft/${dataset}/checkpoint-2628/chat_template.jinja
[INFO|trainer.py:2810] 2025-10-21 18:45:47,952 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                     100%|██████████| 2628/2628 [1:49:23<00:00,  1.84s/it]100%|██████████| 2628/2628 [1:49:23<00:00,  2.50s/it]
[INFO|image_processing_base.py:253] 2025-10-21 18:45:47,957 >> Image processor saved in saves/qwen3_5vl-4b/full/sft/${dataset}/preprocessor_config.json
[INFO|tokenization_utils_base.py:2421] 2025-10-21 18:45:47,958 >> chat template saved in saves/qwen3_5vl-4b/full/sft/${dataset}/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-21 18:45:47,958 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-21 18:45:47,959 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/special_tokens_map.json
[INFO|video_processing_utils.py:600] 2025-10-21 18:45:48,046 >> Video processor saved in saves/qwen3_5vl-4b/full/sft/${dataset}/video_preprocessor_config.json
[INFO|processing_utils.py:814] 2025-10-21 18:45:48,046 >> chat template saved in saves/qwen3_5vl-4b/full/sft/${dataset}/chat_template.jinja
[INFO|trainer.py:4309] 2025-10-21 18:45:48,348 >> Saving model checkpoint to saves/qwen3_5vl-4b/full/sft/${dataset}
[INFO|configuration_utils.py:491] 2025-10-21 18:45:48,353 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/${dataset}/config.json
[INFO|configuration_utils.py:757] 2025-10-21 18:45:48,353 >> Configuration saved in saves/qwen3_5vl-4b/full/sft/${dataset}/generation_config.json
[INFO|modeling_utils.py:4189] 2025-10-21 18:45:52,219 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at saves/qwen3_5vl-4b/full/sft/${dataset}/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2421] 2025-10-21 18:45:52,222 >> chat template saved in saves/qwen3_5vl-4b/full/sft/${dataset}/chat_template.jinja
[INFO|tokenization_utils_base.py:2590] 2025-10-21 18:45:52,223 >> tokenizer config file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/tokenizer_config.json
[INFO|tokenization_utils_base.py:2599] 2025-10-21 18:45:52,223 >> Special tokens file saved in saves/qwen3_5vl-4b/full/sft/${dataset}/special_tokens_map.json
[INFO|trainer.py:4643] 2025-10-21 18:45:52,497 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2025-10-21 18:45:52,497 >>   Num examples = 83
[INFO|trainer.py:4648] 2025-10-21 18:45:52,497 >>   Batch size = 8
  0%|          | 0/3 [00:00<?, ?it/s] 67%|██████▋   | 2/3 [00:02<00:01,  1.23s/it]100%|██████████| 3/3 [00:05<00:00,  1.82s/it]100%|██████████| 3/3 [00:05<00:00,  1.74s/it]
Traceback (most recent call last):
  File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/launcher.py", line 180, in <module>
    run_exp()
  File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/tuner.py", line 112, in run_exp
    override_config = OmegaConf.from_cli(sys.argv[2:])
  File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/tuner.py", line 74, in _training_function
    if finetuning_args.early_stopping_steps is not None:
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/sft/workflow.py", line 165, in run_sft
    trainer.log_metrics("eval", metrics)
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer_pt_utils.py", line 1041, in log_metrics
    metrics_formatted = metrics_format(metrics)
                        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer_pt_utils.py", line 944, in metrics_format
    metrics_copy = metrics.copy()
                   ^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'copy'
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/launcher.py", line 180, in <module>
[rank0]:     run_exp()
[rank0]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/tuner.py", line 112, in run_exp
[rank0]:     override_config = OmegaConf.from_cli(sys.argv[2:])
[rank0]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/tuner.py", line 74, in _training_function
[rank0]:     if finetuning_args.early_stopping_steps is not None:
[rank0]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/train/sft/workflow.py", line 165, in run_sft
[rank0]:     trainer.log_metrics("eval", metrics)
[rank0]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer_pt_utils.py", line 1041, in log_metrics
[rank0]:     metrics_formatted = metrics_format(metrics)
[rank0]:                         ^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/transformers/trainer_pt_utils.py", line 944, in metrics_format
[rank0]:     metrics_copy = metrics.copy()
[rank0]:                    ^^^^^^^^^^^^
[rank0]: AttributeError: 'NoneType' object has no attribute 'copy'
W1021 18:46:05.870000 3682406 /hkfs/home/project/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3682411 closing signal SIGTERM
W1021 18:46:05.890000 3682406 /hkfs/home/project/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3682412 closing signal SIGTERM
W1021 18:46:05.918000 3682406 /hkfs/home/project/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3682413 closing signal SIGTERM
E1021 18:46:05.939000 3682406 /hkfs/home/project/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 3682410) of binary: /home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/bin/python3.12
Traceback (most recent call last):
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/bin/torchrun", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/launcher.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-21_18:46:05
  host      : hkn0922.localdomain
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3682410)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/cli.py", line 31, in <module>
    main()
  File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/cli.py", line 24, in main
    launcher.launch()
  File "/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/launcher.py", line 110, in launch
    process = subprocess.run(
              ^^^^^^^^^^^^^^^
  File "/home/hk-project-sustainebot/bm3844/miniconda3/envs/roboG_train/lib/python3.12/subprocess.py", line 571, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['torchrun', '--nnodes', '1', '--node_rank', '0', '--nproc_per_node', '4', '--master_addr', '127.0.0.1', '--master_port', '45241', '/home/hk-project-sustainebot/bm3844/code/LLaMA-Factory-RoboG-v2/src/llamafactory/launcher.py', 'examples/train_full/qwen3vl/qwen3vl_roboG_poc_two_frames.yaml']' returned non-zero exit status 1.
srun: error: hkn0922: task 0: Exited with exit code 1
